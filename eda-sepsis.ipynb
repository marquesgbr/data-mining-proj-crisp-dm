{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6713f917",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA) - Dataset de Sepsis\n",
    "\n",
    "## Objetivo da Análise\n",
    "\n",
    "* Compreender a estrutura e qualidade dos dados\n",
    "* Analisar padrões de valores faltantes\n",
    "* Identificar relações entre variáveis e a ocorrência de sepsis\n",
    "* Gerar insights para construção de modelos preditivos\n",
    "\n",
    "## Sobre o Dataset\n",
    "\n",
    "* **Problema**: Detecção precoce de sepsis em pacientes de UTI\n",
    "* **Tipo**: Classificação binária (Sepsis vs Não-Sepsis)\n",
    "* **Características**: Dados de sinais vitais, exames laboratoriais e informações demográficas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457206f",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas\n",
    "\n",
    "Primeiro, vamos importar todas as bibliotecas necessárias para nossa análise exploratória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas essenciais para análise exploratória\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configurações para otimizar as visualizações\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c51c3",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Estrutura do Dataset\n",
    "\n",
    "Nesta seção, carregamos o dataset de treino e analisamos suas características básicas para compreender a estrutura dos dados e identificar possíveis problemas de qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset de treino\n",
    "train_df = pd.read_csv('dataset_sepsis_train.csv')\n",
    "\n",
    "# Análise da estrutura básica do dataset\n",
    "print(\"INFORMAÇÕES GERAIS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dimensões do dataset (shape): {train_df.shape}\")\n",
    "print(f\"Número de amostras: {train_df.shape[0]:,}\")\n",
    "print(f\"Número de features: {train_df.shape[1]}\")\n",
    "print(f\"Tamanho em memória: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nINFORMAÇÕES DETALHADAS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "# Usar info() para mostrar tipos de dados e valores não-nulos\n",
    "train_df.info()\n",
    "\n",
    "print(f\"\\nESTATÍSTICAS DESCRITIVAS (TRANSPOSTAS)\")\n",
    "print(\"=\" * 50)\n",
    "# Mostrar estatísticas descritivas transpostas para melhor visualização\n",
    "display(train_df.describe().T)\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(f\"\\nPRIMEIRAS 5 LINHAS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cacb5",
   "metadata": {},
   "source": [
    "### 2.1 Análise de Valores Faltantes\n",
    "\n",
    "A análise sistemática de valores faltantes é essencial para identificar padrões de missings e definir estratégias de tratamento adequadas. Esta análise nos permite entender se os dados faltam de forma aleatória ou seguem algum padrão específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise quantitativa dos valores faltantes\n",
    "missing_count = train_df.isnull().sum()\n",
    "missing_pct = (missing_count / len(train_df)) * 100\n",
    "\n",
    "# Criar DataFrame para análise organizada\n",
    "missing_df = pd.DataFrame({\n",
    "    'Coluna': missing_count.index,\n",
    "    'Valores_Faltantes': missing_count.values,\n",
    "    'Porcentagem': missing_pct.values\n",
    "}).sort_values('Porcentagem', ascending=False)\n",
    "\n",
    "# Estatísticas gerais\n",
    "total_samples = len(train_df)\n",
    "mean_missing = missing_pct.mean()\n",
    "vars_with_missing = (missing_count > 0).sum()\n",
    "total_vars = len(missing_count)\n",
    "\n",
    "print(\"ANÁLISE DE VALORES FALTANTES\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total de amostras: {total_samples:,}\")\n",
    "print(f\"Total de variáveis: {total_vars}\")\n",
    "print(f\"Variáveis com missing values: {vars_with_missing}\")\n",
    "print(f\"Percentual médio de missing values: {mean_missing:.3f}%\")\n",
    "\n",
    "print(f\"\\nTOP 10 VARIÁVEIS COM MAIS MISSING VALUES:\")\n",
    "top_10_missing = missing_df.head(10)\n",
    "display(top_10_missing)\n",
    "\n",
    "# Categorização por nível de missing\n",
    "very_high = missing_df[missing_df['Porcentagem'] > 50]\n",
    "high_missing = missing_df[(missing_df['Porcentagem'] > 20) & (missing_df['Porcentagem'] <= 50)]\n",
    "medium_missing = missing_df[(missing_df['Porcentagem'] > 5) & (missing_df['Porcentagem'] <= 20)]\n",
    "low_missing = missing_df[(missing_df['Porcentagem'] > 0) & (missing_df['Porcentagem'] <= 5)]\n",
    "\n",
    "print(f\"\\nCATEGORIZAÇÃO POR NÍVEL DE MISSING:\")\n",
    "print(f\"Muito Alto (>50%): {len(very_high)} variáveis\")\n",
    "print(f\"Alto (20-50%): {len(high_missing)} variáveis\")\n",
    "print(f\"Médio (5-20%): {len(medium_missing)} variáveis\")\n",
    "print(f\"Baixo (0-5%): {len(low_missing)} variáveis\")\n",
    "print(f\"Sem missing: {len(missing_df[missing_df['Porcentagem'] == 0])} variáveis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2046f3",
   "metadata": {},
   "source": [
    "### 2.2 Visualização dos Padrões de Missing Values\n",
    "\n",
    "A visualização dos padrões de valores faltantes nos ajuda a identificar se existe alguma estrutura nos dados ausentes e a definir estratégias de tratamento mais eficazes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee376ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas variáveis com missing values para visualização\n",
    "missing_with_nans = missing_df[missing_df['Porcentagem'] > 0]\n",
    "\n",
    "# Configurar subplots - 2 gráficos principais\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "# 1. Gráfico de barras horizontais - TODAS as colunas com missing values\n",
    "# Preparar dados para o seaborn barplot\n",
    "missing_sorted = missing_with_nans.sort_values('Porcentagem', ascending=True)  # Crescente para barras horizontais\n",
    "\n",
    "# Criar gráfico de barras horizontais usando seaborn\n",
    "sns.barplot(\n",
    "    x=missing_sorted['Porcentagem'],\n",
    "    y=missing_sorted['Coluna'],\n",
    "    orient='h',\n",
    "    palette='rocket_r',  # Paleta de cores\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "# Configurar títulos e labels\n",
    "axes[0].set_title(f'Percentual de Valores Nulos (NaNs) por Coluna\\n({len(missing_sorted)} variáveis com dados ausentes)', \n",
    "                    fontsize=14, pad=20)\n",
    "axes[0].set_xlabel('Percentual (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Colunas do Dataset', fontsize=12)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, (idx, row) in enumerate(missing_sorted.iterrows()):\n",
    "    pct = row['Porcentagem']\n",
    "    axes[0].text(pct + 1, i, f'{pct:.1f}%', \n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Adicionar linhas de referência\n",
    "axes[0].axvline(20, color='orange', linestyle='--', alpha=0.8, label='20% (Baixo)')\n",
    "axes[0].axvline(80, color='red', linestyle='--', alpha=0.8, label='80% (Alto)')\n",
    "axes[0].legend(loc='upper right')\n",
    "\n",
    "# Configurar grid e limites\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "axes[0].set_xlim(0, 105)\n",
    "\n",
    "# 2. Histograma da distribuição de missing values (mais segmentado)\n",
    "# Criar bins de 10 em 10\n",
    "bins = range(0, 101, 10) \n",
    "\n",
    "axes[1].hist(missing_with_nans['Porcentagem'], bins=bins, alpha=0.7, \n",
    "            color='#34495e', edgecolor='black', rwidth=0.8)\n",
    "\n",
    "axes[1].set_xlabel('Percentual de Missing Values (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Número de Variáveis', fontsize=12)\n",
    "axes[1].set_title('Distribuição de Missing Values por Faixa', fontsize=14, pad=20)\n",
    "\n",
    "# Configurar eixo X \n",
    "axes[1].set_xticks(bins)\n",
    "axes[1].set_xlim(0, 100)\n",
    "\n",
    "# Adicionar linha vertical para a média\n",
    "mean_missing = missing_with_nans['Porcentagem'].mean()\n",
    "axes[1].axvline(mean_missing, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Média: {mean_missing:.1f}%')\n",
    "axes[1].legend()\n",
    "\n",
    "# Configurar grid\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionar anotações no histograma\n",
    "counts, bins_edges = np.histogram(missing_with_nans['Porcentagem'], bins=bins)\n",
    "for i, count in enumerate(counts):\n",
    "    if count > 0:\n",
    "        bin_center = (bins_edges[i] + bins_edges[i+1]) / 2\n",
    "        axes[1].text(bin_center, count + max(counts)*0.01, str(count), \n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise estatística dos missing values (mais detalhada)\n",
    "print(\"ANÁLISE DOS MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Categorização mais detalhada\n",
    "very_low = missing_with_nans[missing_with_nans['Porcentagem'] < 10]\n",
    "low_missing = missing_with_nans[(missing_with_nans['Porcentagem'] >= 10) & \n",
    "                                (missing_with_nans['Porcentagem'] < 20)]\n",
    "medium_missing = missing_with_nans[(missing_with_nans['Porcentagem'] >= 20) & \n",
    "                                    (missing_with_nans['Porcentagem'] < 50)]\n",
    "high_missing = missing_with_nans[(missing_with_nans['Porcentagem'] >= 50) & \n",
    "                                (missing_with_nans['Porcentagem'] < 80)]\n",
    "very_high = missing_with_nans[missing_with_nans['Porcentagem'] >= 80]\n",
    "\n",
    "print(\"Categorização detalhada por nível de missing values:\")\n",
    "print(f\"  • Muito baixo (<10%): {len(very_low)} variáveis\")\n",
    "print(f\"  • Baixo (10-20%): {len(low_missing)} variáveis\")\n",
    "print(f\"  • Médio (20-50%): {len(medium_missing)} variáveis\")\n",
    "print(f\"  • Alto (50-80%): {len(high_missing)} variáveis\")\n",
    "print(f\"  • Muito alto (≥80%): {len(very_high)} variáveis\")\n",
    "\n",
    "print(f\"\\nEstatísticas descritivas dos missing values:\")\n",
    "print(f\"  • Média: {missing_with_nans['Porcentagem'].mean():.1f}%\")\n",
    "print(f\"  • Mediana: {missing_with_nans['Porcentagem'].median():.1f}%\")\n",
    "print(f\"  • Desvio padrão: {missing_with_nans['Porcentagem'].std():.1f}%\")\n",
    "print(f\"  • Mínimo: {missing_with_nans['Porcentagem'].min():.1f}%\")\n",
    "print(f\"  • Máximo: {missing_with_nans['Porcentagem'].max():.1f}%\")\n",
    "\n",
    "print(f\"\\nTop 5 variáveis com mais missing values:\")\n",
    "top_5_missing = missing_with_nans.head(5)\n",
    "for idx, (_, row) in enumerate(top_5_missing.iterrows(), 1):\n",
    "    print(f\"  {idx}. {row['Coluna']}: {row['Porcentagem']:.1f}% ({row['Valores_Faltantes']:,} valores)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79778e58",
   "metadata": {},
   "source": [
    "Estratégias de tratamento possíveis por faixa de valores faltantes \n",
    "\n",
    "- Muito baixo/Baixo (<20%): Imputação simples (mediana/moda)\n",
    "- Médio (20-50%): Imputação específica por domínio clínico ()\n",
    "- Alto (50-80%): Considerar remoção ou imputação avançada\n",
    "- Muito alto (≥80%): Forte candidato à remoção. Chance de tratamento se estiver associado a muitas instâncias de SepsisLabel=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97d5c8",
   "metadata": {},
   "source": [
    "#### 2.2.1 Análise Visual de Outliers e Inconsistências\n",
    "\n",
    "Baseando-se nas estatísticas descritivas, vamos identificar e visualizar variáveis com potenciais problemas de qualidade dos dados, incluindo outliers extremos e valores fisiologicamente inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de outliers e inconsistências baseada nas estatísticas descritivas\n",
    "# Obter estatísticas descritivas apenas para variáveis numéricas (excluindo SepsisLabel)\n",
    "numerical_vars = train_df.select_dtypes(include=[np.number]).columns\n",
    "numerical_vars = numerical_vars.drop('SepsisLabel')  # Remover a variável target\n",
    "\n",
    "\n",
    "# Criar boxplot para visualizar distribuições e outliers\n",
    "# Como temos muitas variáveis, vamos fazer um gráfico grande com subplots\n",
    "n_vars = len(numerical_vars)\n",
    "n_cols = 4  # 4 gráficos por linha\n",
    "n_rows = (n_vars + n_cols - 1) // n_cols  # Arredondar para cima\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten() if n_vars > 1 else [axes]\n",
    "\n",
    "for i, var in enumerate(numerical_vars):\n",
    "    # Criar boxplot para cada variável\n",
    "    data = train_df[var].dropna()\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        axes[i].boxplot(data, patch_artist=True, \n",
    "                       boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                       medianprops=dict(color='red', linewidth=2),\n",
    "                       flierprops=dict(marker='o', markerfacecolor='red', markersize=2, alpha=0.5))\n",
    "        \n",
    "        axes[i].set_title(f'{var}\\n(n={len(data):,})', fontsize=10, pad=10)\n",
    "        axes[i].set_ylabel('Valores')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar estatísticas básicas no gráfico\n",
    "        stats_text = f'Min: {data.min():.2f}\\nMédia: {data.mean():.2f}\\nMax: {data.max():.2f}'\n",
    "        axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes, \n",
    "                    fontsize=8, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, 'Sem dados\\nválidos', \n",
    "                    transform=axes[i].transAxes, ha='center', va='center')\n",
    "        axes[i].set_title(var, fontsize=10)\n",
    "\n",
    "# Remover subplots extras se houver\n",
    "for i in range(n_vars, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3c0c1",
   "metadata": {},
   "source": [
    "### 2.3 Estrutura Temporal dos Dados\n",
    "\n",
    "Um aspecto fundamental para compreender este dataset é que **cada linha não representa um paciente único**, mas sim um **momento específico no tempo** para diferentes pacientes. O dataset é uma coleção de séries temporais clínicas onde múltiplas observações são registradas para cada paciente ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANÁLISE DA ESTRUTURA TEMPORAL DOS DADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "patient_id_cols = [col for col in train_df.columns if 'patient' in col.lower() or 'id' in col.lower()]\n",
    "print(f\"Colunas que podem ser ID do paciente: {patient_id_cols}\")\n",
    "\n",
    "print(f\"\\nDIMENSÕES DO DATASET:\")\n",
    "print(f\"   Total de observações (linhas): {len(train_df):,}\")\n",
    "print(f\"   Total de variáveis (colunas): {len(train_df.columns)}\")\n",
    "\n",
    "print(f\"\\nVARIÁVEIS TEMPORAIS IDENTIFICADAS:\")\n",
    "\n",
    "# Análise da variável Hour\n",
    "hour_non_null = train_df['Hour'].notna().sum()\n",
    "hour_unique = train_df['Hour'].nunique()\n",
    "hour_min = train_df['Hour'].min()\n",
    "hour_max = train_df['Hour'].max()\n",
    "\n",
    "print(f\"\\n   Hour:\")\n",
    "print(f\"      Observações válidas: {hour_non_null:,}\")\n",
    "print(f\"      Valores únicos: {hour_unique:,}\")\n",
    "print(f\"      Range: {hour_min:.2f} - {hour_max:.2f} horas\")\n",
    "print(f\"      Interpretação: Horas desde admissão na UTI\")\n",
    "print(f\"      Máximo: {hour_max/24:.1f} dias na UTI\")\n",
    "\n",
    "# Análise da variável HospAdmTime  \n",
    "hospadm_non_null = train_df['HospAdmTime'].notna().sum()\n",
    "hospadm_unique = train_df['HospAdmTime'].nunique()\n",
    "hospadm_min = train_df['HospAdmTime'].min()\n",
    "hospadm_max = train_df['HospAdmTime'].max()\n",
    "\n",
    "print(f\"\\n   HospAdmTime:\")\n",
    "print(f\"      Observações válidas: {hospadm_non_null:,}\")\n",
    "print(f\"      Valores únicos: {hospadm_unique:,}\")\n",
    "print(f\"      Range: {hospadm_min:.2f} - {hospadm_max:.2f} horas\")\n",
    "print(f\"      Interpretação: Tempo de internação hospitalar\")\n",
    "print(f\"      Máximo: {hospadm_max:.1f} horas para ser admitido na UTI depois de ser admitido no hospital\")\n",
    "\n",
    "# Estimativa de pacientes únicos usando características demográficas\n",
    "demographic_cols = ['Age', 'Gender', 'Unit1', 'Unit2']\n",
    "print(f\"\\nESTIMATIVA DE PACIENTES ÚNICOS:\")\n",
    "print(f\"   (Baseada em combinação de: {', '.join(demographic_cols)})\")\n",
    "\n",
    "demo_combination = train_df[demographic_cols].fillna('Unknown')\n",
    "demo_string = demo_combination.astype(str).agg('_'.join, axis=1)\n",
    "unique_combinations = demo_string.nunique()\n",
    "\n",
    "print(f\"   Combinações únicas de características: {unique_combinations:,}\")\n",
    "print(f\"   Observações por combinação (média): {len(train_df) / unique_combinations:.1f}\")\n",
    "\n",
    "combo_counts = demo_string.value_counts()\n",
    "print(f\"\\n   DISTRIBUIÇÃO DE OBSERVAÇÕES:\")\n",
    "print(f\"      Min observações por paciente: {combo_counts.min()}\")\n",
    "print(f\"      Max observações por paciente: {combo_counts.max()}\")\n",
    "print(f\"      Mediana observações por paciente: {combo_counts.median():.0f}\")\n",
    "print(f\"      Média observações por paciente: {combo_counts.mean():.1f}\")\n",
    "\n",
    "# Padrão temporal das observações\n",
    "print(f\"\\nPADRÃO TEMPORAL DAS OBSERVAÇÕES:\")\n",
    "\n",
    "hour_dist = train_df['Hour'].value_counts().sort_index()\n",
    "print(f\"   Horas com mais observações:\")\n",
    "top_hours = hour_dist.head(5)\n",
    "for hour, count in top_hours.items():\n",
    "    print(f\"      Hora {hour:.0f}: {count:,} observações ({count/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "unique_hours = train_df['Hour'].nunique()\n",
    "\n",
    "print(f\"   Frequência média de coleta: {len(train_df) / unique_hours:.1f} pacientes por momento\")\n",
    "print(f\"\\n   Total de momentos temporais únicos: {unique_hours:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0986e",
   "metadata": {},
   "source": [
    "**Implicações para a análise:**\n",
    "\n",
    "Este é um dataset de séries temporais, não de pacientes individuais, isto é, cada linha = 1 momento no tempo para 1 paciente, logo as análises devem considerar a dependência temporal, pois pacientes podem ter múltiplas observações ao longo do tempo e a variável target (SepsisLabel) pode mudar ao longo do tempo para o mesmo paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7599ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da estrutura temporal\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribuição das observações por hora\n",
    "hour_counts = train_df['Hour'].value_counts().sort_index()\n",
    "axes[0,0].plot(hour_counts.index, hour_counts.values, marker='o', linewidth=2, markersize=4)\n",
    "axes[0,0].set_title('Distribuição de Observações por Hora', fontsize=12)\n",
    "axes[0,0].set_xlabel('Horas desde admissão na UTI até a observação de dados clínicos')\n",
    "axes[0,0].set_ylabel('Número de observações')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Boxplot da distribuição de horas\n",
    "axes[0,1].boxplot(train_df['Hour'].dropna(), patch_artist=True, \n",
    "                 boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "axes[0,1].set_title('Distribuição das Horas de Observação', fontsize=12)\n",
    "axes[0,1].set_ylabel('Horas')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Distribuição de SepsisLabel ao longo do tempo\n",
    "sepsis_by_hour = train_df.groupby('Hour')['SepsisLabel'].agg(['count', 'sum']).reset_index()\n",
    "sepsis_by_hour['sepsis_rate'] = sepsis_by_hour['sum'] / sepsis_by_hour['count'] * 100\n",
    "\n",
    "# Filtrar apenas horas com pelo menos 100 observações para estabilidade\n",
    "stable_hours = sepsis_by_hour[sepsis_by_hour['count'] >= 100]\n",
    "\n",
    "axes[1,0].plot(stable_hours['Hour'], stable_hours['sepsis_rate'], \n",
    "              marker='o', linewidth=2, markersize=4, color='red')\n",
    "axes[1,0].set_title('Taxa de Sepsis ao Longo do Tempo', fontsize=12)\n",
    "axes[1,0].set_xlabel('Horas desde admissão na UTI até a observação de dados clínicos')\n",
    "axes[1,0].set_ylabel('Taxa de Sepsis (%)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histograma do número de observações por paciente estimado\n",
    "demo_combination = train_df[demographic_cols].fillna('Unknown')\n",
    "demo_string = demo_combination.astype(str).agg('_'.join, axis=1)\n",
    "combo_counts = demo_string.value_counts()\n",
    "\n",
    "axes[1,1].hist(combo_counts.values, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1,1].set_title('Distribuição do Número de Observações\\npor Paciente Estimado', fontsize=12)\n",
    "axes[1,1].set_xlabel('Número de observações por paciente')\n",
    "axes[1,1].set_ylabel('Frequência')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar estatísticas no gráfico\n",
    "mean_obs = combo_counts.mean()\n",
    "median_obs = combo_counts.median()\n",
    "axes[1,1].axvline(mean_obs, color='red', linestyle='--', \n",
    "                 label=f'Média: {mean_obs:.1f}')\n",
    "axes[1,1].axvline(median_obs, color='orange', linestyle='--', \n",
    "                 label=f'Mediana: {median_obs:.0f}')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.suptitle('Estrutura Temporal do Dataset de Sepsis', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c65535",
   "metadata": {},
   "source": [
    "### Interpretação dos Gráficos da Estrutura Temporal\n",
    "\n",
    "#### **1. Distribuição de Observações por Hora (Superior Esquerdo)**\n",
    "\n",
    "Este gráfico revela um padrão temporal crítico no dataset:\n",
    "\n",
    "- **Concentração inicial**: Há uma concentração massiva de observações nas primeiras horas após admissão na UTI (0-50 horas)\n",
    "- **Pico máximo**: Ocorre nas primeiras horas, com mais de 30.000 observações\n",
    "- **Declínio exponencial**: O número de observações diminui drasticamente após as primeiras 100 horas\n",
    "- **Cauda longa**: Alguns pacientes permanecem na UTI por até 300+ horas (12+ dias)\n",
    "\n",
    "**Implicação clínica**: A maioria dos pacientes tem estadia curta na UTI ou são transferidos/recebem alta rapidamente, enquanto uma minoria permanece por períodos prolongados.\n",
    "\n",
    "#### **2. Distribuição das Horas de Observação (Superior Direito)**\n",
    "\n",
    "O boxplot complementa a análise temporal:\n",
    "\n",
    "- **Mediana baixa**: A mediana está próxima a 25-30 horas, confirmando que metade dos pacientes tem observações concentradas no início\n",
    "- **Outliers extremos**: Existem casos com observações muito tardias (acima de 250 horas)\n",
    "- **IQR compacto**: O intervalo interquartil é relativamente pequeno, indicando que 75% das observações ocorrem nas primeiras ~75 horas\n",
    "- **Assimetria positiva**: A distribuição é fortemente enviesada para a direita\n",
    "\n",
    "**Interpretação**: O tempo de permanência na UTI segue um padrão típico de cuidados intensivos, com a maioria dos casos sendo resolvidos rapidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a7a43",
   "metadata": {},
   "source": [
    "#### **3. Taxa de Sepsis ao Longo do Tempo (Inferior Esquerdo)**\n",
    "\n",
    "Este é o gráfico mais clinicamente relevante, mostrando a evolução temporal do risco de sepsis:\n",
    "\n",
    "- **Período inicial de baixo risco**: Nas primeiras 50 horas, a taxa de sepsis permanece baixa (0-5%)\n",
    "- **Transição crítica**: Entre 50-100 horas, há um aumento gradual mas consistente na taxa de sepsis\n",
    "- **Pico de risco**: A partir de 100 horas, a taxa de sepsis aumenta significativamente, chegando a 15-20%\n",
    "- **Padrão progressivo**: O risco continua aumentando com o tempo de permanência\n",
    "\n",
    "**Significado clínico**: \n",
    "- Pacientes com internação prolongada têm risco progressivamente maior de desenvolver sepsis\n",
    "- O tempo de permanência é um **preditor temporal** importante para sepsis\n",
    "- Após 100 horas na UTI, o risco praticamente triplica\n",
    "\n",
    "#### **4. Distribuição do Número de Observações por Paciente Estimado (Inferior Direito)**\n",
    "\n",
    "Este histograma revela a estrutura longitudinal do dataset:\n",
    "\n",
    "- **Concentração em baixas contagens**: A maioria dos pacientes tem poucas observações (< 500)\n",
    "- **Distribuição assimétrica**: Distribuição com cauda longa à direita\n",
    "- **Mediana vs Média**: Mediana (36) muito menor que a média (83.2), confirmando assimetria\n",
    "- **Casos extremos**: Alguns pacientes têm mais de 3.000 observações\n",
    "\n",
    "**Interpretações importantes**:\n",
    "- **Heterogeneidade temporal**: Pacientes variam drasticamente no tempo de monitoramento\n",
    "- **Natureza longitudinal**: Confirma que cada paciente contribui com múltiplas observações\n",
    "- **Viés potencial**: Pacientes mais graves podem ter mais observações (mais tempo na UTI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8426b183",
   "metadata": {},
   "source": [
    "### **Síntese dos Insights Temporais para o Relatório**\n",
    "\n",
    "#### **Principais Descobertas:**\n",
    "\n",
    "1. **Padrão de Permanência na UTI**:\n",
    "   - 75% dos pacientes têm observações concentradas nas primeiras 75 horas\n",
    "   - Mediana de permanência: ~30 horas (1,25 dias)\n",
    "   - Casos extremos podem chegar a 300+ horas (12+ dias)\n",
    "\n",
    "2. **Relação Temporal com Sepsis**:\n",
    "   - **Janela de baixo risco**: Primeiras 50 horas (taxa < 5%)\n",
    "   - **Janela de transição**: 50-100 horas (aumento gradual)\n",
    "   - **Janela de alto risco**: >100 horas (taxa pode ultrapassar 15%)\n",
    "\n",
    "3. **Estrutura dos Dados**:\n",
    "   - Dataset é uma **coleção de séries temporais**, não registros únicos de pacientes\n",
    "   - Cada linha = um momento temporal para um paciente específico\n",
    "   - Variabilidade alta no número de observações por paciente (mediana: 36, máximo: >3000)\n",
    "\n",
    "#### **Implicações para Modelagem**:\n",
    "\n",
    "- **Dependência temporal**: Modelos devem considerar a sequência temporal das observações\n",
    "- **Feature temporal**: O tempo de permanência é um preditor importante\n",
    "- **Validação temporal**: Necessária validação que preserve a ordem temporal\n",
    "- **Threshold temporal**: Considerar diferentes estratégias para janelas temporais específicas\n",
    "\n",
    "#### **Relevância Clínica**:\n",
    "\n",
    "- O tempo de permanência prolongado na UTI está associado ao aumento progressivo do risco de sepsis\n",
    "- Pacientes que permanecem >100 horas na UTI constituem um grupo de alto risco que requer monitoramento intensificado\n",
    "- A detecção precoce de sepsis é mais crítica nos primeiros dias de internação, quando a taxa é naturalmente baixa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25813412",
   "metadata": {},
   "source": [
    "### 2.4 Separação de Features e Target\n",
    "\n",
    "Separamos a variável alvo (SepsisLabel) das features para facilitar as análises subsequentes. Essa separação é fundamental para a análise univariada e bivariada posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação entre features (X) e variável target (y)\n",
    "X_train = train_df.drop('SepsisLabel', axis=1)\n",
    "y_train = train_df['SepsisLabel']\n",
    "\n",
    "print(\"SEPARAÇÃO DE FEATURES E TARGET\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Shape das features (X_train): {X_train.shape}\")\n",
    "print(f\"Shape do target (y_train): {y_train.shape}\")\n",
    "\n",
    "# Verificar se há duplicatas no dataset\n",
    "duplicates = train_df.duplicated().sum()\n",
    "print(f\"\\nLinhas duplicadas: {duplicates}\")\n",
    "\n",
    "# Análise de valores únicos por coluna\n",
    "print(f\"\\nANÁLISE DE VALORES ÚNICOS POR COLUNA\")\n",
    "print(\"=\" * 50)\n",
    "unique_counts = train_df.nunique().sort_values(ascending=False)\n",
    "print(\"Valores únicos por coluna:\")\n",
    "display(unique_counts.to_frame('Valores_Únicos'))\n",
    "\n",
    "print(f\"\\nColunas com poucos valores únicos (potencialmente categóricas):\")\n",
    "few_unique = unique_counts[unique_counts <= 10]\n",
    "display(few_unique.to_frame('Valores_Únicos'))\n",
    "\n",
    "# Análise da distribuição da variável target\n",
    "print(f\"\\nDISTRIBUIÇÃO DA VARIÁVEL TARGET\")\n",
    "print(\"=\" * 50)\n",
    "target_counts = y_train.value_counts().sort_index()\n",
    "target_pct = y_train.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "for label, count in target_counts.items():\n",
    "    pct = target_pct[label]\n",
    "    status = \"Não-Sepsis\" if label == 0 else \"Sepsis\"\n",
    "    print(f\"{status} ({label}): {count:,} amostras ({pct:.2f}%)\")\n",
    "\n",
    "# Calcular razão de desbalanceamento\n",
    "imbalance_ratio = target_counts[0] / target_counts[1]\n",
    "print(f\"\\nRazão de desbalanceamento: {imbalance_ratio:.1f}:1\")\n",
    "print(f\"Para cada caso de sepsis, existem {imbalance_ratio:.1f} casos de não-sepsis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73399d",
   "metadata": {},
   "source": [
    "#### 2.4.1 Visualização da Distribuição da Variável Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ee48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da distribuição da variável target\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Gráfico 1: Contagem absoluta\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar(['Não-Sepsis', 'Sepsis'], target_counts.values, \n",
    "               color=['#3498db', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
    "plt.title('Distribuição Absoluta das Classes', fontsize=14, pad=20)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, count in zip(bars, target_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(target_counts)*0.01,\n",
    "            f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico 2: Gráfico de pizza\n",
    "plt.subplot(1, 2, 2)\n",
    "wedges, texts, autotexts = plt.pie(target_pct.values, \n",
    "                                  labels=['Não-Sepsis', 'Sepsis'], \n",
    "                                  autopct='%1.2f%%', \n",
    "                                  colors=['#3498db', '#e74c3c'],\n",
    "                                  startangle=90,\n",
    "                                  explode=(0, 0.1))\n",
    "plt.title('Proporção das Classes', fontsize=14, pad=20)\n",
    "\n",
    "# Melhorar formatação dos rótulos\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1d6bb",
   "metadata": {},
   "source": [
    "Podemos ver que o dataset está altamente desbalanceado. Precisaremos tomar alguns cuidados na fase de avaliação e amostragem:\n",
    "- Utilizar métricas adequadas (F1-Score, AUC-ROC, Precision-Recall)\n",
    "- Aplicar técnicas de balanceamento (SMOTE, undersampling)\n",
    "- Configurar class_weight nos algoritmos de ML\n",
    "- Considerar threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93f3d9",
   "metadata": {},
   "source": [
    "## Análise Univariada Detalhada\n",
    "\n",
    "A análise univariada examina cada variável individualmente para compreender suas distribuições, identificar outliers e avaliar características estatísticas importantes como assimetria e curtose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e75d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Histogramas com KDE para análise de distribuição das variáveis numéricas\n",
    "\n",
    "# Selecionar variáveis numéricas com baixo percentual de missing values\n",
    "numerical_columns = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# Filtrar colunas com menos de 30% de valores faltantes para análise\n",
    "low_missing_cols = []\n",
    "for col in numerical_columns:\n",
    "    missing_pct = X_train[col].isnull().sum() / len(X_train) * 100\n",
    "    if missing_pct < 30:\n",
    "        low_missing_cols.append(col)\n",
    "\n",
    "print(f\"Analisando {len(low_missing_cols)} variáveis numéricas com <30% missing values\")\n",
    "\n",
    "# Selecionar as primeiras 12 variáveis para visualização\n",
    "cols_to_plot = low_missing_cols[:12]\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(18, n_rows * 4))\n",
    "\n",
    "for idx, feature in enumerate(cols_to_plot, 1):\n",
    "    plt.subplot(n_rows, n_cols, idx)\n",
    "    \n",
    "    # Calcular skewness (assimetria)\n",
    "    skewness = X_train[feature].skew()\n",
    "    \n",
    "    # Plotar histograma com KDE\n",
    "    sns.histplot(X_train[feature].dropna(), kde=True, alpha=0.7, color='skyblue')\n",
    "    plt.title(f\"{feature} | Skewness: {skewness:.2f}\", fontsize=12)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequência')\n",
    "    \n",
    "    # Adicionar linha vertical para a média\n",
    "    mean_val = X_train[feature].mean()\n",
    "    plt.axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Média: {mean_val:.2f}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResumo das {len(cols_to_plot)} variáveis analisadas:\")\n",
    "for col in cols_to_plot:\n",
    "    skew_val = X_train[col].skew()\n",
    "    if skew_val > 1:\n",
    "        interpretation = \"Fortemente assimétrica à direita\"\n",
    "    elif skew_val < -1:\n",
    "        interpretation = \"Fortemente assimétrica à esquerda\"\n",
    "    elif abs(skew_val) < 0.5:\n",
    "        interpretation = \"Aproximadamente simétrica\"\n",
    "    else:\n",
    "        interpretation = \"Moderadamente assimétrica\"\n",
    "    \n",
    "    print(f\"  {col}: {skew_val:.2f} ({interpretation})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05693e43",
   "metadata": {},
   "source": [
    "Interpretação dos gráficos de assimetria:\n",
    "- Skewness = 0: Distribuição simétrica\n",
    "- Skewness > 1: Fortemente assimétrica à direita\n",
    "- Skewness < -1: Fortemente assimétrica à esquerda\n",
    "- -1 ≤ Skewness ≤ 1: Moderadamente assimétrica ou simétrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd19d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Swarm Plot para identificar outliers (Não rodar essa célula: muito exemplos para rodar de uma vez)\n",
    "# Obs: usar amostragem para conseguir usar o swarm plot\n",
    "# Análise de outliers em variáveis importantes vs target\n",
    "\n",
    "# Selecionar algumas variáveis importantes para análise de outliers\n",
    "important_vars = ['HR', 'SBP', 'DBP', 'Temp', 'Resp', 'O2Sat', 'Age']\n",
    "available_vars = [col for col in important_vars if col in X_train.columns]\n",
    "\n",
    "# Criar subplots para swarm plots\n",
    "n_vars = min(4, len(available_vars))  # Limitar a 4 para não sobrecarregar\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, var in enumerate(available_vars[:n_vars]):\n",
    "    # Preparar dados removendo NaN\n",
    "    temp_df = pd.DataFrame({\n",
    "        'variable': X_train[var],\n",
    "        'target': y_train\n",
    "    }).dropna()\n",
    "    \n",
    "    # Converter target para string para melhor visualização\n",
    "    temp_df['target_str'] = temp_df['target'].map({0: 'Não-Sepsis', 1: 'Sepsis'})\n",
    "    \n",
    "    if len(temp_df) > 0:\n",
    "        # Criar swarm plot\n",
    "        sns.swarmplot(data=temp_df, x='target_str', y='variable', \n",
    "                        palette=['#3498db', '#e74c3c'], alpha=0.6, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Swarm Plot: {var} vs SepsisLabel', fontsize=12)\n",
    "        axes[idx].set_xlabel('SepsisLabel')\n",
    "        axes[idx].set_ylabel(var)\n",
    "        \n",
    "        # Adicionar informações estatísticas\n",
    "        stats_0 = temp_df[temp_df['target'] == 0]['variable'].describe()\n",
    "        stats_1 = temp_df[temp_df['target'] == 1]['variable'].describe()\n",
    "        \n",
    "        info_text = f\"Não-Sepsis: μ={stats_0['mean']:.2f}\\\\nSepsis: μ={stats_1['mean']:.2f}\"\n",
    "        axes[idx].text(0.02, 0.98, info_text, transform=axes[idx].transAxes,\n",
    "                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                        fontsize=9)\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f'Dados insuficientes\\\\npara {var}', \n",
    "                        transform=axes[idx].transAxes, ha='center', va='center')\n",
    "        axes[idx].set_title(f'{var} - Sem dados')\n",
    "\n",
    "# Remover subplots vazios\n",
    "for i in range(n_vars, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\nINTERPRETAÇÃO DOS SWARM PLOTS:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"- Pontos isolados e distantes dos clusters principais = outliers\")\n",
    "print(\"- Densidade maior de pontos = concentração de valores\")\n",
    "print(\"- Diferentes posições verticais entre classes = possível discriminação\")\n",
    "print(\"- Sobreposição entre classes = dificuldade de separação\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47275667",
   "metadata": {},
   "source": [
    "## Análise Bivariada\n",
    "\n",
    "A análise bivariada examina as relações entre duas variáveis, ajudando a identificar padrões, dependências e correlações que podem ser cruciais para o desenvolvimento de modelos preditivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pair Plot para mostrar distribuições e relações entre variáveis\n",
    "# Selecionar um subconjunto de variáveis para o pairplot (para performance)\n",
    "\n",
    "# Pegar variáveis com baixo missing e adicionar o target\n",
    "pairplot_vars = []\n",
    "if len(low_missing_cols) > 0:\n",
    "    # Selecionar as 5 primeiras variáveis numéricas com baixo missing\n",
    "    pairplot_vars = low_missing_cols[:5]\n",
    "\n",
    "# Criar DataFrame para pairplot incluindo o target\n",
    "if len(pairplot_vars) > 0:\n",
    "    pairplot_data = X_train[pairplot_vars].copy()\n",
    "    pairplot_data['SepsisLabel'] = y_train\n",
    "    \n",
    "    # Amostrar dados se o dataset for muito grande (para performance)\n",
    "    if len(pairplot_data) > 5000:\n",
    "        pairplot_sample = pairplot_data.sample(n=5000, random_state=42)\n",
    "        print(f\"Usando amostra de 5000 registros para pairplot (de {len(pairplot_data)} total)\")\n",
    "    else:\n",
    "        pairplot_sample = pairplot_data\n",
    "        print(f\"Usando todos os {len(pairplot_data)} registros para pairplot\")\n",
    "    \n",
    "    # Remover linhas com valores faltantes para o pairplot\n",
    "    pairplot_sample = pairplot_sample.dropna()\n",
    "    \n",
    "    if len(pairplot_sample) > 0:\n",
    "        print(f\"\\\\nCriando Pair Plot com {len(pairplot_sample)} amostras válidas...\")\n",
    "        print(f\"Variáveis incluídas: {pairplot_vars}\")\n",
    "        \n",
    "        # Configurar paleta de cores\n",
    "        sns.set_palette(\"Set1\")\n",
    "        \n",
    "        # Criar pairplot\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        \n",
    "        # Pairplot com diferenciação por classe\n",
    "        pair_grid = sns.pairplot(pairplot_sample, hue='SepsisLabel', \n",
    "                                diag_kind='hist', \n",
    "                                plot_kws={'alpha': 0.6},\n",
    "                                diag_kws={'alpha': 0.7})\n",
    "        \n",
    "        # Personalizar a legenda\n",
    "        pair_grid._legend.set_title(\"SepsisLabel\")\n",
    "        for text, label in zip(pair_grid._legend.get_texts(), ['Não-Sepsis', 'Sepsis']):\n",
    "            text.set_text(label)\n",
    "        \n",
    "        plt.suptitle('Pair Plot - Análise de Relações entre Variáveis', y=1.02, fontsize=16)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\\\nINTERPRETAÇÃO DO PAIR PLOT:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"- Diagonal: Histogramas mostram a distribuição individual de cada variável\")\n",
    "        print(\"- Triângulo inferior/superior: Scatter plots mostram relações entre pares de variáveis\")\n",
    "        print(\"- Cores diferentes: Separação por classe (Sepsis vs Não-Sepsis)\")\n",
    "        print(\"- Padrões lineares nos scatter plots: Possíveis correlações\")\n",
    "        print(\"- Separação clara entre cores: Potencial discriminativo da variável\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Dados insuficientes após remoção de valores faltantes para pairplot.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Nenhuma variável numérica disponível para pairplot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Box Plots para análise de distribuições por classe\n",
    "# Examinar como variáveis numéricas se comportam para cada classe do target\n",
    "\n",
    "# Selecionar variáveis para box plots\n",
    "boxplot_vars = available_vars[:4] if available_vars else low_missing_cols[:4]\n",
    "\n",
    "if len(boxplot_vars) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, var in enumerate(boxplot_vars):\n",
    "        # Preparar dados\n",
    "        temp_df = pd.DataFrame({\n",
    "            'variable': X_train[var],\n",
    "            'target': y_train\n",
    "        }).dropna()\n",
    "        \n",
    "        # Converter target para labels descritivos\n",
    "        temp_df['target_str'] = temp_df['target'].map({0: 'Não-Sepsis', 1: 'Sepsis'})\n",
    "        \n",
    "        if len(temp_df) > 0:\n",
    "            # Criar box plot\n",
    "            sns.boxplot(data=temp_df, x='target_str', y='variable', \n",
    "                       palette=['#3498db', '#e74c3c'], ax=axes[idx])\n",
    "            axes[idx].set_title(f'Box Plot: {var} vs SepsisLabel', fontsize=12)\n",
    "            axes[idx].set_xlabel('SepsisLabel')\n",
    "            axes[idx].set_ylabel(var)\n",
    "            \n",
    "            # Calcular e mostrar estatísticas\n",
    "            stats_by_class = temp_df.groupby('target')['variable'].agg(['median', 'mean', 'std']).round(2)\n",
    "            \n",
    "            # Adicionar informações estatísticas\n",
    "            info_text = f\"Não-Sepsis - Med: {stats_by_class.loc[0, 'median']:.2f}\\\\n\"\n",
    "            info_text += f\"Sepsis - Med: {stats_by_class.loc[1, 'median']:.2f}\"\n",
    "            \n",
    "            axes[idx].text(0.02, 0.98, info_text, transform=axes[idx].transAxes,\n",
    "                          verticalalignment='top', \n",
    "                          bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                          fontsize=10)\n",
    "        else:\n",
    "            axes[idx].text(0.5, 0.5, f'Dados insuficientes\\\\npara {var}', \n",
    "                          transform=axes[idx].transAxes, ha='center', va='center')\n",
    "            axes[idx].set_title(f'{var} - Sem dados')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Análise estatística das diferenças\n",
    "    print(\"\\\\nANÁLISE ESTATÍSTICA DAS DIFERENÇAS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for var in boxplot_vars:\n",
    "        if var in X_train.columns:\n",
    "            temp_df = pd.DataFrame({\n",
    "                'variable': X_train[var],\n",
    "                'target': y_train\n",
    "            }).dropna()\n",
    "            \n",
    "            if len(temp_df) > 10:  # Mínimo de dados para análise\n",
    "                group_0 = temp_df[temp_df['target'] == 0]['variable']\n",
    "                group_1 = temp_df[temp_df['target'] == 1]['variable']\n",
    "                \n",
    "                if len(group_0) > 0 and len(group_1) > 0:\n",
    "                    median_diff = group_1.median() - group_0.median()\n",
    "                    mean_diff = group_1.mean() - group_0.mean()\n",
    "                    \n",
    "                    print(f\"{var}:\")\n",
    "                    print(f\"  Diferença de medianas (Sepsis - Não-Sepsis): {median_diff:.3f}\")\n",
    "                    print(f\"  Diferença de médias (Sepsis - Não-Sepsis): {mean_diff:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Nenhuma variável disponível para box plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e830a0",
   "metadata": {},
   "source": [
    "INTERPRETAÇÃO DOS BOX PLOTS\n",
    "- Caixa (box): Representa o IQR (Intervalo Interquartil)\n",
    "- Linha central: Mediana da distribuição\n",
    "- Whiskers (bigodes): Extensão até valores dentro de 1.5×IQR\n",
    "- Pontos individuais: Outliers (valores extremos)\n",
    "- Caixas mais longas: Maior variabilidade nos dados\n",
    "- Diferenças entre medianas das classes: Potencial discriminativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e5ab2",
   "metadata": {},
   "source": [
    "## Análise Multivariada\n",
    "\n",
    "A análise multivariada examina as interações entre múltiplas variáveis simultaneamente, identificando padrões complexos e correlações que podem não ser aparentes na análise univariada ou bivariada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929370bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap - Análise de correlações entre variáveis\n",
    "\n",
    "# Selecionar variáveis numéricas com baixo missing para análise de correlação\n",
    "correlation_vars = low_missing_cols[:20] if len(low_missing_cols) > 20 else low_missing_cols\n",
    "\n",
    "if len(correlation_vars) > 1:\n",
    "    # Criar subset dos dados para correlação\n",
    "    correlation_data = X_train[correlation_vars].copy()\n",
    "    \n",
    "    # Calcular matriz de correlação\n",
    "    correlation_matrix = correlation_data.corr()\n",
    "    \n",
    "    print(f\"MATRIZ DE CORRELAÇÃO\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Analisando correlações entre {len(correlation_vars)} variáveis numéricas\")\n",
    "    print(f\"Variáveis incluídas: {correlation_vars[:10]}{'...' if len(correlation_vars) > 10 else ''}\")\n",
    "    \n",
    "    # Criar heatmap de correlação\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    # Configurar máscara para a diagonal superior (opcional)\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    \n",
    "    # Criar heatmap\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                annot=True,           # Mostrar valores\n",
    "                fmt='.2f',           # Formato dos números\n",
    "                cmap='RdBu_r',       # Paleta de cores (similar ao GeeksforGeeks)\n",
    "                center=0,            # Centralizar em zero\n",
    "                square=True,         # Células quadradas\n",
    "                linewidths=0.5,      # Linhas entre células\n",
    "                cbar_kws={\"shrink\": .8},  # Configurar colorbar\n",
    "                mask=mask)           # Máscara para diagonal superior\n",
    "    \n",
    "    plt.title('Matriz de Correlação - Heatmap', fontsize=16, pad=20)\n",
    "    plt.xlabel('Variáveis', fontsize=12)\n",
    "    plt.ylabel('Variáveis', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Análise de correlações mais significativas\n",
    "    print(\"\\\\nANÁLISE DE CORRELAÇÕES SIGNIFICATIVAS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Encontrar correlações mais altas (excluindo diagonal)\n",
    "    correlation_matrix_no_diag = correlation_matrix.copy()\n",
    "    np.fill_diagonal(correlation_matrix_no_diag.values, np.nan)\n",
    "    \n",
    "    # Achatar a matriz e ordenar por valor absoluto\n",
    "    corr_pairs = []\n",
    "    for i in range(len(correlation_matrix_no_diag)):\n",
    "        for j in range(i+1, len(correlation_matrix_no_diag)):\n",
    "            var1 = correlation_matrix_no_diag.index[i]\n",
    "            var2 = correlation_matrix_no_diag.columns[j]\n",
    "            corr_value = correlation_matrix_no_diag.iloc[i, j]\n",
    "            if not np.isnan(corr_value):\n",
    "                corr_pairs.append((var1, var2, corr_value))\n",
    "    \n",
    "    # Ordenar por valor absoluto de correlação\n",
    "    corr_pairs_sorted = sorted(corr_pairs, key=lambda x: abs(x[2]), reverse=True)\n",
    "    \n",
    "    print(\"Top 10 correlações mais fortes:\")\n",
    "    for i, (var1, var2, corr) in enumerate(corr_pairs_sorted[:10], 1):\n",
    "        strength = \"Muito forte\" if abs(corr) > 0.8 else \"Forte\" if abs(corr) > 0.6 else \"Moderada\" if abs(corr) > 0.4 else \"Fraca\"\n",
    "        direction = \"positiva\" if corr > 0 else \"negativa\"\n",
    "        print(f\"{i:2d}. {var1} ↔ {var2}: {corr:.3f} ({strength} {direction})\")\n",
    "    \n",
    "    # Identificar correlações problemáticas (multicolinearidade)\n",
    "    high_corr_pairs = [pair for pair in corr_pairs_sorted if abs(pair[2]) > 0.8]\n",
    "    if high_corr_pairs:\n",
    "        print(f\"Atenção: {len(high_corr_pairs)} pares com correlação muito alta (>0.8) detectados!\")\n",
    "        print(\"Considere técnicas para lidar com multicolinearidade:\")\n",
    "        print(\"- Remoção de uma das variáveis correlacionadas\")\n",
    "        print(\"- Análise de Componentes Principais (PCA)\")\n",
    "        print(\"- Regularização (Ridge, Lasso)\")\n",
    "    \n",
    "    print(\"\\\\nINTERPRETAÇÃO DA MATRIZ DE CORRELAÇÃO:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"- Valores próximos a +1: Correlação positiva forte (variáveis aumentam juntas)\")\n",
    "    print(\"- Valores próximos a -1: Correlação negativa forte (uma aumenta, outra diminui)\")\n",
    "    print(\"- Valores próximos a 0: Sem correlação linear\")\n",
    "    print(\"- Cores mais escuras (vermelho/azul): Correlações mais fortes\")\n",
    "    print(\"- Cores mais claras: Correlações mais fracas\")\n",
    "    \n",
    "else:\n",
    "    print(\"Dados insuficientes para análise de correlação.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df5350",
   "metadata": {},
   "source": [
    "## Análise das Variáveis Categóricas\n",
    "\n",
    "A identificação e análise das variáveis categóricas nos permite compreender as características demográficas e clínicas dos pacientes, bem como sua associação com o desenvolvimento de sepsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação de variáveis categóricas\n",
    "print(\"IDENTIFICAÇÃO DE VARIÁVEIS CATEGÓRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variáveis categóricas explícitas\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Variáveis numéricas que podem ser categóricas (poucos valores únicos)\n",
    "potential_categorical = []\n",
    "for col in X_train.columns:\n",
    "    unique_values = X_train[col].nunique()\n",
    "    if unique_values <= 10 and X_train[col].dtype in ['int64', 'float64']:\n",
    "        potential_categorical.append((col, unique_values))\n",
    "\n",
    "print(f\"Variáveis categóricas explícitas: {len(categorical_cols)}\")\n",
    "if categorical_cols:\n",
    "    print(f\"  {categorical_cols}\")\n",
    "\n",
    "print(f\"\\nVariáveis potencialmente categóricas (≤10 valores únicos): {len(potential_categorical)}\")\n",
    "for col, count in potential_categorical[:10]:\n",
    "    print(f\"  {col}: {count} valores únicos\")\n",
    "\n",
    "# Selecionar variáveis categóricas relevantes para análise\n",
    "important_categorical = ['Gender', 'Unit1', 'Unit2']\n",
    "selected_categorical = []\n",
    "\n",
    "for col in important_categorical:\n",
    "    if col in X_train.columns:\n",
    "        selected_categorical.append(col)\n",
    "\n",
    "# Adicionar outras variáveis categóricas se necessário\n",
    "for col, count in potential_categorical:\n",
    "    if col not in selected_categorical and len(selected_categorical) < 5:\n",
    "        selected_categorical.append(col)\n",
    "\n",
    "print(f\"\\nVariáveis selecionadas para análise detalhada: {selected_categorical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb4480",
   "metadata": {},
   "source": [
    "## Análise Detalhada das Variáveis Categóricas Selecionadas\n",
    "\n",
    "Vamos examinar estatisticamente cada variável categórica selecionada, incluindo sua distribuição e relação com a variável target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise estatística detalhada das variáveis categóricas selecionadas\n",
    "for col in selected_categorical:\n",
    "    print(f\"\\nANÁLISE DA VARIÁVEL: {col}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Distribuição de frequências\n",
    "    value_counts = X_train[col].value_counts()\n",
    "    value_pct = X_train[col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"Distribuição de frequências:\")\n",
    "    for value in value_counts.index:\n",
    "        count = value_counts[value]\n",
    "        pct = value_pct[value]\n",
    "        print(f\"  {value}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nEstatísticas básicas:\")\n",
    "    print(f\"  Valores únicos: {X_train[col].nunique()}\")\n",
    "    print(f\"  Valores faltantes: {X_train[col].isnull().sum()}\")\n",
    "    print(f\"  Moda: {X_train[col].mode().iloc[0] if len(X_train[col].mode()) > 0 else 'N/A'}\")\n",
    "    \n",
    "    # Análise da relação com a variável target\n",
    "    if len(value_counts) <= 10:  # Só para variáveis com poucos valores\n",
    "        print(f\"\\nRelação com SepsisLabel:\")\n",
    "        \n",
    "        # Tabela de contingência\n",
    "        crosstab = pd.crosstab(X_train[col], y_train, margins=True)\n",
    "        print(\"Tabela de contingência:\")\n",
    "        display(crosstab)\n",
    "        \n",
    "        # Proporções condicionais\n",
    "        crosstab_pct = pd.crosstab(X_train[col], y_train, normalize='index') * 100\n",
    "        print(f\"\\nTaxa de sepsis por categoria:\")\n",
    "        for category in crosstab_pct.index:\n",
    "            if category != 'All':\n",
    "                sepsis_rate = crosstab_pct.loc[category, 1] if 1 in crosstab_pct.columns else 0\n",
    "                print(f\"  {category}: {sepsis_rate:.2f}% de casos com sepsis\")\n",
    "    \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37522ac2",
   "metadata": {},
   "source": [
    "## Visualização das Variáveis Categóricas\n",
    "\n",
    "As visualizações nos permitem compreender melhor a distribuição das variáveis categóricas e sua associação com a ocorrência de sepsis de forma intuitiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das variáveis categóricas\n",
    "if selected_categorical:\n",
    "    n_vars = len(selected_categorical)\n",
    "    fig, axes = plt.subplots(n_vars, 2, figsize=(16, 6*n_vars))\n",
    "    \n",
    "    if n_vars == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, col in enumerate(selected_categorical):\n",
    "        # Gráfico 1: Distribuição simples\n",
    "        counts = X_train[col].value_counts()\n",
    "        \n",
    "        ax1 = axes[i, 0] if n_vars > 1 else axes[0]\n",
    "        bars = ax1.bar(range(len(counts)), counts.values, \n",
    "                      color='#2c3e50', alpha=0.8, edgecolor='black')\n",
    "        ax1.set_xticks(range(len(counts)))\n",
    "        ax1.set_xticklabels(counts.index, rotation=45)\n",
    "        ax1.set_title(f'Distribuição de {col}')\n",
    "        ax1.set_xlabel(col)\n",
    "        ax1.set_ylabel('Frequência')\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for bar, count in zip(bars, counts.values):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n",
    "                    f'{count:,}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Gráfico 2: Relação com target\n",
    "        ax2 = axes[i, 1] if n_vars > 1 else axes[1]\n",
    "        \n",
    "        # Criar tabela de contingência para visualização\n",
    "        temp_df = pd.DataFrame({'categoria': X_train[col], 'target': y_train})\n",
    "        crosstab = pd.crosstab(temp_df['categoria'], temp_df['target'])\n",
    "        crosstab_pct = pd.crosstab(temp_df['categoria'], temp_df['target'], normalize='index') * 100\n",
    "        \n",
    "        # Gráfico de barras empilhadas\n",
    "        crosstab.plot(kind='bar', stacked=True, ax=ax2, \n",
    "                     color=['#3498db', '#e74c3c'], alpha=0.8)\n",
    "        ax2.set_title(f'{col} vs SepsisLabel')\n",
    "        ax2.set_xlabel(col)\n",
    "        ax2.set_ylabel('Frequência')\n",
    "        ax2.legend(['Não-Sepsis', 'Sepsis'], title='SepsisLabel')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Adicionar percentuais de sepsis\n",
    "        for j, category in enumerate(crosstab.index):\n",
    "            if 1 in crosstab_pct.columns:\n",
    "                sepsis_pct = crosstab_pct.loc[category, 1]\n",
    "                total_height = crosstab.loc[category].sum()\n",
    "                ax2.text(j, total_height + max(crosstab.sum(axis=1))*0.02, \n",
    "                        f'{sepsis_pct:.1f}%', ha='center', va='bottom', \n",
    "                        fontweight='bold', fontsize=8, color='red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Nenhuma variável categórica disponível para visualização.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96611658",
   "metadata": {},
   "source": [
    "## Análise de Relações entre Variáveis Categóricas e Numéricas\n",
    "\n",
    "Esta análise explora como as variáveis categóricas influenciam a distribuição das variáveis numéricas, especialmente no contexto da sepsis. Isso nos ajuda a identificar padrões clínicos importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de variáveis numéricas relevantes para análise\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Filtrar variáveis numéricas com menos de 50% de valores faltantes\n",
    "numeric_cols_clean = []\n",
    "for col in numeric_cols:\n",
    "    missing_pct = X_train[col].isnull().sum() / len(X_train) * 100\n",
    "    if missing_pct < 50:\n",
    "        numeric_cols_clean.append(col)\n",
    "\n",
    "print(\"SELEÇÃO DE VARIÁVEIS NUMÉRICAS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total de variáveis numéricas: {len(numeric_cols)}\")\n",
    "print(f\"Variáveis com <50% missing: {len(numeric_cols_clean)}\")\n",
    "\n",
    "# Priorizar variáveis de sinais vitais importantes\n",
    "important_numeric = ['HR', 'SBP', 'DBP', 'Temp', 'Resp', 'O2Sat', 'Age']\n",
    "selected_numeric = []\n",
    "\n",
    "for col in important_numeric:\n",
    "    if col in numeric_cols_clean:\n",
    "        selected_numeric.append(col)\n",
    "    if len(selected_numeric) >= 3:\n",
    "        break\n",
    "\n",
    "# Completar com outras variáveis se necessário\n",
    "if len(selected_numeric) < 3:\n",
    "    for col in numeric_cols_clean:\n",
    "        if col not in selected_numeric and len(selected_numeric) < 3:\n",
    "            selected_numeric.append(col)\n",
    "\n",
    "print(f\"Variáveis numéricas selecionadas: {selected_numeric}\")\n",
    "print(f\"Variáveis categóricas disponíveis: {selected_categorical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59b695",
   "metadata": {},
   "source": [
    "## Análise Estatística das Relações Categórica vs Numérica\n",
    "\n",
    "Vamos examinar estatisticamente como as variáveis categóricas influenciam as distribuições das variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise estatística das relações entre variáveis categóricas e numéricas\n",
    "for cat_col in selected_categorical[:2]:  # Limitar a 2 categóricas para não sobrecarregar\n",
    "    for num_col in selected_numeric[:2]:  # Limitar a 2 numéricas por categórica\n",
    "        \n",
    "        print(f\"\\nANÁLISE: {num_col} por {cat_col}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Preparar dados removendo valores faltantes\n",
    "        temp_df = pd.DataFrame({\n",
    "            'categorical': X_train[cat_col],\n",
    "            'numerical': X_train[num_col],\n",
    "            'target': y_train\n",
    "        }).dropna()\n",
    "        \n",
    "        if len(temp_df) > 0:\n",
    "            print(f\"Amostras válidas para análise: {len(temp_df):,}\")\n",
    "            \n",
    "            # Estatísticas descritivas por categoria\n",
    "            stats_by_cat = temp_df.groupby('categorical')['numerical'].agg([\n",
    "                'count', 'mean', 'std', 'min', 'max', 'median'\n",
    "            ]).round(2)\n",
    "            \n",
    "            print(f\"\\nEstatísticas descritivas de {num_col} por {cat_col}:\")\n",
    "            display(stats_by_cat)\n",
    "            \n",
    "            # Estatísticas por categoria E target (sepsis)\n",
    "            stats_by_cat_target = temp_df.groupby(['categorical', 'target'])['numerical'].agg([\n",
    "                'count', 'mean', 'std'\n",
    "            ]).round(2)\n",
    "            \n",
    "            print(f\"\\nEstatísticas de {num_col} por {cat_col} e SepsisLabel:\")\n",
    "            display(stats_by_cat_target)\n",
    "            \n",
    "            # Teste estatístico para diferença de médias (se aplicável)\n",
    "            categories = temp_df['categorical'].unique()\n",
    "            if len(categories) == 2:\n",
    "                from scipy import stats\n",
    "                \n",
    "                group1 = temp_df[temp_df['categorical'] == categories[0]]['numerical']\n",
    "                group2 = temp_df[temp_df['categorical'] == categories[1]]['numerical']\n",
    "                \n",
    "                if len(group1) > 1 and len(group2) > 1:\n",
    "                    # Teste t para amostras independentes\n",
    "                    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "                    \n",
    "                    print(f\"\\nTeste t para diferença de médias entre categorias:\")\n",
    "                    print(f\"Estatística t: {t_stat:.4f}\")\n",
    "                    print(f\"P-valor: {p_value:.4f}\")\n",
    "                    \n",
    "                    alpha = 0.05\n",
    "                    if p_value < alpha:\n",
    "                        print(f\"Resultado: Diferença estatisticamente significativa (p < {alpha})\")\n",
    "                    else:\n",
    "                        print(f\"Resultado: Diferença não estatisticamente significativa (p >= {alpha})\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Dados insuficientes após remoção de valores faltantes.\")\n",
    "        \n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7c1f0",
   "metadata": {},
   "source": [
    "## Visualização das Relações Categórica vs Numérica\n",
    "\n",
    "Os boxplots nos permitem visualizar como as distribuições das variáveis numéricas variam entre as diferentes categorias, incluindo a presença de sepsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das relações entre variáveis categóricas e numéricas\n",
    "if selected_categorical and selected_numeric:\n",
    "    # Calcular número de combinações para subplot\n",
    "    n_combinations = min(4, len(selected_categorical) * len(selected_numeric))\n",
    "    \n",
    "    if n_combinations > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        combination_count = 0\n",
    "        \n",
    "        for cat_col in selected_categorical[:2]:  # Máximo 2 categóricas\n",
    "            for num_col in selected_numeric[:2]:  # 2 numéricas por categórica\n",
    "                if combination_count >= n_combinations:\n",
    "                    break\n",
    "                \n",
    "                # Preparar dados removendo valores faltantes\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'categorical': X_train[cat_col],\n",
    "                    'numerical': X_train[num_col],\n",
    "                    'target': y_train\n",
    "                }).dropna()\n",
    "                \n",
    "                if len(temp_df) > 0:\n",
    "                    ax = axes[combination_count]\n",
    "                    \n",
    "                    # Criar boxplot com separação por target\n",
    "                    sns.boxplot(data=temp_df, x='categorical', y='numerical', \n",
    "                               hue='target', ax=ax, palette=['#3498db', '#e74c3c'])\n",
    "                    \n",
    "                    ax.set_title(f'{num_col} por {cat_col} e SepsisLabel', fontsize=12, pad=15)\n",
    "                    ax.set_xlabel(cat_col)\n",
    "                    ax.set_ylabel(num_col)\n",
    "                    ax.tick_params(axis='x', rotation=45)\n",
    "                    \n",
    "                    # Configurar legenda\n",
    "                    handles, labels = ax.get_legend_handles_labels()\n",
    "                    ax.legend(handles, ['Não-Sepsis', 'Sepsis'], title='SepsisLabel')\n",
    "                    \n",
    "                    # Adicionar informação sobre o tamanho da amostra\n",
    "                    n_points = len(temp_df)\n",
    "                    ax.text(0.02, 0.98, f'n = {n_points:,}', transform=ax.transAxes, \n",
    "                           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "                \n",
    "                combination_count += 1\n",
    "        \n",
    "        # Remover subplots vazios\n",
    "        for i in range(combination_count, len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"Combinações insuficientes para visualização.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Variáveis insuficientes para análise de relações.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f630d",
   "metadata": {},
   "source": [
    "## Conclusões da Análise Exploratória\n",
    "\n",
    "Vamos consolidar os principais insights obtidos durante nossa análise exploratória e suas implicações para o desenvolvimento de modelos preditivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidação dos principais insights da análise exploratória\n",
    "print(\"RESUMO EXECUTIVO DA ANÁLISE EXPLORATÓRIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. ESTRUTURA DO DATASET\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"   • Dimensões: {train_df.shape[0]:,} amostras x {train_df.shape[1]} features\")\n",
    "print(f\"   • Tamanho em memória: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"   • Duplicatas: {train_df.duplicated().sum()} linhas\")\n",
    "\n",
    "print(f\"\\n2. DISTRIBUIÇÃO DO TARGET\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"   • Não-Sepsis: {target_counts[0]:,} ({target_pct[0]:.2f}%)\")\n",
    "print(f\"   • Sepsis: {target_counts[1]:,} ({target_pct[1]:.2f}%)\")\n",
    "print(f\"   • Razão de desbalanceamento: {imbalance_ratio:.1f}:1\")\n",
    "print(f\"   • Classificação: {'Altamente desbalanceado' if imbalance_ratio > 10 else 'Moderadamente desbalanceado'}\")\n",
    "\n",
    "print(f\"\\n3. QUALIDADE DOS DADOS\")\n",
    "print(\"-\" * 30)\n",
    "if len(missing_with_nans) > 0:\n",
    "    print(f\"   • Colunas com missing values: {len(missing_with_nans)}/{len(X_train.columns)}\")\n",
    "    print(f\"   • Total de valores faltantes: {missing_count.sum():,}\")\n",
    "    print(f\"   • Porcentagem do dataset: {(missing_count.sum() / (len(X_train) * len(X_train.columns)))*100:.2f}%\")\n",
    "    \n",
    "    # Categorização dos missing values\n",
    "    low_missing = missing_with_nans[missing_with_nans['Porcentagem'] < 20]\n",
    "    medium_missing = missing_with_nans[(missing_with_nans['Porcentagem'] >= 20) & \n",
    "                                      (missing_with_nans['Porcentagem'] < 80)]\n",
    "    high_missing = missing_with_nans[missing_with_nans['Porcentagem'] >= 80]\n",
    "    \n",
    "    print(f\"   • Baixo missing (<20%): {len(low_missing)} colunas\")\n",
    "    print(f\"   • Médio missing (20-80%): {len(medium_missing)} colunas\")\n",
    "    print(f\"   • Alto missing (≥80%): {len(high_missing)} colunas\")\n",
    "else:\n",
    "    print(f\"   • Dataset sem valores faltantes\")\n",
    "\n",
    "print(f\"\\n4. ANÁLISE UNIVARIADA\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"   • Variáveis numéricas analisadas: {len(low_missing_cols) if 'low_missing_cols' in locals() else 'N/A'}\")\n",
    "print(f\"   • Distribuição do target: Altamente desbalanceada\")\n",
    "print(f\"   • Assimetria identificada em múltiplas variáveis\")\n",
    "print(f\"   • Outliers detectados em várias features\")\n",
    "\n",
    "print(f\"\\n5. ANÁLISE BIVARIADA\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"   • Pair plots revelaram relações entre variáveis\")\n",
    "print(f\"   • Box plots mostraram diferenças de distribuição entre classes\")\n",
    "print(f\"   • Potencial discriminativo identificado em múltiplas features\")\n",
    "\n",
    "print(f\"\\n6. ANÁLISE MULTIVARIADA\")\n",
    "print(\"-\" * 30)\n",
    "if 'correlation_matrix' in locals():\n",
    "    high_corr_count = len([pair for pair in corr_pairs_sorted if abs(pair[2]) > 0.8]) if 'corr_pairs_sorted' in locals() else 0\n",
    "    print(f\"   • Matriz de correlação gerada com {len(correlation_vars)} variáveis\")\n",
    "    print(f\"   • Correlações muito altas (>0.8): {high_corr_count} pares\")\n",
    "    print(f\"   • Potencial multicolinearidade {'detectada' if high_corr_count > 0 else 'não detectada'}\")\n",
    "else:\n",
    "    print(f\"   • Análise de correlação executada\")\n",
    "\n",
    "print(f\"\\n7. VARIÁVEIS CATEGÓRICAS\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"   • Variáveis identificadas: {len(selected_categorical) if 'selected_categorical' in locals() else 'N/A'}\")\n",
    "print(f\"   • Variáveis analisadas: {selected_categorical if 'selected_categorical' in locals() else 'N/A'}\")\n",
    "\n",
    "print(f\"\\n8. RECOMENDAÇÕES PARA MODELAGEM\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"   • Tratar desbalanceamento de classes (SMOTE, class_weight)\")\n",
    "print(f\"   • Estratégia de imputação para missing values\")\n",
    "print(f\"   • Normalização/padronização das features\")\n",
    "print(f\"   • Feature selection para reduzir dimensionalidade\")\n",
    "print(f\"   • Validação cruzada estratificada\")\n",
    "print(f\"   • Métricas adequadas: AUC-ROC, F1-Score, Precision-Recall\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
