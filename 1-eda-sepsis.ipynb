{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6713f917",
   "metadata": {
    "id": "6713f917"
   },
   "source": [
    "## Análise Exploratória de Dados (EDA) - Dataset de Sepsis\n",
    "\n",
    "**Objetivo da Análise**\n",
    "\n",
    "* Compreender a estrutura e qualidade dos dados\n",
    "* Analisar padrões de valores faltantes\n",
    "* Identificar relações entre variáveis e a ocorrência de sepsis\n",
    "* Gerar insights para construção de modelos preditivos\n",
    "\n",
    "**Sobre o Dataset**\n",
    "\n",
    "* **Problema**: Detecção precoce de sepsis em pacientes de UTI\n",
    "* **Tipo**: Classificação binária (Sepsis vs Não-Sepsis)\n",
    "* **Características**: Dados de sinais vitais, exames laboratoriais e informações demográficas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OT_NdejDKz1-",
   "metadata": {
    "id": "OT_NdejDKz1-"
   },
   "source": [
    "## Acessando o dataset de treino do Drive\n",
    "\n",
    "Para funcionar no Google Colab, é necessário criar um atalho do diretório MDA no seu próprio Drive e então rodar os dois comandos abaixo e conceder permissão ao seu drive quando rodar a célula logo abaixo.\n",
    "\n",
    "[Link](https://towardsdatascience.com/simplify-file-sharing-44bde79a8a18/) detalhando como funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zCS0TNb58jYK",
   "metadata": {
    "id": "zCS0TNb58jYK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iZlrBv4VHB_8",
   "metadata": {
    "id": "iZlrBv4VHB_8"
   },
   "outputs": [],
   "source": [
    "# modificar para o diretorio que contém os dados de teste e treino\n",
    "%cd /content/drive/MyDrive/MDA/Train\\ and\\ test\\ data\\ -\\ Proj\\ DM/\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QqkyN-Z-QNBj",
   "metadata": {
    "id": "QqkyN-Z-QNBj"
   },
   "source": [
    "Se carregado corretamente o output de\n",
    "\n",
    "```\n",
    "!ls\n",
    "```\n",
    "\n",
    " mostrará os arquivos de teste e treino:\n",
    "\n",
    "dataset_sepsis_test.csv  dataset_sepsis_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457206f",
   "metadata": {
    "id": "5457206f"
   },
   "source": [
    "## 1.Importação das Bibliotecas\n",
    "\n",
    "Primeiro, vamos importar todas as bibliotecas necessárias para nossa análise exploratória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3eae8",
   "metadata": {
    "id": "88f3eae8"
   },
   "outputs": [],
   "source": [
    "# Importação das bibliotecas essenciais para análise exploratória\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configurações para otimizar as visualizações\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c51c3",
   "metadata": {
    "id": "676c51c3"
   },
   "source": [
    "## 2.Carregamento e Descrição da Estrutura e Qualidade do Dataset\n",
    "\n",
    "Nesta seção, carregamos o dataset de treino e analisamos suas características básicas para compreender a estrutura dos dados e identificar possíveis problemas de qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e0798",
   "metadata": {
    "id": "bb2e0798"
   },
   "outputs": [],
   "source": [
    "# Carregamento do dataset de treino\n",
    "train_df = pd.read_csv('dataset_sepsis_train.csv')\n",
    "\n",
    "# Análise da estrutura básica do dataset\n",
    "print(\"INFORMAÇÕES GERAIS DO DATASET\\n\")\n",
    "print(f\"Dimensões do dataset (shape): {train_df.shape}\")\n",
    "print(f\"Número de amostras: {train_df.shape[0]:,}\")\n",
    "print(f\"Número de features: {train_df.shape[1]}\")\n",
    "print(f\"Tamanho em memória: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nINFORMAÇÕES DETALHADAS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "# Usar info() para mostrar tipos de dados e valores não-nulos\n",
    "train_df.info()\n",
    "\n",
    "print(f\"\\nESTATÍSTICAS DESCRITIVAS (TRANSPOSTAS)\")\n",
    "print(\"=\" * 50)\n",
    "# Mostrar estatísticas descritivas transpostas para melhor visualização\n",
    "display(train_df.describe().T)\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(f\"\\nPRIMEIRAS 5 LINHAS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cacb5",
   "metadata": {
    "id": "558cacb5"
   },
   "source": [
    "### 2.1 Análise de Valores Faltantes\n",
    "\n",
    "A análise sistemática de valores faltantes é essencial para identificar padrões de missings e definir estratégias de tratamento adequadas. Esta análise nos permite entender se os dados faltam de forma aleatória ou seguem algum padrão específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b704f75",
   "metadata": {},
   "source": [
    "#### 2.1.1 Análise Verbosa de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d758a",
   "metadata": {
    "id": "755d758a"
   },
   "outputs": [],
   "source": [
    "# Análise quantitativa dos valores faltantes\n",
    "missing_count = train_df.isnull().sum()\n",
    "missing_pct = (missing_count / len(train_df)) * 100\n",
    "\n",
    "# Criar DataFrame para análise organizada\n",
    "missing_df = pd.DataFrame({\n",
    "    'Coluna': missing_count.index,\n",
    "    'Valores_Faltantes': missing_count.values,\n",
    "    'Porcentagem': missing_pct.values\n",
    "}).sort_values('Porcentagem', ascending=False)\n",
    "\n",
    "# Estatísticas gerais\n",
    "total_samples = len(train_df)\n",
    "mean_missing = missing_pct.mean()\n",
    "vars_with_missing = (missing_count > 0).sum()\n",
    "total_vars = len(missing_count)\n",
    "\n",
    "print(\"ANÁLISE DE VALORES FALTANTES\\n\")\n",
    "print(f\"Total de amostras: {total_samples:,}\")\n",
    "print(f\"Total de variáveis: {total_vars}\")\n",
    "print(f\"Variáveis com missing values: {vars_with_missing}\")\n",
    "print(f\"Percentual médio de missing values: {mean_missing:.3f}%\")\n",
    "\n",
    "print(f\"\\nTOP 10 VARIÁVEIS COM MAIS MISSING VALUES:\")\n",
    "top_10_missing = missing_df.head(10)\n",
    "display(top_10_missing)\n",
    "\n",
    "# Categorização por nível de missing\n",
    "very_high = missing_df[missing_df['Porcentagem'] > 50]\n",
    "high_missing = missing_df[(missing_df['Porcentagem'] > 20) & (missing_df['Porcentagem'] <= 50)]\n",
    "medium_missing = missing_df[(missing_df['Porcentagem'] > 5) & (missing_df['Porcentagem'] <= 20)]\n",
    "low_missing = missing_df[(missing_df['Porcentagem'] > 0) & (missing_df['Porcentagem'] <= 5)]\n",
    "\n",
    "print(f\"\\nCATEGORIZAÇÃO POR NÍVEL DE MISSING:\\n\")\n",
    "print(f\"Muito Alto (>50%): {len(very_high)} variáveis\")\n",
    "print(f\"Alto (20-50%): {len(high_missing)} variáveis\")\n",
    "print(f\"Médio (5-20%): {len(medium_missing)} variáveis\")\n",
    "print(f\"Baixo (0-5%): {len(low_missing)} variáveis\")\n",
    "print(f\"Sem missing: {len(missing_df[missing_df['Porcentagem'] == 0])} variáveis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2046f3",
   "metadata": {
    "id": "9c2046f3"
   },
   "source": [
    "#### 2.1.2 Visualização dos Padrões de Missing Values\n",
    "\n",
    "A visualização dos padrões de valores faltantes nos ajuda a identificar se existe alguma estrutura nos dados ausentes e a definir estratégias de tratamento mais eficazes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee376ddc",
   "metadata": {
    "id": "ee376ddc"
   },
   "outputs": [],
   "source": [
    "# Filtrar apenas variáveis com missing values para visualização\n",
    "missing_with_nans = missing_df[missing_df['Porcentagem'] > 0]\n",
    "\n",
    "# Configurar subplots - 2 gráficos principais\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "# 1. Gráfico de barras horizontais - TODAS as colunas com missing values\n",
    "# Preparar dados para o seaborn barplot\n",
    "missing_sorted = missing_with_nans.sort_values('Porcentagem', ascending=True)  # Crescente para barras horizontais\n",
    "\n",
    "# Criar gráfico de barras horizontais usando seaborn\n",
    "sns.barplot(\n",
    "    x=missing_sorted['Porcentagem'],\n",
    "    y=missing_sorted['Coluna'],\n",
    "    orient='h',\n",
    "    palette='rocket_r',  # Paleta de cores\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "# Configurar títulos e labels\n",
    "axes[0].set_title(f'Percentual de Valores Nulos (NaNs) por Coluna\\n({len(missing_sorted)} variáveis com dados ausentes)',\n",
    "                    fontsize=14, pad=20)\n",
    "axes[0].set_xlabel('Percentual (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Colunas do Dataset', fontsize=12)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, (idx, row) in enumerate(missing_sorted.iterrows()):\n",
    "    pct = row['Porcentagem']\n",
    "    axes[0].text(pct + 1, i, f'{pct:.1f}%',\n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Adicionar linhas de referência\n",
    "axes[0].axvline(20, color='orange', linestyle='--', alpha=0.8, label='20% (Baixo)')\n",
    "axes[0].axvline(80, color='red', linestyle='--', alpha=0.8, label='80% (Alto)')\n",
    "axes[0].legend(loc='upper right')\n",
    "\n",
    "# Configurar grid e limites\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "axes[0].set_xlim(0, 105)\n",
    "\n",
    "# 2. Histograma da distribuição de missing values (mais segmentado)\n",
    "# Criar bins de 10 em 10\n",
    "bins = range(0, 101, 10)\n",
    "\n",
    "axes[1].hist(missing_with_nans['Porcentagem'], bins=bins, alpha=0.7,\n",
    "            color='#34495e', edgecolor='black', rwidth=0.8)\n",
    "\n",
    "axes[1].set_xlabel('Percentual de Missing Values (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Número de Variáveis', fontsize=12)\n",
    "axes[1].set_title('Distribuição de Missing Values por Faixa', fontsize=14, pad=20)\n",
    "\n",
    "# Configurar eixo X\n",
    "axes[1].set_xticks(bins)\n",
    "axes[1].set_xlim(0, 100)\n",
    "\n",
    "# Adicionar linha vertical para a média\n",
    "mean_missing = missing_with_nans['Porcentagem'].mean()\n",
    "axes[1].axvline(mean_missing, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Média: {mean_missing:.1f}%')\n",
    "axes[1].legend()\n",
    "\n",
    "# Configurar grid\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionar anotações no histograma\n",
    "counts, bins_edges = np.histogram(missing_with_nans['Porcentagem'], bins=bins)\n",
    "for i, count in enumerate(counts):\n",
    "    if count > 0:\n",
    "        bin_center = (bins_edges[i] + bins_edges[i+1]) / 2\n",
    "        axes[1].text(bin_center, count + max(counts)*0.01, str(count),\n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nEstatísticas descritivas dos missing values:\")\n",
    "print(f\"  • Média: {missing_with_nans['Porcentagem'].mean():.1f}%\")\n",
    "print(f\"  • Mediana: {missing_with_nans['Porcentagem'].median():.1f}%\")\n",
    "print(f\"  • Desvio padrão: {missing_with_nans['Porcentagem'].std():.1f}%\")\n",
    "print(f\"  • Mínimo: {missing_with_nans['Porcentagem'].min():.1f}%\")\n",
    "print(f\"  • Máximo: {missing_with_nans['Porcentagem'].max():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79778e58",
   "metadata": {
    "id": "79778e58"
   },
   "source": [
    "Estratégias de tratamento possíveis por faixa de valores faltantes\n",
    "\n",
    "- Muito baixo/Baixo (<20%): Imputação simples (mediana/moda)\n",
    "- Médio (20-50%): Imputação específica por domínio clínico ()\n",
    "- Alto (50-80%): Considerar remoção ou imputação avançada\n",
    "- Muito alto (≥80%): Forte candidato à remoção. Chance de tratamento se estiver associado a muitas instâncias de SepsisLabel=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97d5c8",
   "metadata": {
    "id": "da97d5c8"
   },
   "source": [
    "#### 2.1.3 Visualização de Outliers e Inconsistências\n",
    "\n",
    "Baseando-se nas estatísticas descritivas, vamos identificar e visualizar variáveis com potenciais problemas de qualidade dos dados, incluindo outliers extremos e valores inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269740b",
   "metadata": {
    "id": "e269740b"
   },
   "outputs": [],
   "source": [
    "# Análise de outliers e inconsistências baseada nas estatísticas descritivas\n",
    "# Obter estatísticas descritivas apenas para variáveis numéricas (excluindo SepsisLabel)\n",
    "numerical_vars = train_df.select_dtypes(include=[np.number]).columns\n",
    "numerical_vars = numerical_vars.drop('SepsisLabel')  # Remover a variável target\n",
    "\n",
    "\n",
    "# Criar boxplot para visualizar distribuições e outliers\n",
    "# Como temos muitas variáveis, vamos fazer um gráfico grande com subplots\n",
    "n_vars = len(numerical_vars)\n",
    "n_cols = 4  # 4 gráficos por linha\n",
    "n_rows = (n_vars + n_cols - 1) // n_cols  # Arredondar para cima\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten() if n_vars > 1 else [axes]\n",
    "\n",
    "for i, var in enumerate(numerical_vars):\n",
    "    # Criar boxplot para cada variável\n",
    "    data = train_df[var].dropna()\n",
    "\n",
    "    if len(data) > 0:\n",
    "        axes[i].boxplot(data, patch_artist=True,\n",
    "                       boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                       medianprops=dict(color='red', linewidth=2),\n",
    "                       flierprops=dict(marker='o', markerfacecolor='red', markersize=2, alpha=0.5))\n",
    "\n",
    "        axes[i].set_title(f'{var}\\n(n={len(data):,})', fontsize=10, pad=10)\n",
    "        axes[i].set_ylabel('Valores')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "        # Adicionar estatísticas básicas no gráfico\n",
    "        stats_text = f'Min: {data.min():.2f}\\nMédia: {data.mean():.2f}\\nMax: {data.max():.2f}'\n",
    "        axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes,\n",
    "                    fontsize=8, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, 'Sem dados\\nválidos',\n",
    "                    transform=axes[i].transAxes, ha='center', va='center')\n",
    "        axes[i].set_title(var, fontsize=10)\n",
    "\n",
    "# Remover subplots extras se houver\n",
    "for i in range(n_vars, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3c0c1",
   "metadata": {
    "id": "8dc3c0c1"
   },
   "source": [
    "### 2.2 Estrutura Temporal dos Dados\n",
    "\n",
    "Um aspecto fundamental para compreender este dataset é que **cada linha não representa um paciente único**, mas sim um **momento específico no tempo** para diferentes pacientes. O dataset é uma coleção de séries temporais clínicas onde múltiplas observações são registradas para cada paciente ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ca8cd",
   "metadata": {},
   "source": [
    "#### 2.2.1 Análise Verbosa das Frequências de Coleta por Paciente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdfe0e",
   "metadata": {
    "id": "2abdfe0e"
   },
   "outputs": [],
   "source": [
    "patient_id_cols = [col for col in train_df.columns if 'patient' in col.lower() or 'id' in col.lower()]\n",
    "print(f\"Colunas que podem ser ID do paciente: {patient_id_cols}\")\n",
    "\n",
    "print(f\"\\nDIMENSÕES DO DATASET:\")\n",
    "print(f\"   Total de observações (linhas): {len(train_df):,}\")\n",
    "print(f\"   Total de variáveis (colunas): {len(train_df.columns)}\")\n",
    "\n",
    "print(f\"\\nVARIÁVEIS TEMPORAIS IDENTIFICADAS:\")\n",
    "\n",
    "# Análise da variável Hour\n",
    "hour_non_null = train_df['Hour'].notna().sum()\n",
    "hour_unique = train_df['Hour'].nunique()\n",
    "hour_min = train_df['Hour'].min()\n",
    "hour_max = train_df['Hour'].max()\n",
    "\n",
    "print(f\"\\n   Hour:\")\n",
    "print(f\"      Observações válidas: {hour_non_null:,}\")\n",
    "print(f\"      Valores únicos: {hour_unique:,}\")\n",
    "print(f\"      Range: {hour_min:.2f} - {hour_max:.2f} horas\")\n",
    "print(f\"      Interpretação: Horas desde admissão na UTI\")\n",
    "print(f\"      Máximo: {hour_max/24:.1f} dias na UTI\")\n",
    "\n",
    "# Análise da variável HospAdmTime\n",
    "hospadm_non_null = train_df['HospAdmTime'].notna().sum()\n",
    "hospadm_unique = train_df['HospAdmTime'].nunique()\n",
    "hospadm_min = train_df['HospAdmTime'].min()\n",
    "hospadm_max = train_df['HospAdmTime'].max()\n",
    "\n",
    "print(f\"\\n   HospAdmTime:\")\n",
    "print(f\"      Observações válidas: {hospadm_non_null:,}\")\n",
    "print(f\"      Valores únicos: {hospadm_unique:,}\")\n",
    "print(f\"      Range: {hospadm_min:.2f} - {hospadm_max:.2f} horas\")\n",
    "print(f\"      Interpretação: Tempo de internação hospitalar\")\n",
    "print(f\"      Máximo: {hospadm_max:.1f} horas para ser admitido na UTI depois de ser admitido no hospital\")\n",
    "\n",
    "# Estimativa de pacientes únicos usando características demográficas\n",
    "demographic_cols = ['Age', 'Gender', 'Unit1', 'Unit2']\n",
    "print(f\"\\nESTIMATIVA DE PACIENTES ÚNICOS:\")\n",
    "print(f\"   (Baseada em combinação de: {', '.join(demographic_cols)})\")\n",
    "\n",
    "demo_combination = train_df[demographic_cols].fillna('Unknown')\n",
    "demo_string = demo_combination.astype(str).agg('_'.join, axis=1)\n",
    "unique_combinations = demo_string.nunique()\n",
    "\n",
    "print(f\"   Combinações únicas de características: {unique_combinations:,}\")\n",
    "print(f\"   Observações por combinação (média): {len(train_df) / unique_combinations:.1f}\")\n",
    "\n",
    "combo_counts = demo_string.value_counts()\n",
    "print(f\"\\n   DISTRIBUIÇÃO DE OBSERVAÇÕES:\")\n",
    "print(f\"      Min observações por paciente: {combo_counts.min()}\")\n",
    "print(f\"      Max observações por paciente: {combo_counts.max()}\")\n",
    "print(f\"      Mediana observações por paciente: {combo_counts.median():.0f}\")\n",
    "print(f\"      Média observações por paciente: {combo_counts.mean():.1f}\")\n",
    "\n",
    "# Padrão temporal das observações\n",
    "print(f\"\\nPADRÃO TEMPORAL DAS OBSERVAÇÕES:\")\n",
    "\n",
    "hour_dist = train_df['Hour'].value_counts().sort_index()\n",
    "print(f\"   Horas com mais observações:\")\n",
    "top_hours = hour_dist.head(5)\n",
    "for hour, count in top_hours.items():\n",
    "    print(f\"      Hora {hour:.0f}: {count:,} observações ({count/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "unique_hours = train_df['Hour'].nunique()\n",
    "\n",
    "print(f\"   Frequência média de coleta: {len(train_df) / unique_hours:.1f} pacientes por momento\")\n",
    "print(f\"\\n   Total de momentos temporais únicos: {unique_hours:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0986e",
   "metadata": {
    "id": "96d0986e"
   },
   "source": [
    "**Implicações para a análise:**\n",
    "\n",
    "As análises devem considerar a dependência temporal, pois pacientes podem ter múltiplas observações ao longo do tempo e a variável target (SepsisLabel) pode mudar ao longo do tempo para o mesmo paciente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6c02b",
   "metadata": {},
   "source": [
    "#### 2.2.2 Visualização das Distribuições pela Variável Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7599ae3",
   "metadata": {
    "id": "a7599ae3"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribuição das observações por hora\n",
    "hour_counts = train_df['Hour'].value_counts().sort_index()\n",
    "axes[0,0].plot(hour_counts.index, hour_counts.values, marker='o', linewidth=2, markersize=4)\n",
    "axes[0,0].set_title('Distribuição de Observações por Hora', fontsize=12)\n",
    "axes[0,0].set_xlabel('Horas desde admissão na UTI até a observação de dados clínicos')\n",
    "axes[0,0].set_ylabel('Número de observações')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Boxplot da distribuição de horas\n",
    "axes[0,1].boxplot(train_df['Hour'].dropna(), patch_artist=True,\n",
    "                 boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "axes[0,1].set_title('Distribuição das Horas de Observação', fontsize=12)\n",
    "axes[0,1].set_ylabel('Horas')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Distribuição de SepsisLabel ao longo do tempo\n",
    "sepsis_by_hour = train_df.groupby('Hour')['SepsisLabel'].agg(['count', 'sum']).reset_index()\n",
    "sepsis_by_hour['sepsis_rate'] = sepsis_by_hour['sum'] / sepsis_by_hour['count'] * 100\n",
    "\n",
    "# Filtrar apenas horas com pelo menos 100 observações para estabilidade\n",
    "stable_hours = sepsis_by_hour[sepsis_by_hour['count'] >= 100]\n",
    "\n",
    "axes[1,0].plot(stable_hours['Hour'], stable_hours['sepsis_rate'],\n",
    "              marker='o', linewidth=2, markersize=4, color='red')\n",
    "axes[1,0].set_title('Taxa de Sepsis ao Longo do Tempo', fontsize=12)\n",
    "axes[1,0].set_xlabel('Horas desde admissão na UTI até a observação de dados clínicos')\n",
    "axes[1,0].set_ylabel('Taxa de Sepsis (%)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histograma do número de observações por paciente estimado\n",
    "demo_combination = train_df[demographic_cols].fillna('Unknown')\n",
    "demo_string = demo_combination.astype(str).agg('_'.join, axis=1)\n",
    "combo_counts = demo_string.value_counts()\n",
    "\n",
    "axes[1,1].hist(combo_counts.values, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1,1].set_title('Distribuição do Número de Observações\\npor Paciente Estimado', fontsize=12)\n",
    "axes[1,1].set_xlabel('Número de observações por paciente')\n",
    "axes[1,1].set_ylabel('Frequência')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar estatísticas no gráfico\n",
    "mean_obs = combo_counts.mean()\n",
    "median_obs = combo_counts.median()\n",
    "axes[1,1].axvline(mean_obs, color='red', linestyle='--',\n",
    "                 label=f'Média: {mean_obs:.1f}')\n",
    "axes[1,1].axvline(median_obs, color='orange', linestyle='--',\n",
    "                 label=f'Mediana: {median_obs:.0f}')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.suptitle('Estrutura Temporal do Dataset de Sepsis', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c65535",
   "metadata": {
    "id": "46c65535"
   },
   "source": [
    "#### 2.2.3 Interpretação dos Gráficos sobre a Variável Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d767b14",
   "metadata": {},
   "source": [
    "**1. Distribuição de Observações por Hora (Superior Esquerdo)**\n",
    "\n",
    "Este gráfico revela um padrão temporal crítico no dataset:\n",
    "\n",
    "- **Concentração inicial**: Há uma concentração massiva de observações nas primeiras horas após admissão na UTI (0-50 horas)\n",
    "- **Pico máximo**: Ocorre nas primeiras horas, com mais de 30.000 observações\n",
    "- **Declínio exponencial**: O número de observações diminui drasticamente após as primeiras 100 horas\n",
    "- **Cauda longa**: Alguns pacientes permanecem na UTI por até 300+ horas (12+ dias)\n",
    "\n",
    "**Implicação clínica**: A maioria dos pacientes tem estadia curta na UTI ou são transferidos/recebem alta rapidamente, enquanto uma minoria permanece por períodos prolongados.\n",
    "\n",
    "**2. Distribuição das Horas de Observação (Superior Direito)**\n",
    "\n",
    "O boxplot complementa a análise temporal:\n",
    "\n",
    "- **Mediana baixa**: A mediana está próxima a 25-30 horas, confirmando que metade dos pacientes tem observações concentradas no início\n",
    "- **Outliers extremos**: Existem casos com observações muito tardias (acima de 250 horas)\n",
    "- **IQR compacto**: O intervalo interquartil é relativamente pequeno, indicando que 75% das observações ocorrem nas primeiras ~50 horas\n",
    "- **Assimetria positiva**: A distribuição é fortemente enviesada para a direita\n",
    "\n",
    "**Interpretação**: O tempo de permanência na UTI segue um padrão típico de cuidados intensivos, com a maioria dos casos sendo resolvidos rapidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a7a43",
   "metadata": {
    "id": "6b3a7a43"
   },
   "source": [
    "**3. Taxa de Sepsis ao Longo do Tempo (Inferior Esquerdo)**\n",
    "\n",
    "Este é o gráfico mais clinicamente relevante, mostrando a evolução temporal do risco de sepsis:\n",
    "\n",
    "- **Período inicial de baixo risco**: Nas primeiras 50 horas, a taxa de sepsis permanece baixa (0-5%)\n",
    "- **Transição crítica**: Entre 50-100 horas, há um aumento gradual mas consistente na taxa de sepsis\n",
    "- **Pico de risco**: A partir de 100 horas, a taxa de sepsis aumenta significativamente, chegando a 15-20%\n",
    "- **Padrão progressivo**: O risco continua aumentando com o tempo de permanência\n",
    "\n",
    "**Significado clínico**:\n",
    "- Pacientes com internação prolongada têm risco progressivamente maior de desenvolver sepsis\n",
    "- O tempo de permanência é um **preditor temporal** importante para sepsis\n",
    "- Após 100 horas na UTI, o risco praticamente triplica\n",
    "\n",
    "**4. Distribuição do Número de Observações por Paciente Estimado (Inferior Direito)**\n",
    "\n",
    "Este histograma revela a estrutura longitudinal do dataset:\n",
    "\n",
    "- **Concentração em baixas contagens**: A maioria dos pacientes tem poucas observações (< 500)\n",
    "- **Distribuição assimétrica**: Distribuição com cauda longa à direita\n",
    "- **Mediana vs Média**: Mediana (36) muito menor que a média (83.2), confirmando assimetria\n",
    "- **Casos extremos**: Alguns pacientes têm mais de 3.000 observações\n",
    "\n",
    "**Interpretações importantes**:\n",
    "- **Heterogeneidade temporal**: Pacientes variam drasticamente no tempo de monitoramento\n",
    "- **Natureza longitudinal**: Confirma que cada paciente contribui com múltiplas observações\n",
    "- **Viés potencial**: Pacientes mais graves podem ter mais observações (mais tempo na UTI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8426b183",
   "metadata": {
    "id": "8426b183"
   },
   "source": [
    "#### 2.2.4 Síntese dos Insights sobre as Relações com Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82de31e",
   "metadata": {},
   "source": [
    "\n",
    "**Principais Descobertas:**\n",
    "\n",
    "1. **Padrão de Permanência na UTI**:\n",
    "   - 75% dos pacientes têm observações concentradas nas primeiras 75 horas\n",
    "   - Mediana de permanência: ~30 horas (1,25 dias)\n",
    "   - Casos extremos podem chegar a 300+ horas (12+ dias)\n",
    "\n",
    "2. **Relação Temporal com Sepsis**:\n",
    "   - **Janela de baixo risco**: Primeiras 50 horas (taxa < 5%)\n",
    "   - **Janela de transição**: 50-100 horas (aumento gradual)\n",
    "   - **Janela de alto risco**: >100 horas (taxa pode ultrapassar 15%)\n",
    "\n",
    "3. **Estrutura dos Dados**:\n",
    "   - Dataset é uma **coleção de séries temporais**, não registros únicos de pacientes\n",
    "   - Cada linha = um momento temporal para um paciente específico\n",
    "   - Variabilidade alta no número de observações por paciente (mediana: 36, máximo: >3000)\n",
    "\n",
    "**Implicações para Modelagem**:\n",
    "\n",
    "- **Dependência temporal**: Modelos devem considerar a sequência temporal das observações\n",
    "- **Feature temporal**: O tempo de permanência é um preditor importante\n",
    "- **Validação temporal**: Necessária validação que preserve a ordem temporal\n",
    "- **Threshold temporal**: Considerar diferentes estratégias para janelas temporais específicas\n",
    "\n",
    "**Relevância Clínica**:\n",
    "\n",
    "- O tempo de permanência prolongado na UTI está associado ao aumento progressivo do risco de sepsis\n",
    "- Pacientes que permanecem >100 horas na UTI constituem um grupo de alto risco que requer monitoramento intensificado\n",
    "- A detecção precoce de sepsis é mais crítica nos primeiros dias de internação, quando a taxa é naturalmente baixa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25813412",
   "metadata": {
    "id": "25813412"
   },
   "source": [
    "### 2.3 Separação de Features e Target\n",
    "\n",
    "Separamos a variável alvo (SepsisLabel) das features para facilitar as análises subsequentes. Essa separação é fundamental para a análise univariada e bivariada posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191cac4",
   "metadata": {
    "id": "e191cac4"
   },
   "outputs": [],
   "source": [
    "# Separação entre features (X) e variável target (y)\n",
    "X_train = train_df.drop('SepsisLabel', axis=1)\n",
    "y_train = train_df['SepsisLabel']\n",
    "\n",
    "# Mostrar valores únicos por coluna\n",
    "print(f\"\\nANÁLISE DE VALORES ÚNICOS POR COLUNA\")\n",
    "print(\"=\" * 50)\n",
    "unique_counts = train_df.nunique().sort_values(ascending=False)\n",
    "print(\"Valores únicos por coluna:\")\n",
    "display(unique_counts.to_frame('Valores_Únicos'))\n",
    "\n",
    "print(f\"\\nColunas com poucos valores únicos (potencialmente categóricas):\")\n",
    "few_unique = unique_counts[unique_counts <= 10]\n",
    "display(few_unique.to_frame('Valores_Únicos'))\n",
    "\n",
    "# Mostrar distribuição da variável target\n",
    "print(f\"\\nDISTRIBUIÇÃO DA VARIÁVEL TARGET\")\n",
    "print(\"=\" * 50)\n",
    "target_counts = y_train.value_counts().sort_index()\n",
    "target_pct = y_train.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "for label, count in target_counts.items():\n",
    "    pct = target_pct[label]\n",
    "    status = \"Não-Sepsis\" if label == 0 else \"Sepsis\"\n",
    "    print(f\"{status} ({label}): {count:,} amostras ({pct:.2f}%)\")\n",
    "\n",
    "# Calcular razão de desbalanceamento\n",
    "imbalance_ratio = target_counts[0] / target_counts[1]\n",
    "print(f\"\\nRazão de desbalanceamento: {imbalance_ratio:.1f}:1\")\n",
    "print(f\"Para cada caso de sepsis, existem {imbalance_ratio:.1f} casos de não-sepsis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73399d",
   "metadata": {
    "id": "5c73399d"
   },
   "source": [
    "#### 2.3.1 Visualização da Distribuição da Variável Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ee48d",
   "metadata": {
    "id": "131ee48d"
   },
   "outputs": [],
   "source": [
    "# Visualização da distribuição da variável target\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Gráfico 1: Contagem absoluta\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar(['Não-Sepsis', 'Sepsis'], target_counts.values,\n",
    "               color=['#3498db', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
    "plt.title('Distribuição Absoluta das Classes', fontsize=14, pad=20)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, count in zip(bars, target_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(target_counts)*0.01,\n",
    "            f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico 2: Gráfico de pizza\n",
    "plt.subplot(1, 2, 2)\n",
    "wedges, texts, autotexts = plt.pie(target_pct.values,\n",
    "                                  labels=['Não-Sepsis', 'Sepsis'],\n",
    "                                  autopct='%1.2f%%',\n",
    "                                  colors=['#3498db', '#e74c3c'],\n",
    "                                  startangle=90,\n",
    "                                  explode=(0, 0.1))\n",
    "plt.title('Proporção das Classes', fontsize=14, pad=20)\n",
    "\n",
    "# Melhorar formatação dos rótulos\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1d6bb",
   "metadata": {
    "id": "5ff1d6bb"
   },
   "source": [
    "Podemos ver que o dataset está altamente desbalanceado. Precisaremos tomar alguns cuidados na fase de avaliação e amostragem:\n",
    "- Utilizar métricas adequadas (F1-Score, AUC-ROC, Precision-Recall)\n",
    "- Aplicar técnicas de balanceamento (SMOTE, undersampling)\n",
    "- Configurar class_weight nos algoritmos de ML\n",
    "- Considerar threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5f39b",
   "metadata": {},
   "source": [
    "#### 2.3.2 Identificação e Remoção de Linhas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se há duplicatas no dataset\n",
    "duplicates = train_df.duplicated().sum()\n",
    "print(f\"\\nLinhas duplicadas: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    train_df = train_df.drop_duplicates()\n",
    "    print(f\"Linhas duplicadas removidas. Novo shape do dataset: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93f3d9",
   "metadata": {
    "id": "5f93f3d9"
   },
   "source": [
    "## 3.Análise Univariada Detalhada\n",
    "\n",
    "A análise univariada examina cada variável individualmente para compreender suas distribuições, identificar outliers e avaliar características estatísticas importantes como assimetria e curtose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85773b",
   "metadata": {},
   "source": [
    "### 3.1 Distribuições de Principais Sinais Vitais e Biomarcadores\n",
    "\n",
    "Análise das distribuições das variáveis clínicas mais importantes para detecção de sepsis, incluindo sinais vitais, parâmetros de oxigenação e biomarcadores laboratoriais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105af6e",
   "metadata": {},
   "source": [
    "**Legenda para as Cores de Fundo:**\n",
    "\n",
    "- Verde claro: Distribuição aproximadamente normal (|skewness| < 0.5)\n",
    "- Amarelo claro: Moderadamente assimétrica (0.5 ≤ |skewness| ≤ 1.0)\n",
    "- Vermelho claro: Fortemente assimétrica (|skewness| > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise univariada focada em variáveis clínicas importantes para sepsis\n",
    "\n",
    "# Definir variáveis clínicas prioritárias\n",
    "clinical_vars = ['DBP', 'Resp', 'WBC', 'Lactate', 'Creatinine', 'BUN', \n",
    "                 'Platelets', 'Glucose', 'SaO2', 'FiO2', 'Age']\n",
    "\n",
    "# Selecionar 9 para visualização (3x3 grid)\n",
    "priority_vars = clinical_vars[:9]\n",
    "\n",
    "# Criar grid 3x3 para histogramas com KDE\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, var in enumerate(priority_vars):\n",
    "    if idx < len(axes):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Dados válidos (sem NaN)\n",
    "        data = X_train[var].dropna()\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            # Histograma com KDE\n",
    "            sns.histplot(data, kde=True, alpha=0.7, color='steelblue', ax=ax)\n",
    "            \n",
    "            # Calcular estatísticas\n",
    "            mean_val = data.mean()\n",
    "            median_val = data.median()\n",
    "            skewness = data.skew()\n",
    "            \n",
    "            # Adicionar linhas de referência\n",
    "            ax.axvline(mean_val, color='red', linestyle='--', alpha=0.8, label=f'Média: {mean_val:.1f}')\n",
    "            ax.axvline(median_val, color='orange', linestyle='--', alpha=0.8, label=f'Mediana: {median_val:.1f}')\n",
    "            \n",
    "            # Título e labels\n",
    "            ax.set_title(f'{var}\\nSkewness: {skewness:.2f} | n={len(data):,}', fontsize=12, pad=10)\n",
    "            ax.set_xlabel(var)\n",
    "            ax.set_ylabel('Frequência')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Análise de normalidade visual\n",
    "            if abs(skewness) > 1:\n",
    "                skew_interpretation = \"Assimétrica\"\n",
    "                ax.set_facecolor('#fff2f2')  # Fundo levemente vermelho para alta assimetria\n",
    "            elif abs(skewness) < 0.5:\n",
    "                skew_interpretation = \"~Normal\"\n",
    "                ax.set_facecolor('#f2fff2')  # Fundo levemente verde para distribuição normal\n",
    "            else:\n",
    "                skew_interpretation = \"Mod. Assim.\"\n",
    "                ax.set_facecolor('#fffff2')  # Fundo levemente amarelo para assimetria moderada\n",
    "        \n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'{var}\\nSem dados válidos', transform=ax.transAxes, \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.set_title(var)\n",
    "\n",
    "# Remover subplots vazios\n",
    "for idx in range(len(priority_vars), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.suptitle('Distribuições das Principais Variáveis Clínicas\\n(Cores de fundo indicam normalidade da distribuição)', \n",
    "             fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAssimetria das {len(priority_vars)} variáveis analisadas:\")\n",
    "for col in priority_vars:\n",
    "    skew_val = X_train[col].skew()\n",
    "    if skew_val > 1:\n",
    "        interpretation = \"Fortemente assimétrica à direita\"\n",
    "    elif skew_val < -1:\n",
    "        interpretation = \"Fortemente assimétrica à esquerda\"\n",
    "    elif abs(skew_val) < 0.5:\n",
    "        interpretation = \"Aproximadamente simétrica\"\n",
    "    else:\n",
    "        interpretation = \"Moderadamente assimétrica\"\n",
    "\n",
    "    print(f\"  {col}: {skew_val:.2f} ({interpretation})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5e8c3",
   "metadata": {},
   "source": [
    "**Padrões de Distribuição Observados**\n",
    "\n",
    "A análise univariada das principais variáveis clínicas revela características importantes sobre a natureza dos dados de sepsis:\n",
    "\n",
    "**1. Predominância de Distribuições Assimétricas:**\n",
    "- A maioria das variáveis clínicas apresenta **assimetria positiva** (cauda à direita)\n",
    "- Este padrão é **esperado em dados médicos**, onde valores extremos elevados são clinicamente significativos\n",
    "- Variáveis como biomarcadores laboratoriais tendem a ter poucos casos com valores muito altos (pacientes críticos)\n",
    "\n",
    "**2. Qualidade dos Dados:**\n",
    "- Variabilidade significativa na **completude dos dados** entre diferentes variáveis\n",
    "- Parâmetros de sinais vitais geralmente apresentam **maior completude** (coleta rotineira)\n",
    "- Exames laboratoriais específicos podem ter **maior percentual de missing values** (coleta sob demanda)\n",
    "\n",
    "**3. Implicações Clínicas das Distribuições:**\n",
    "- **Distribuições normais** (fundo verde): Indicam parâmetros com comportamento fisiológico regular\n",
    "- **Distribuições assimétricas** (fundo vermelho/amarelo): Sugerem presença de:\n",
    "  - Valores de referência com limite inferior natural (ex: 0 para muitos biomarcadores)\n",
    "  - Casos extremos clinicamente relevantes (pacientes em estado crítico)\n",
    "  - Necessidade de transformações para modelagem\n",
    "\n",
    "**4. Considerações para Modelagem:**\n",
    "- Variáveis com **alta assimetria** podem beneficiar de transformações logarítmicas ou de Box-Cox\n",
    "- A presença de **outliers** pode representar casos críticos clinicamente importantes\n",
    "- **Diferentes escalas** entre variáveis requerem normalização/padronização\n",
    "- **Missing values** precisam de estratégias de imputação específicas por tipo de variável\n",
    "\n",
    "**5. Padrões por Categoria de Variável:**\n",
    "- **Sinais Vitais**: Tendem a ter distribuições mais regulares, refletindo homeostase\n",
    "- **Biomarcadores Laboratoriais**: Frequentemente assimétricos, com valores de referência bem definidos  \n",
    "- **Parâmetros de Oxigenação**: Podem apresentar distribuições bimodais (pacientes ventilados vs. não-ventilados)\n",
    "- **Variáveis Demográficas**: Distribuições específicas (ex: idade com padrão populacional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5a65a",
   "metadata": {},
   "source": [
    "## 4. Análise Bivariada\n",
    "\n",
    "A análise bivariada examina as relações entre variáveis, focando especialmente na associação com sepsis e em correlações clinicamente relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62596bb3",
   "metadata": {},
   "source": [
    "### 4.1 Relacionando Variáveis com Alto Missing vs SepsisLabel\n",
    "\n",
    "O intuito é identificar se alguma(s) variável(is) extremamente esparsa(s) possui(em) valor preditivo ou se podem ser descartadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe83d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 9 Variáveis com >90% Missing vs Sepsis\n",
    "\n",
    "\n",
    "# Calcular % de missing values para todas as variáveis numéricas\n",
    "missing_analysis = []\n",
    "for col in X_train.select_dtypes(include=[np.number]).columns:\n",
    "    missing_pct = (X_train[col].isnull().sum() / len(X_train)) * 100\n",
    "    missing_analysis.append({'variavel': col, 'missing_pct': missing_pct})\n",
    "\n",
    "missing_df = pd.DataFrame(missing_analysis).sort_values('missing_pct', ascending=False)\n",
    "\n",
    "# Selecionar TOP 9 variáveis com >90% missing\n",
    "vars_to_analyze = missing_df[missing_df['missing_pct'] > 90]['variavel'].head(9).tolist()\n",
    "\n",
    "# Criar visualização estratégica: 3x3 grid para as 9 variáveis\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, var in enumerate(vars_to_analyze):  # Processa todas as 9 variáveis\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Dados válidos apenas\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature': X_train[var],\n",
    "        'sepsis': y_train\n",
    "    }).dropna()\n",
    "    \n",
    "    missing_pct = missing_df[missing_df['variavel'] == var]['missing_pct'].iloc[0]\n",
    "    \n",
    "    # Converter para labels\n",
    "    temp_df['sepsis_label'] = temp_df['sepsis'].map({0: 'Não-Sepsis', 1: 'Sepsis'})\n",
    "    \n",
    "    # Boxplot principal\n",
    "    sns.boxplot(data=temp_df, x='sepsis_label', y='feature', \n",
    "                palette=['#3498db', '#e74c3c'], ax=ax)\n",
    "    \n",
    "    # Calcular métricas de separabilidade (importantes para ML)\n",
    "    no_sepsis_data = temp_df[temp_df['sepsis'] == 0]['feature']\n",
    "    sepsis_data = temp_df[temp_df['sepsis'] == 1]['feature']\n",
    "    \n",
    "    # Métricas para avaliação de utilidade em ML\n",
    "    median_diff = sepsis_data.median() - no_sepsis_data.median()\n",
    "    separability = abs(median_diff) / no_sepsis_data.std() if no_sepsis_data.std() > 0 else 0\n",
    "    data_loss = (1 - len(temp_df)/len(X_train)) * 100  # % dados perdidos\n",
    "    \n",
    "    # Decisão de ML baseada em critérios\n",
    "    if separability > 0.3:\n",
    "        decision = \"MANTER\"\n",
    "        bg_color = '#f0fff0'  # Verde claro\n",
    "    elif separability > 0.1:\n",
    "        decision = \"TRATAR\"  \n",
    "        bg_color = '#fff8f0'  # Laranja claro\n",
    "    else:\n",
    "        decision = \"DESCARTAR\"\n",
    "        bg_color = '#fff0f0'  # Vermelho claro\n",
    "    \n",
    "    ax.set_facecolor(bg_color)\n",
    "    \n",
    "    # Título com métricas\n",
    "    ax.set_title(f'{var} \\nSep={separability:.2f} | Loss={data_loss:.1f}% | n={len(temp_df):,}', \n",
    "                fontsize=11, pad=10)\n",
    "    ax.set_xlabel('Sepsis Status')\n",
    "    ax.set_ylabel(var)\n",
    "    \n",
    "    # Stats box\n",
    "    stats_text = f'Missing: {missing_pct:.0f}% | Separabilidade: {separability:.2f} | {decision}'\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "            \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e3d55",
   "metadata": {},
   "source": [
    "Decisões:\n",
    "- DESCARTAR: 8 variáveis\n",
    "- TRATAR: 1 variáveis\n",
    "\n",
    "Top Candidadatas por Separabilidade:\n",
    "  - Fibrinogen                     | Sep: 0.134 | Miss: 99%\n",
    "  - PTT                            | Sep: 0.085 | Miss: 97%\n",
    "  - Bilirubin_total                | Sep: 0.077 | Miss: 99%\n",
    "\n",
    "Aplicar Imputação Cuidadosa: Fibrinogen\n",
    "\n",
    "Métricas Agregadas:\n",
    "  - Separabilidade média: 0.055\n",
    "  - Perda de dados média: 98.3%\n",
    "  - ROI threshold calculado: 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ada05",
   "metadata": {},
   "source": [
    "### 4.2 Emparelhando Variáveis Pouco Esparsas\n",
    "\n",
    "A análise bivariada examina as relações entre duas variáveis, ajudando a identificar padrões, dependências e correlações que podem ser cruciais para o desenvolvimento de modelos preditivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Plot para mostrar distribuições e relações entre variáveis\n",
    "# Seleciona um subconjunto de variáveis para o pairplot (para performance)\n",
    "\n",
    "# Calcular missing values para variáveis numéricas\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "low_missing_cols = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    missing_pct = (X_train[col].isnull().sum() / len(X_train)) * 100\n",
    "    if missing_pct < 20:  # Menos de 20% missing\n",
    "        low_missing_cols.append(col)\n",
    "\n",
    "print(f\"Variáveis numéricas com <20% missing: {len(low_missing_cols)}\")\n",
    "\n",
    "# [1:6] -> Pula a variável Hour a fim de analisar variáveis diferentes\n",
    "pairplot_vars = low_missing_cols[1:6] if len(low_missing_cols) >= 5 else low_missing_cols\n",
    "\n",
    "print(f\"Variáveis selecionadas para pairplot: {pairplot_vars}\")\n",
    "\n",
    "pairplot_data = X_train[pairplot_vars].copy()\n",
    "pairplot_data['SepsisLabel'] = y_train\n",
    "\n",
    "# Amostrar dados se o dataset for muito grande (para performance)\n",
    "if len(pairplot_data) > 5000:\n",
    "    pairplot_sample = pairplot_data.sample(n=5000, random_state=42)\n",
    "    print(f\"Usando amostra de 5000 registros para pairplot (de {len(pairplot_data)} total)\")\n",
    "else:\n",
    "    pairplot_sample = pairplot_data\n",
    "    print(f\"Usando todos os {len(pairplot_data)} registros para pairplot\")\n",
    "\n",
    "# Remover linhas com valores faltantes para o pairplot\n",
    "pairplot_sample = pairplot_sample.dropna()\n",
    "\n",
    "print(f\"\\nCriando Pair Plot com {len(pairplot_sample)} amostras válidas...\")\n",
    "print(f\"Variáveis incluídas: {pairplot_vars}\")\n",
    "\n",
    "# Configurar paleta de cores\n",
    "sns.set_palette(\"Set1\")\n",
    "\n",
    "# Criar pairplot\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Pairplot com diferenciação por classe\n",
    "pair_grid = sns.pairplot(pairplot_sample, hue='SepsisLabel',\n",
    "                        diag_kind='hist',\n",
    "                        plot_kws={'alpha': 0.6},\n",
    "                        diag_kws={'alpha': 0.7})\n",
    "\n",
    "# Personalizar a legenda\n",
    "pair_grid._legend.set_title(\"SepsisLabel\")\n",
    "for text, label in zip(pair_grid._legend.get_texts(), ['Não-Sepsis', 'Sepsis']):\n",
    "    text.set_text(label)\n",
    "\n",
    "plt.suptitle('Pair Plot - Análise de Relações entre Variáveis', y=1.02, fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256456ea",
   "metadata": {},
   "source": [
    "## 5. Análise Multivariada\n",
    "\n",
    "A análise multivariada examina as interações complexas entre múltiplas variáveis clínicas simultaneamente, identificando padrões de correlação e dependências que são cruciais para o entendimento fisiopatológico da sepsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929370bc",
   "metadata": {
    "id": "929370bc"
   },
   "outputs": [],
   "source": [
    "# Correlation Heatmap - Análise de correlações entre variáveis\n",
    "\n",
    "# Definir variáveis numéricas com baixo missing (<20%) para análise de correlação\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "low_missing_cols = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    missing_pct = (X_train[col].isnull().sum() / len(X_train)) * 100\n",
    "    if missing_pct < 20:  # Menos de 20% missing\n",
    "        low_missing_cols.append(col)\n",
    "\n",
    "print(f\"Variáveis numéricas com <20% missing: {len(low_missing_cols)}\")\n",
    "print(f\"Lista: {low_missing_cols}\")\n",
    "\n",
    "# Criar subset dos dados para correlação\n",
    "correlation_data = X_train[low_missing_cols].copy()\n",
    "\n",
    "# Calcular matriz de correlação\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "print(f\"MATRIZ DE CORRELAÇÃO\")\n",
    "\n",
    "# Criar heatmap de correlação\n",
    "plt.figure(figsize=(16, 14))\n",
    "\n",
    "# Configurar máscara para a diagonal superior (opcional)\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Criar heatmap\n",
    "sns.heatmap(correlation_matrix,\n",
    "            annot=True,           # Mostrar valores\n",
    "            fmt='.2f',           # Formato dos números\n",
    "            cmap='RdBu_r',       # Paleta de cores\n",
    "            center=0,            # Centralizar em zero\n",
    "            square=True,         # Células quadradas\n",
    "            linewidths=0.5,      # Linhas entre células\n",
    "            cbar_kws={\"shrink\": .8},  # Configurar colorbar\n",
    "            mask=mask)           # Máscara para diagonal superior\n",
    "\n",
    "plt.title('Matriz de Correlação - Heatmap', fontsize=16, pad=20)\n",
    "plt.xlabel('Variáveis', fontsize=12)\n",
    "plt.ylabel('Variáveis', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Encontrar correlações mais altas (excluindo diagonal)\n",
    "correlation_matrix_no_diag = correlation_matrix.copy()\n",
    "np.fill_diagonal(correlation_matrix_no_diag.values, np.nan)\n",
    "\n",
    "# Achatar a matriz e ordenar por valor absoluto\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation_matrix_no_diag)):\n",
    "    for j in range(i+1, len(correlation_matrix_no_diag)):\n",
    "        var1 = correlation_matrix_no_diag.index[i]\n",
    "        var2 = correlation_matrix_no_diag.columns[j]\n",
    "        corr_value = correlation_matrix_no_diag.iloc[i, j]\n",
    "        if not np.isnan(corr_value):\n",
    "            corr_pairs.append((var1, var2, corr_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df5350",
   "metadata": {
    "id": "a8df5350"
   },
   "source": [
    "## 6.Análise das Variáveis Categóricas\n",
    "\n",
    "A identificação e análise das variáveis categóricas nos permite compreender as características demográficas e clínicas dos pacientes, bem como sua associação com o desenvolvimento de sepsis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8cb450",
   "metadata": {},
   "source": [
    "### 6.1 Visualização das Variáveis Categóricas\n",
    "\n",
    "As visualizações nos permitem compreender melhor a distribuição das variáveis categóricas e sua associação com a ocorrência de sepsis de forma intuitiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c02a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise e visualização das variáveis categóricas: Unit1, Unit2 e Gender\n",
    "# Criar barplots para distribuição e relação com sepsis\n",
    "\n",
    "categorical_vars = ['Gender', 'Unit1', 'Unit2']\n",
    "\n",
    "# Criar figura com subplots em grid 3x2 (3 linhas, 2 colunas)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    "for idx, cat_var in enumerate(categorical_vars):\n",
    "    # Preparar dados removendo valores faltantes\n",
    "    temp_df = pd.DataFrame({\n",
    "        'categorical': X_train[cat_var],\n",
    "        'target': y_train\n",
    "    }).dropna()\n",
    "    \n",
    "    # Gráfico 1: Distribuição da variável categórica (esquerda)\n",
    "    ax1 = axes[idx, 0]\n",
    "    \n",
    "    # Contar valores únicos\n",
    "    cat_counts = temp_df['categorical'].value_counts()\n",
    "    \n",
    "    # Criar gráfico de barras\n",
    "    bars = ax1.bar(range(len(cat_counts)), cat_counts.values, \n",
    "                    color='#2c3e50', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    ax1.set_title(f'Distribuição de {cat_var}', fontsize=14, pad=15)\n",
    "    ax1.set_xlabel(cat_var)\n",
    "    ax1.set_ylabel('Frequência')\n",
    "    ax1.set_xticks(range(len(cat_counts)))\n",
    "    ax1.set_xticklabels(cat_counts.index, rotation=45)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar, count in zip(bars, cat_counts.values):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(cat_counts)*0.01,\n",
    "                f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Gráfico 2: Variável categórica vs SepsisLabel (direita)\n",
    "    ax2 = axes[idx, 1]\n",
    "    \n",
    "    # Preparar dados para stacked bar chart (números absolutos)\n",
    "    crosstab_abs = pd.crosstab(temp_df['categorical'], temp_df['target'])\n",
    "    \n",
    "    # Preparar dados para percentuais (para os labels)\n",
    "    crosstab_pct = pd.crosstab(temp_df['categorical'], temp_df['target'], normalize='index') * 100\n",
    "    \n",
    "    # Criar gráfico de barras empilhadas\n",
    "    crosstab_abs.plot(kind='bar', stacked=True, ax=ax2, \n",
    "                        color=['#3498db', '#e74c3c'], alpha=0.8)\n",
    "    \n",
    "    ax2.set_title(f'{cat_var} vs SepsisLabel', fontsize=14, pad=15)\n",
    "    ax2.set_xlabel(cat_var)\n",
    "    ax2.set_ylabel('Frequência')\n",
    "    ax2.set_xticklabels(crosstab_abs.index, rotation=45)\n",
    "    ax2.legend(['Não-Sepsis', 'Sepsis'], title='SepsisLabel')\n",
    "    \n",
    "    # Adicionar percentual de sepsis acima das barras\n",
    "    for i, category in enumerate(crosstab_abs.index):\n",
    "        sepsis_pct = crosstab_pct.loc[category, 1]\n",
    "        non_sepsis_count = crosstab_abs.loc[category, 0]\n",
    "        sepsis_count = crosstab_abs.loc[category, 1]\n",
    "        total_height = non_sepsis_count + sepsis_count\n",
    "        \n",
    "        max_total = crosstab_abs.sum(axis=1).max()  # Altura máxima das barras\n",
    "        ax2.text(i, total_height + max_total*0.01, f'{sepsis_pct:.1f}%',\n",
    "                ha='center', va='bottom', fontweight='bold', color='red')\n",
    "        \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b930319",
   "metadata": {},
   "source": [
    "### 6.2 Análise Verbosa com Inferência Estatística\n",
    "\n",
    "Fazemos uma análise mais matemática envolvendo teste de hipóteses (Qui-quadrado e Valor-p) para complementar a interpretação do BarPlot e sustentar nossas decisões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f607683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_var in categorical_vars:\n",
    "    temp_df = pd.DataFrame({\n",
    "        'categorical': X_train[cat_var],\n",
    "        'target': y_train\n",
    "    }).dropna()\n",
    "    \n",
    "    print(f\"\\n{cat_var.upper()}:\")\n",
    "    \n",
    "    # Taxa de sepsis por categoria\n",
    "    sepsis_rates = temp_df.groupby('categorical')['target'].agg(['count', 'sum', 'mean'])\n",
    "    sepsis_rates.columns = ['Total', 'Sepsis_Count', 'Sepsis_Rate']\n",
    "    sepsis_rates['Sepsis_Rate_%'] = sepsis_rates['Sepsis_Rate'] * 100\n",
    "    \n",
    "    print(sepsis_rates[['Total', 'Sepsis_Count', 'Sepsis_Rate_%']].round(2))\n",
    "    \n",
    "    # Teste qui-quadrado para independência\n",
    "    from scipy.stats import chi2_contingency\n",
    "    contingency_table = pd.crosstab(temp_df['categorical'], temp_df['target'])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"Chi-quadrado: {chi2:.4f} | P-valor: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Associação estatisticamente significativa com sepsis\")\n",
    "    else:\n",
    "        print(\"Não há associação estatisticamente significativa\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
