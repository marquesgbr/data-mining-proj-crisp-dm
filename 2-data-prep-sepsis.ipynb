{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a2846b",
   "metadata": {},
   "source": [
    "# Data Preparation - Dataset de Sepsis\n",
    "## CRISP-DM Fase 3: Preparação dos Dados\n",
    "\n",
    "**Objetivo da Fase:**\n",
    "* Transformar dados brutos em formato adequado para modelagem\n",
    "* Implementar estratégias de limpeza e tratamento baseadas nos insights da EDA\n",
    "* Criar features derivadas com relevância clínica\n",
    "* Preparar datasets finais para algoritmos de machine learning\n",
    "\n",
    "**Baseado nos Insights da EDA:**\n",
    "* 37/41 variáveis apresentam missing values (68.37% do dataset)\n",
    "* 27 variáveis com >80% missing (candidatas à remoção)\n",
    "* Dataset altamente desbalanceado: 98.2% não-sepsis vs 1.8% sepsis\n",
    "* Estrutura temporal importante: risco aumenta após 100h na UTI\n",
    "* Variáveis categóricas bem definidas: Gender, Unit1, Unit2\n",
    "\n",
    "**Tarefas CRISP-DM a serem executadas:**\n",
    "1. **Seleção dos Dados**: Escolher variáveis mais relevantes\n",
    "2. **Limpeza dos Dados**: Tratar inconsistências e valores ausentes  \n",
    "3. **Construção dos Dados**: Criar features derivadas e engenharia\n",
    "4. **Integração dos Dados**: Combinar fontes (não aplicável aqui)\n",
    "5. **Formatação dos Dados**: Preparar formato final para modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21555a66",
   "metadata": {},
   "source": [
    "## Configuração do Ambiente Google Colab\n",
    "\n",
    "Para funcionar no Google Colab, é necessário criar um atalho do diretório [MDA](https://drive.google.com/drive/u/0/folders/1YFieuvYMGx198h_CKCULdfv7IKRwDuMp) no seu próprio Drive e então rodar os dois comandos abaixo e conceder permissão ao seu drive quando rodar a célula logo abaixo.\n",
    "\n",
    "[Link](https://towardsdatascience.com/simplify-file-sharing-44bde79a8a18/) detalhando como funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f059104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificar para o diretorio que contém os dados de teste e treino\n",
    "%cd /content/drive/MyDrive/MDA/Train\\ and\\ test\\ data\\ -\\ Proj\\ DM/\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fed35e",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas\n",
    "\n",
    "Importação de todas as bibliotecas necessárias para preparação dos dados, incluindo bibliotecas específicas para pré-processamento, feature engineering e balanceamento de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas essenciais para manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configurações gerais\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cfe4b",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados e Insights da EDA\n",
    "\n",
    "Carregamento dos datasets de treino e teste, seguido da documentação dos principais insights obtidos na análise exploratória que guiarão as decisões de preparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945c328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1241768, 41) | y_train: (1241768,)\n",
      "SepsisLabel\n",
      "0.0    0.982015\n",
      "1.0    0.017985\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('dataset_sepsis_train.csv')\n",
    "\n",
    "# Separar features e target\n",
    "X_train = train_df.drop('SepsisLabel', axis=1)\n",
    "y_train = train_df['SepsisLabel']\n",
    "\n",
    "# Forma final\n",
    "print(f\"X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
    "\n",
    "# Distribuição das classes no treino\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a29a8",
   "metadata": {},
   "source": [
    "## 3. TAREFA 1: Seleção dos Dados\n",
    "\n",
    "**Objetivo:** Escolher as variáveis mais relevantes para o modelo de mineração, removendo features com baixo potencial preditivo ou problemas graves de qualidade.\n",
    "\n",
    "**Critérios de seleção:**\n",
    "* Relevância clínica para detecção de sepsis\n",
    "* Percentual de missing values aceitável\n",
    "* Separabilidade entre classes (baseada na EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90a9f6",
   "metadata": {},
   "source": [
    "### 3.1 Mapeamento de Variáveis com Excesso de Missing Values para Remoção\n",
    "\n",
    "Vamos refazer a análise, mais objetiva e breve, das variáveis com >60% missing values para decidir quais manter, tratar ou remover baseado no critério de separabilidade de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4c277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMPUTAR_SIMPLES (2 variáveis):\n",
      "  • Temp: Sep=0.393 | Missing=66.2% | n=419,945\n",
      "  • BUN: Sep=0.353 | Missing=93.1% | n=85,440\n",
      "\n",
      "IMPUTAR_AVANCADA (2 variáveis):\n",
      "  • Platelets: Sep=0.203 | Missing=94.1% | n=73,790\n",
      "  • WBC: Sep=0.194 | Missing=93.6% | n=79,613\n",
      "\n",
      "DESCARTAR (24 variáveis):\n",
      "  • Hgb: Sep=0.152 | Missing=92.6% | n=91,759\n",
      "  • Creatinine: Sep=0.151 | Missing=93.9% | n=75,809\n",
      "  • pH: Sep=0.135 | Missing=93.1% | n=86,094\n",
      "  • Fibrinogen: Sep=0.134 | Missing=99.3% | n=8,203\n",
      "  • Hct: Sep=0.091 | Missing=91.1% | n=109,980\n",
      "  • PTT: Sep=0.085 | Missing=97.0% | n=36,690\n",
      "  • Calcium: Sep=0.083 | Missing=94.1% | n=73,269\n",
      "  • Bilirubin_total: Sep=0.077 | Missing=98.5% | n=18,518\n",
      "  • Alkalinephos: Sep=0.071 | Missing=98.4% | n=19,954\n",
      "  • Phosphate: Sep=0.070 | Missing=96.0% | n=50,011\n",
      "  • Bilirubin_direct: Sep=0.062 | Missing=99.8% | n=2,393\n",
      "  • Lactate: Sep=0.048 | Missing=97.3% | n=33,238\n",
      "  • Glucose: Sep=0.039 | Missing=82.9% | n=212,578\n",
      "  • AST: Sep=0.015 | Missing=98.4% | n=20,144\n",
      "  • Potassium: Sep=0.008 | Missing=90.7% | n=115,900\n",
      "  • TroponinI: Sep=0.000 | Missing=99.1% | n=11,743\n",
      "  • EtCO2: Sep=0.000 | Missing=96.3% | n=46,047\n",
      "  • BaseExcess: Sep=0.000 | Missing=94.6% | n=67,324\n",
      "  • HCO3: Sep=0.000 | Missing=95.8% | n=52,334\n",
      "  • FiO2: Sep=0.000 | Missing=91.7% | n=103,618\n",
      "  • PaCO2: Sep=0.000 | Missing=94.4% | n=69,132\n",
      "  • SaO2: Sep=0.000 | Missing=96.6% | n=42,777\n",
      "  • Chloride: Sep=0.000 | Missing=95.4% | n=56,701\n",
      "  • Magnesium: Sep=0.000 | Missing=93.7% | n=78,652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identificar variáveis com >60% missing\n",
    "high_missing_vars = []\n",
    "for col in X_train.select_dtypes(include=[np.number]).columns:\n",
    "    missing_pct = (X_train[col].isnull().sum() / len(X_train)) * 100\n",
    "    if missing_pct > 60:\n",
    "        high_missing_vars.append({\n",
    "            'variavel': col,\n",
    "            'missing_pct': missing_pct\n",
    "        })\n",
    "\n",
    "# Calcular separabilidade para cada variável\n",
    "separability_results = {\n",
    "    'IMPUTAR_SIMPLES': [],     # Separabilidade > 0.3: Alta discriminação\n",
    "    'IMPUTAR_AVANCADA': [],    # Separabilidade 0.16 - 0.3: Discriminação moderada  \n",
    "    'DESCARTAR': []            # Separabilidade < 0.16: Baixa discriminação\n",
    "}\n",
    "\n",
    "for var_info in high_missing_vars:\n",
    "    col = var_info['variavel']\n",
    "    missing_pct = var_info['missing_pct']\n",
    "    \n",
    "    # Criar DataFrame temporário sem valores faltantes\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature': X_train[col],\n",
    "        'target': y_train\n",
    "    }).dropna()\n",
    "\n",
    "    # Separar por classe\n",
    "    no_sepsis_data = temp_df[temp_df['target'] == 0]['feature']\n",
    "    sepsis_data = temp_df[temp_df['target'] == 1]['feature']\n",
    "\n",
    "    # Calcular separabilidade (diferença de medianas / desvio padrão)\n",
    "    median_diff = abs(sepsis_data.median() - no_sepsis_data.median())\n",
    "    pooled_std = no_sepsis_data.std() if no_sepsis_data.std() > 0 else 1\n",
    "    separability = median_diff / pooled_std\n",
    "    \n",
    "    # Classificar baseado na separabilidade\n",
    "    var_result = {\n",
    "        'variavel': col,\n",
    "        'missing_pct': missing_pct,\n",
    "        'separabilidade': separability,\n",
    "        'n_amostras': len(temp_df)\n",
    "    }\n",
    "    \n",
    "    if separability > 0.3:\n",
    "        separability_results['IMPUTAR_SIMPLES'].append(var_result)\n",
    "    elif separability >= 0.16:\n",
    "        separability_results['IMPUTAR_AVANCADA'].append(var_result)\n",
    "    else:\n",
    "        separability_results['DESCARTAR'].append(var_result)\n",
    "\n",
    "# Exibir resultados \n",
    "\n",
    "for categoria, vars_list in separability_results.items():\n",
    "    print(f\"\\n{categoria} ({len(vars_list)} variáveis):\")\n",
    "    for var in sorted(vars_list, key=lambda x: x['separabilidade'], reverse=True):\n",
    "        print(f\"  • {var['variavel']}: Sep={var['separabilidade']:.3f} | Missing={var['missing_pct']:.1f}% | n={var['n_amostras']:,}\")\n",
    "\n",
    "variables_to_keep = [var['variavel'] for var in separability_results['IMPUTAR_SIMPLES']]\n",
    "variables_to_treat = [var['variavel'] for var in separability_results['IMPUTAR_AVANCADA']]  \n",
    "variables_to_discard = [var['variavel'] for var in separability_results['DESCARTAR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb9bb2c",
   "metadata": {},
   "source": [
    "### 3.2 Análise de Separabilidade Estatística\n",
    "\n",
    "Avaliação da capacidade discriminativa das variáveis que não foram selecionadas para exclusão, a fim de confirmar e justificar as decisões antes de fazer a remoção, usando testes estatísticos e métricas de separação entre classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a8bc6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANÁLISE DE VARIÁVEIS NUMÉRICAS:\n",
      "Variável        Missing%   Separab.   p-value_MW   Mutual Info  N_samples \n",
      "\n",
      "Min Hour: 0\n",
      "Hour            0.0        0.303      0.00000      0.0038413    1,241,768 \n",
      "Min HR: 20.0\n",
      "HR              9.9        0.386      0.00000      0.0010304    1,119,123 \n",
      "Min O2Sat: 20.0\n",
      "O2Sat           13.1       0.000      0.00079      0.0000634    1,079,708 \n",
      "Min Temp: 23.0\n",
      "Temp            66.2       0.326      0.00000      0.0020082    419,945   \n",
      "Min SBP: 20.0\n",
      "SBP             14.6       0.124      0.00000      0.0001972    1,060,857 \n",
      "Min MAP: 20.0\n",
      "MAP             12.4       0.121      0.00000      0.0002270    1,087,236 \n",
      "Min DBP: 20.0\n",
      "DBP             31.3       0.143      0.00000      0.0001955    852,691   \n",
      "Min Resp: 1.0\n",
      "Resp            15.3       0.356      0.00000      0.0010005    1,051,181 \n",
      "Min BUN: 1.0\n",
      "BUN             93.1       0.328      0.00000      0.0018243    85,440    \n",
      "Min WBC: 0.1\n",
      "WBC             93.6       0.166      0.00000      0.0009935    79,613    \n",
      "Min Platelets: 2.0\n",
      "Platelets       94.1       0.189      0.00000      0.0007498    73,790    \n",
      "Min HospAdmTime: -5366.86\n",
      "HospAdmTime     0.0        0.017      0.00000      0.0010616    1,241,762 \n",
      "Min ICULOS: 1.0\n",
      "ICULOS          0.0        0.302      0.00000      0.0040386    1,241,768 \n",
      "\n",
      "ANÁLISE DE VARIÁVEIS CATEGÓRICAS:\n",
      "Variável        Missing%   p-value_Chi2 Mutual Info  N_samples \n",
      "\n",
      "Gender          0.0        0.00000      0.0000457    1,241,768 \n",
      "Unit1           39.5       0.00000      0.0002854    751,787   \n",
      "Unit2           39.5       0.00000      0.0002854    751,787   \n",
      "\n",
      "Separabilidades Numéricas:\n",
      "  • Variáveis com Sep > 0.3: 6\n",
      "  • Variáveis com Sep > 0.16: 8\n",
      "\n",
      "SIGNIFICÂNCIA ESTATÍSTICA (Numéricas):\n",
      "  • p < 0.001 (altamente significativo): 13 variáveis\n",
      "  • 0.001 ≤ p < 0.01 (muito significativo): 0 variáveis\n",
      "  • 0.01 ≤ p < 0.05 (significativo): 0 variáveis\n",
      "  • p ≥ 0.05 (não significativo): 0 variáveis\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "X_train_not_discard = X_train.drop(columns=variables_to_discard)\n",
    "# Separar variáveis numéricas e categóricas\n",
    "categorical_vars = ['Gender', 'Unit1', 'Unit2']  \n",
    "# Numéricas são todas as colunas MENOS as categóricas\n",
    "numeric_vars = [col for col in X_train_not_discard.columns if col not in categorical_vars]\n",
    "\n",
    "\n",
    "# Análise para variáveis numéricas\n",
    "all_separability_results = []\n",
    "\n",
    "print(f\"\\nANÁLISE DE VARIÁVEIS NUMÉRICAS:\")\n",
    "print(f\"{'Variável':<15} {'Missing%':<10} {'Separab.':<10} {'p-value_MW':<12} {'Mutual Info':<12} {'N_samples':<10}\\n\")\n",
    "\n",
    "for var in numeric_vars:\n",
    "    missing_pct = (X_train_not_discard[var].isnull().sum() / len(X_train_not_discard)) * 100\n",
    "    \n",
    "    # Criar DataFrame temporário sem valores faltantes\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature': X_train_not_discard[var],\n",
    "        'target': y_train\n",
    "    }).dropna()\n",
    "    \n",
    "    # Separar por classe\n",
    "    no_sepsis_data = temp_df[temp_df['target'] == 0]['feature']\n",
    "    sepsis_data = temp_df[temp_df['target'] == 1]['feature']\n",
    "\n",
    "    # Calcular separabilidade (diferença de medianas / desvio padrão)\n",
    "    median_diff = abs(sepsis_data.median() - no_sepsis_data.median())\n",
    "    pooled_std = np.sqrt(((no_sepsis_data.std()**2 + sepsis_data.std()**2) / 2))\n",
    "    separability = median_diff / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    # Teste U de Mann-Whitney (não-paramétrico)\n",
    "    try:\n",
    "        stat, p_value = stats.mannwhitneyu(sepsis_data, no_sepsis_data, alternative='two-sided')\n",
    "        mann_whitney_pval = p_value\n",
    "    except:\n",
    "        mann_whitney_pval = 1.0  # p-value máximo para casos de erro\n",
    "\n",
    "    # Informação mútua\n",
    "    try:\n",
    "        # Discretizar para mutual info (usar quintis)\n",
    "        temp_df['feature_disc'] = pd.qcut(temp_df['feature'], q=5, labels=False, duplicates='drop')\n",
    "        mutual_info = mutual_info_score(temp_df['target'], temp_df['feature_disc'])\n",
    "    except:\n",
    "        mutual_info = 0\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    result = {\n",
    "        'variavel': var,\n",
    "        'missing_pct': missing_pct,\n",
    "        'separabilidade': separability,\n",
    "        'mann_whitney': mann_whitney_pval,\n",
    "        'mutual_info': mutual_info,\n",
    "        'n_amostras': len(temp_df)\n",
    "    }\n",
    "    all_separability_results.append(result)\n",
    "    \n",
    "    # Exibir resultado\n",
    "    print(f\"{var:<15} {missing_pct:<10.1f} {separability:<10.3f} {mann_whitney_pval:<12.5f} {mutual_info:<12.7f} {len(temp_df):<10,}\")\n",
    "\n",
    "\n",
    "# Análise para variáveis categóricas\n",
    "print(f\"\\nANÁLISE DE VARIÁVEIS CATEGÓRICAS:\")\n",
    "print(f\"{'Variável':<15} {'Missing%':<10} {'p-value_Chi2':<12} {'Mutual Info':<12} {'N_samples':<10}\\n\")\n",
    "\n",
    "for var in categorical_vars:\n",
    "    missing_pct = (X_train_not_discard[var].isnull().sum() / len(X_train_not_discard)) * 100\n",
    "    \n",
    "    # Criar DataFrame temporário sem valores faltantes\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature': X_train_not_discard[var],\n",
    "        'target': y_train\n",
    "    }).dropna()\n",
    "    \n",
    "    # Teste Qui-quadrado\n",
    "    try:\n",
    "        contingency_table = pd.crosstab(temp_df['feature'], temp_df['target'])\n",
    "        chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "        chi2_pval = p_value\n",
    "    except:\n",
    "        chi2_pval = 1.0  # p-value máximo para casos de erro\n",
    "    \n",
    "    # Informação mútua\n",
    "    try:\n",
    "        mutual_info = mutual_info_score(temp_df['target'], temp_df['feature'])\n",
    "    except:\n",
    "        mutual_info = 0\n",
    "    \n",
    "    result = {\n",
    "        'variavel': var,\n",
    "        'missing_pct': missing_pct,\n",
    "        'chi2_sig': chi2_pval,\n",
    "        'mutual_info': mutual_info,\n",
    "        'n_amostras': len(temp_df),\n",
    "        'tipo': 'categorical'\n",
    "    }\n",
    "    all_separability_results.append(result)\n",
    "    \n",
    "    print(f\"{var:<15} {missing_pct:<10.1f} {chi2_pval:<12.5f} {mutual_info:<12.7f} {len(temp_df):<10,}\")\n",
    "\n",
    "\n",
    "# Ranking por separabilidade (variáveis numéricas)\n",
    "numeric_results = [r for r in all_separability_results if 'separabilidade' in r]\n",
    "numeric_results_sorted = sorted(numeric_results, key=lambda x: x['separabilidade'], reverse=True)\n",
    "\n",
    "print(f\"\\nSeparabilidades Numéricas:\")\n",
    "separabilities = [r['separabilidade'] for r in numeric_results]\n",
    "print(f\"  • Variáveis com Sep > 0.3: {sum(1 for s in separabilities if s > 0.3)}\")\n",
    "print(f\"  • Variáveis com Sep > 0.16: {sum(1 for s in separabilities if s > 0.16)}\")\n",
    "\n",
    "# Análise de significância estatística\n",
    "print(f\"\\nSIGNIFICÂNCIA ESTATÍSTICA (Numéricas):\")\n",
    "sig_001 = sum(1 for r in numeric_results if r['mann_whitney'] < 0.001)\n",
    "sig_01 = sum(1 for r in numeric_results if 0.001 <= r['mann_whitney'] < 0.01)\n",
    "sig_05 = sum(1 for r in numeric_results if 0.01 <= r['mann_whitney'] < 0.05)\n",
    "not_sig = sum(1 for r in numeric_results if r['mann_whitney'] >= 0.05)\n",
    "print(f\"  • p < 0.001 (altamente significativo): {sig_001} variáveis\")\n",
    "print(f\"  • 0.001 ≤ p < 0.01 (muito significativo): {sig_01} variáveis\")  \n",
    "print(f\"  • 0.01 ≤ p < 0.05 (significativo): {sig_05} variáveis\")\n",
    "print(f\"  • p ≥ 0.05 (não significativo): {not_sig} variáveis\")\n",
    "\n",
    "# Salvar resultados para uso posterior\n",
    "statistical_analysis_results = {\n",
    "    'numeric_results': numeric_results_sorted,\n",
    "    'all_results': all_separability_results\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ec87c",
   "metadata": {},
   "source": [
    "#### Alteração Após Análise \n",
    "Percebe-se que ainda é possível remover `Age` do escopo de features visto que não há nenhuma métrica que aponte essa variável como algo relevante apesar do que diz a literatura sobre sepsis e o baixo percentual de missing values. Ela possui baixa separabilidade, um Man Whitney não significativo e Mutual Info demonstra zero informação qundo comparado a SepsisLabel\n",
    "\n",
    "| Variável | Missing% | Separabilidade |  p-value_MW | Mutual Info |\n",
    "|----------|----------|----------------|--------------|-------------| \n",
    "| **Age** | 0.0 | 0.000 |  0.4367935 | 0.00000 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977f647",
   "metadata": {},
   "source": [
    "### 3.3 Aplicação das Decisões de Separabilidade\n",
    "\n",
    "Implementação prática da remoção de variáveis com baixa separabilidade e organização das listas para tratamento adiante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39f998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removendo 25 variáveis com baixa separabilidade...\n",
      "Variáveis removidas:\n",
      "  • EtCO2: 96.3% missing\n",
      "  • BaseExcess: 94.6% missing\n",
      "  • HCO3: 95.8% missing\n",
      "  • FiO2: 91.7% missing\n",
      "  • pH: 93.1% missing\n",
      "  • PaCO2: 94.4% missing\n",
      "  • SaO2: 96.6% missing\n",
      "  • AST: 98.4% missing\n",
      "  • Alkalinephos: 98.4% missing\n",
      "  • Calcium: 94.1% missing\n",
      "  • Chloride: 95.4% missing\n",
      "  • Creatinine: 93.9% missing\n",
      "  • Bilirubin_direct: 99.8% missing\n",
      "  • Glucose: 82.9% missing\n",
      "  • Lactate: 97.3% missing\n",
      "  • Magnesium: 93.7% missing\n",
      "  • Phosphate: 96.0% missing\n",
      "  • Potassium: 90.7% missing\n",
      "  • Bilirubin_total: 98.5% missing\n",
      "  • TroponinI: 99.1% missing\n",
      "  • Hct: 91.1% missing\n",
      "  • Hgb: 92.6% missing\n",
      "  • PTT: 97.0% missing\n",
      "  • Fibrinogen: 99.3% missing\n",
      "  • Age: 0.0% missing (removida por baixa discriminação)\n",
      "\n",
      "Dimensões do dataset:\n",
      "  • Original: (1241768, 41)\n",
      "  • Após seleção: (1241768, 16)\n"
     ]
    }
   ],
   "source": [
    "# Adicionar Age às variáveis a descartar \n",
    "variables_to_discard.append('Age')\n",
    "\n",
    "# Remover variáveis com baixa separabilidade e alto missing do dataset principal\n",
    "total_to_remove = len(variables_to_discard)\n",
    "print(f\"Removendo {total_to_remove} variáveis com baixa separabilidade...\")\n",
    "\n",
    "X_train_selected = X_train.drop(columns=variables_to_discard)\n",
    "\n",
    "print(\"Variáveis removidas:\")\n",
    "for var in variables_to_discard:\n",
    "    missing_pct = (X_train[var].isnull().sum() / len(X_train)) * 100\n",
    "    if var == 'Age':\n",
    "        print(f\"  • {var}: {missing_pct:.1f}% missing (removida por baixa discriminação)\")\n",
    "    else:\n",
    "        print(f\"  • {var}: {missing_pct:.1f}% missing\")\n",
    "\n",
    "print(f\"\\nDimensões do dataset:\")\n",
    "print(f\"  • Original: {X_train.shape}\")\n",
    "print(f\"  • Após seleção: {X_train_selected.shape}\")\n",
    "\n",
    "# Organizar variáveis por estratégia de tratamento\n",
    "high_missing_strategy = {\n",
    "    'imputacao_simples': variables_to_keep,      \n",
    "    'imputacao_avancada': variables_to_treat,    \n",
    "    'removidas': variables_to_discard           \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63353242",
   "metadata": {},
   "source": [
    "### 3.4 Síntese das Decisões de Seleção de Variáveis\n",
    "\n",
    "**Documentação completa das decisões tomadas na Tarefa 1 (Seleção dos Dados) com respectivas justificativas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759d1bb",
   "metadata": {},
   "source": [
    "\n",
    "RESULTADOS FINAIS DA SELEÇÃO DE VARIÁVEIS\n",
    "\n",
    "CRITÉRIOS DE SELEÇÃO APLICADOS\n",
    "\n",
    "1. **Critério de Missing Values**: Variáveis com >60% de valores ausentes analisadas\n",
    "2. **Critério de Separabilidade**: Capacidade discriminativa entre classes (limite: 0.16)\n",
    "3. **Critério Estatístico**: Significância nos testes Mann-Whitney U e Chi-quadrado\n",
    "\n",
    "IMPACTO FINAL DAS DECISÕES\n",
    "\n",
    "**Redução Dimensional Efetiva:**\n",
    "- **Dataset original**: 1,241,768 × 41 variáveis\n",
    "- **Dataset final**: 1,241,768 × 16 variáveis  \n",
    "- **Redução**: 61% das variáveis removidas (25/41)\n",
    "- **Taxa de compressão**: 2.6:1\n",
    "\n",
    "ESTRATÉGIAS DE TRATAMENTO DEFINIDAS\n",
    "\n",
    "**IMPUTAÇÃO Cuidadosa** (1 variáveis - Separabilidade > 0.3)\n",
    "\n",
    "**Estratégia**: Imputação com medidas robustas (mediana) + validação clínica\n",
    "\n",
    "| Variável | Missing% | Separabilidade | p-value | Justificativa Médica |\n",
    "|----------|----------|----------------|---------|---------------------|\n",
    "| **Temp** | 66.2% | 0.326 | < 0.001 | Temperatura corporal: indicador direto de resposta inflamatória |\n",
    "\n",
    "**IMPUTAÇÃO Específica** (3 variáveis - Separabilidade 0.16-0.3 ou Separabilidade>0.3 e Missing>90%)  \n",
    "\n",
    "**Estratégia**: Técnicas sofisticadas (KNN, regressão) devido à considerável relevância clínica \n",
    "\n",
    "| Variável | Missing% | Separabilidade | p-value | Justificativa Médica |\n",
    "|----------|----------|----------------|---------|---------------------|\n",
    "| **BUN** | 93.1% | 0.328 | < 0.001 | Função renal: biomarcador de disfunção orgânica na sepsis |\n",
    "| **Platelets** | 94.1% | 0.189 | < 0.001 | Coagulação: trombocitopenia marca disfunção hemostática |\n",
    "| **WBC** | 93.6% | 0.166 | < 0.001 | Sistema imune: resposta leucocitária à infecção |\n",
    "\n",
    "**REMOVIDAS** (25 variáveis - Separabilidade < 0.16)\n",
    "\n",
    "**Critério duplo**: Baixa discriminação + Alto missing (>60%)\n",
    "\n",
    "**Destaques das remoções:**\n",
    "- **Age**: 0.0% missing, Sep: 0.000, p-value: 0.437 (única exceção por baixa discriminação)\n",
    "- **24 variáveis** com >80% missing + separabilidade < 0.16\n",
    "- **Maior redução**: TroponinI (99.1% missing), Bilirubin_direct (99.8% missing)\n",
    "\n",
    "VALIDAÇÃO ESTATÍSTICA FINAL\n",
    "\n",
    "**Testes Aplicados:**\n",
    "- **Mann-Whitney U**: Para variáveis numéricas (não-paramétrico)\n",
    "- **Qui-quadrado**: Para variáveis categóricas\n",
    "- **Informação Mútua**: Medida de dependência entre variáveis\n",
    "\n",
    "**Significância dos Testes:**\n",
    "- **Variáveis numéricas significativas**: 13/14 (p < 0.05)\n",
    "- **Variáveis categóricas significativas**: 3/3 (p < 0.001)  \n",
    "- **Taxa de significância geral**: 94.1% (16/17 variáveis)\n",
    "\n",
    "**Estratégias de Tratamento Definidas:**\n",
    "- **Imputação cuidadosa**: 2 variáveis de alta relevância\n",
    "- **Imputação específica**: 6 variáveis de relevância moderada\n",
    "- **Manutenção**: 13 variáveis com baixo missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995bf50",
   "metadata": {},
   "source": [
    "## 4. Limpeza dos Dados\n",
    "\n",
    "**Objetivo:** Corrigir ou remover dados inconsistentes, duplicados ou ausentes através de estratégias específicas para cada tipo de variável.\n",
    "\n",
    "**Estratégias por tipo de missing:**\n",
    "* Missing < 20%: Imputação simples (mediana/moda)\n",
    "* Missing >= 20%: Imputação baseada em modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34539dc5",
   "metadata": {},
   "source": [
    "### 4.1 Detecção e Remoção de Duplicatas\n",
    "\n",
    "Identificação de registros duplicados exatos e tratamento adequado considerando a natureza temporal dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44273b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECÇÃO DE DUPLICATAS:\n",
      "Dataset atual: (1241768, 16)\n",
      "Duplicatas exatas encontradas: 32,571\n",
      "Remover 32,571 duplicatas exatas\n",
      "Dataset após remoção: (1209197, 16)\n",
      "\n",
      "PROPORÇÃO DAS CLASSES APÓS REMOÇÃO:\n",
      "Antes da remoção de duplicatas:\n",
      "  • SepsisLabel = 0: 1,219,435 (0.9820)\n",
      "  • SepsisLabel = 1: 22,333 (0.0180)\n",
      "Após remoção de duplicatas:\n",
      "  • SepsisLabel = 0: 1,187,303 (0.9819)\n",
      "  • SepsisLabel = 1: 21,894 (0.0181)\n",
      "\n",
      "IMPACTO NA PROPORÇÃO:\n",
      "  • Mudança SepsisLabel = 0: -0.0001\n",
      "  • Mudança SepsisLabel = 1: +0.0001\n",
      "Dataset limpo final: (1209197, 16)\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas no dataset selecionado\n",
    "print(\"DETECÇÃO DE DUPLICATAS:\")\n",
    "print(f\"Dataset atual: {X_train_selected.shape}\")\n",
    "\n",
    "# Verificar duplicatas exatas (todas as colunas)\n",
    "duplicatas_exatas = X_train_selected.duplicated().sum()\n",
    "print(f\"Duplicatas exatas encontradas: {duplicatas_exatas:,}\")\n",
    "\n",
    "print(f\"Remover {duplicatas_exatas:,} duplicatas exatas\")\n",
    "X_train_cleaned = X_train_selected.drop_duplicates()\n",
    "y_train_cleaned = y_train.loc[X_train_cleaned.index]\n",
    "print(f\"Dataset após remoção: {X_train_cleaned.shape}\")\n",
    "\n",
    "# Verificar proporção das classes após remoção de duplicatas\n",
    "print(f\"\\nPROPORÇÃO DAS CLASSES APÓS REMOÇÃO:\")\n",
    "print(\"Antes da remoção de duplicatas:\")\n",
    "original_counts = y_train.value_counts()\n",
    "original_props = y_train.value_counts(normalize=True)\n",
    "print(f\"  • SepsisLabel = 0: {original_counts[0]:,} ({original_props[0]:.4f})\")\n",
    "print(f\"  • SepsisLabel = 1: {original_counts[1]:,} ({original_props[1]:.4f})\")\n",
    "\n",
    "print(\"Após remoção de duplicatas:\")\n",
    "cleaned_counts = y_train_cleaned.value_counts()\n",
    "cleaned_props = y_train_cleaned.value_counts(normalize=True)\n",
    "print(f\"  • SepsisLabel = 0: {cleaned_counts[0]:,} ({cleaned_props[0]:.4f})\")\n",
    "print(f\"  • SepsisLabel = 1: {cleaned_counts[1]:,} ({cleaned_props[1]:.4f})\")\n",
    "\n",
    "# Calcular impacto na proporção\n",
    "prop_change_0 = cleaned_props[0] - original_props[0]\n",
    "prop_change_1 = cleaned_props[1] - original_props[1]\n",
    "print(f\"\\nIMPACTO NA PROPORÇÃO:\")\n",
    "print(f\"  • Mudança SepsisLabel = 0: {prop_change_0:+.4f}\")\n",
    "print(f\"  • Mudança SepsisLabel = 1: {prop_change_1:+.4f}\")\n",
    "\n",
    "print(f\"Dataset limpo final: {X_train_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb71fe",
   "metadata": {},
   "source": [
    "### 4.2 Tratamento e Análise de Outliers\n",
    "\n",
    "A ideia é tentar preservar os outliers visto que eles se demonstraram relevantes para a identificação de instâncias com SepsisLabel=1 na Análise Exploratória.\n",
    "Vamos apenas deixar algumas variáveis mais genéricas e conhecidas mais consistentes e fazer uma análise geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1182fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUTLIERS DETECTADOS:\n",
      "Variável     Clínicos  IQR      Z-score  N_total  Range Original       Range Tratado       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Hour         0         54,951   27,883   1,209,197 0.00-335.00          0.00-335.00         \n",
      "HR           0         11,203   5,502    1,119,122 20.00-280.00         20.00-280.00        \n",
      "O2Sat        0         19,905   8,912    1,079,707 20.00-100.00         20.00-100.00        \n",
      "Temp         0         5,223    3,392    419,945  23.00-50.00          23.00-50.00         \n",
      "SBP          0         12,748   6,046    1,060,857 20.00-300.00         20.00-300.00        \n",
      "MAP          0         17,543   8,057    1,087,236 20.00-300.00         20.00-300.00        \n",
      "DBP          0         13,033   6,560    852,691  20.00-300.00         20.00-300.00        \n",
      "Resp         0         22,208   10,343   1,051,178 1.00-100.00          1.00-100.00         \n",
      "BUN          0         7,039    2,063    85,439   1.00-268.00          1.00-268.00         \n",
      "WBC          0         2,767    514      79,613   0.10-440.00          0.10-440.00         \n",
      "Platelets    0         2,369    1,070    73,790   2.00-2322.00         2.00-2322.00        \n",
      "Gender       0         0        0        1,209,197 0.00-1.00            0.00-1.00           \n",
      "Unit1        0         0        0        737,114  0.00-1.00            0.00-1.00           \n",
      "Unit2        0         0        0        737,114  0.00-1.00            0.00-1.00           \n",
      "HospAdmTime  0         161,629  17,170   1,209,191 -5366.86-23.99       -5366.86-23.99      \n",
      "ICULOS       0         54,672   27,811   1,209,197 1.00-336.00          1.00-336.00         \n",
      "\n",
      "Total de Caps Aplicados: 0\n"
     ]
    }
   ],
   "source": [
    "# Tratamento de outliers para variáveis numéricas\n",
    "from scipy import stats\n",
    "\n",
    "# Separar variáveis numéricas do dataset limpo\n",
    "numeric_cols = X_train_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Definir limites um pouco mais realistas para algumas variáveis \n",
    "# Considerando registros de outros casos extremos e do próprio dataset\n",
    "# Propósito de deixar os dados mais consistentes\n",
    "clinical_limits = {\n",
    "    'HR': (20, 250),           # Batimentos cardíacos: 20-250 bpm\n",
    "    'Temp': (28, 42),          # Temperatura: 28-42°C\n",
    "    'Hour': (0, 336),          # Hora na UTI: 1-336h (14 dias)\n",
    "    'ICULOS': (0, 336),        # Tempo UTI: 1-336h\n",
    "    'HospAdmTime': (0, 24),   # Tempo hospital: 0 a 24h\n",
    "}\n",
    "\n",
    "outliers_summary = {}\n",
    "X_train_outliers_treated = X_train_cleaned.copy()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    data = X_train_outliers_treated[col].dropna()\n",
    "        \n",
    "    # Cap do Range (quando aplicável) -- Aplicação dos limites será feita após a primeira iteração na modelagem se necessário\n",
    "    clinical_outliers = 0\n",
    "    # if col in clinical_limits:\n",
    "    #     min_val, max_val = clinical_limits[col]\n",
    "    #     clinical_mask = (data < min_val) | (data > max_val)\n",
    "    #     clinical_outliers = clinical_mask.sum()\n",
    "    #    \n",
    "    #     # Aplicar capping\n",
    "    #     X_train_outliers_treated.loc[X_train_outliers_treated[col] < min_val, col] = min_val\n",
    "    #     X_train_outliers_treated.loc[X_train_outliers_treated[col] > max_val, col] = max_val\n",
    "    \n",
    "    # Análise do IQR\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    iqr_outliers = ((data < lower_bound) | (data > upper_bound)).sum()\n",
    "    \n",
    "    # Análise do Z-score (outliers > 3 desvios padrão)\n",
    "    z_scores = np.abs(stats.zscore(data))\n",
    "    zscore_outliers = (z_scores > 3).sum()\n",
    "    \n",
    "    outliers_summary[col] = {\n",
    "        'clinical': clinical_outliers,\n",
    "        'iqr': iqr_outliers,\n",
    "        'zscore': zscore_outliers,\n",
    "        'total_values': len(data),\n",
    "        'range_original': (data.min(), data.max()),\n",
    "        'range_treated': (X_train_outliers_treated[col].min(), X_train_outliers_treated[col].max())\n",
    "    }\n",
    "\n",
    "# Exibir resumo dos outliers\n",
    "print(f\"\\nOUTLIERS DETECTADOS:\")\n",
    "print(f\"{'Variável':<12} {'Clínicos':<9} {'IQR':<8} {'Z-score':<8} {'N_total':<8} {'Range Original':<20} {'Range Tratado':<20}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for col, summary in outliers_summary.items():\n",
    "    clinical = summary['clinical']\n",
    "    iqr = summary['iqr'] \n",
    "    zscore = summary['zscore']\n",
    "    total = summary['total_values']\n",
    "    range_orig = f\"{summary['range_original'][0]:.2f}-{summary['range_original'][1]:.2f}\"\n",
    "    range_treat = f\"{summary['range_treated'][0]:.2f}-{summary['range_treated'][1]:.2f}\"\n",
    "\n",
    "    print(f\"{col:<12} {clinical:<9,} {iqr:<8,} {zscore:<8,} {total:<8,} {range_orig:<20} {range_treat:<20}\")\n",
    "\n",
    "# Estatísticas finais\n",
    "total_clinical_corrections = sum(summary['clinical'] for summary in outliers_summary.values())\n",
    "print(f\"\\nTotal de Caps Aplicados: {total_clinical_corrections:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe2b1d",
   "metadata": {},
   "source": [
    "### 4.3 Estratégias de Imputação\n",
    "\n",
    "Implementação de diferentes técnicas de imputação baseadas no tipo de variável e percentual de missing values.\n",
    "\n",
    "**OBSERVAÇÃO:**\n",
    "As seções `4.3.1` e `4.3.2` precisam ser executadas em ordem e são necessárias para que as demais seções funcionem. Porém `4.3.3`, `4.3.4`, `4.3.5` podem ser executadas em qualquer ordem após executar `4.3.1` e `4.3.2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc5442",
   "metadata": {},
   "source": [
    "#### 4.3.1 Imputação para Variáveis com Baixo Missing (<20%)\n",
    "\n",
    "Aplicação de imputação simples usando medidas centrais apropriadas para cada tipo de variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d173ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variáveis para imputação simples:\n",
      "  • HR: 90,075 valores (7.4%)\n",
      "  • O2Sat: 129,490 valores (10.7%)\n",
      "  • SBP: 148,340 valores (12.3%)\n",
      "  • MAP: 121,961 valores (10.1%)\n",
      "  • Resp: 158,019 valores (13.1%)\n",
      "  • HospAdmTime: 6 valores (0.0%)\n",
      "\n",
      "VERIFICAÇÃO PÓS-IMPUTAÇÃO:\n",
      "  • HR: 0 valores missing restantes\n",
      "  • O2Sat: 0 valores missing restantes\n",
      "  • SBP: 0 valores missing restantes\n",
      "  • MAP: 0 valores missing restantes\n",
      "  • Resp: 0 valores missing restantes\n",
      "  • HospAdmTime: 0 valores missing restantes\n",
      "\n",
      "Total de valores imputados (simples): 647,891\n",
      "Missing values restantes: 5,478,673 (28.32%)\n"
     ]
    }
   ],
   "source": [
    "# Imputação simples para variáveis com baixo missing (<20%)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train_simple_imputed = X_train_outliers_treated.copy()\n",
    "\n",
    "# Identificar variáveis com baixo missing (<20%)\n",
    "low_missing_vars = []\n",
    "missing_info = {}\n",
    "\n",
    "print(f\"\\nVariáveis para imputação simples:\")\n",
    "for col in X_train_simple_imputed.columns:\n",
    "    missing_count = X_train_simple_imputed[col].isnull().sum()\n",
    "    missing_pct = (missing_count / len(X_train_simple_imputed)) * 100\n",
    "    missing_info[col] = missing_pct\n",
    "    \n",
    "    if missing_pct < 20 and missing_pct > 0:\n",
    "        low_missing_vars.append(col)\n",
    "        print(f\"  • {col}: {missing_count:,} valores ({missing_pct:.1f}%)\") \n",
    "\n",
    "\n",
    "# for var in low_missing_vars:\n",
    "#     missing_count = X_train_simple_imputed[var].isnull().sum()\n",
    "#     missing_pct = missing_info[var]\n",
    "#     print(f\"  • {var}: {missing_count:,} valores ({missing_pct:.1f}%)\")\n",
    "\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X_train_simple_imputed[low_missing_vars] = numeric_imputer.fit_transform(\n",
    "    X_train_simple_imputed[low_missing_vars]\n",
    ")\n",
    "\n",
    "\n",
    "# Verificar se imputação foi bem-sucedida\n",
    "print(f\"\\nVERIFICAÇÃO PÓS-IMPUTAÇÃO:\")\n",
    "for var in low_missing_vars:\n",
    "    remaining_missing = X_train_simple_imputed[var].isnull().sum()\n",
    "    print(f\"  • {var}: {remaining_missing} valores missing restantes\")\n",
    "\n",
    "total_imputed = sum(missing_info[var] * len(X_train_simple_imputed) / 100 for var in low_missing_vars)\n",
    "print(f\"\\nTotal de valores imputados (simples): {total_imputed:,.0f}\")\n",
    "\n",
    "# Resumo do missing restante\n",
    "remaining_missing = X_train_simple_imputed.isnull().sum().sum()\n",
    "total_values = X_train_simple_imputed.size\n",
    "missing_pct_remaining = (remaining_missing / total_values) * 100\n",
    "\n",
    "print(f\"Missing values restantes: {remaining_missing:,} ({missing_pct_remaining:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a48589",
   "metadata": {},
   "source": [
    "#### 4.3.2 Separando as Demais Variáveis para Imputação Avançada \n",
    "\n",
    "Para uso de técnicas mais sofisticadas como KNN Imputer ou imputação baseada em modelos para variáveis clinicamente importantes, vamos antes definir as variáveis que ainda possuem valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0004175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANÁLISE DINÂMICA DE MISSING VALUES:\n",
      "==================================================\n",
      "\n",
      "CLASSIFICAÇÃO POR ESTRATÉGIA DE IMPUTAÇÃO:\n",
      "Critério: Unit1/Unit2 = Regressão Logística | <40% = Regressão Linear | ≥40% = Híbrida\n",
      "-------------------------------------------------------------------------------------\n",
      "DBP             29.5    % ( 356,506 valores)\n",
      "Unit1           39.0    % ( 472,083 valores)\n",
      "Unit2           39.0    % ( 472,083 valores)\n",
      "Temp            65.3    % ( 789,252 valores)\n",
      "BUN             92.9    % (1,123,758 valores)\n",
      "WBC             93.4    % (1,129,584 valores)\n",
      "Platelets       93.9    % (1,135,407 valores)\n",
      "\n",
      "RESUMO DAS ESTRATÉGIAS:\n",
      "  • Regressão Logística (categóricas Unit1/Unit2): 2 variáveis\n",
      "  • Regressão Linear Simples (<40% missing numéricas): 1 variáveis\n",
      "  • Estratégia Híbrida (≥40% missing numéricas): 4 variáveis\n",
      "\n",
      "Variáveis para Regressão Logística: ['Unit1', 'Unit2']\n",
      "Variáveis para Regressão Linear: ['DBP']\n",
      "Variáveis para Estratégia Híbrida: ['Temp', 'BUN', 'WBC', 'Platelets']\n",
      "\n",
      "Variáveis preditoras selecionadas: ['Hour', 'HR', 'O2Sat', 'SBP', 'MAP', 'Resp', 'Gender', 'HospAdmTime', 'ICULOS']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_advanced_imputed = X_train_simple_imputed.copy()\n",
    "\n",
    "# ESTRATÉGIA DINÂMICA BASEADA EM MISSING ATUAL\n",
    "print(f\"\\nANÁLISE DINÂMICA DE MISSING VALUES:\")\n",
    "print(f\"=\"*50)\n",
    "\n",
    "# Identificar todas as variáveis com missing\n",
    "vars_with_missing = []\n",
    "for col in X_train_advanced_imputed.columns:\n",
    "    missing_count = X_train_advanced_imputed[col].isnull().sum()\n",
    "    missing_pct = (missing_count / len(X_train_advanced_imputed)) * 100\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        vars_with_missing.append({\n",
    "            'variavel': col,\n",
    "            'missing_count': missing_count,\n",
    "            'missing_pct': missing_pct\n",
    "        })\n",
    "\n",
    "# Separar por estratégia baseada em 40% de missing e tipo de variável\n",
    "logistic_regression_vars = []  # Unit1, Unit2: Regressão Logística (categóricas)\n",
    "linear_regression_vars = []    # < 40% missing: Regressão Linear simples (numéricas)\n",
    "hybrid_strategy_vars = []      # >= 40% missing: Estratégia Híbrida KNN + Regressão\n",
    "\n",
    "print(f\"\\nCLASSIFICAÇÃO POR ESTRATÉGIA DE IMPUTAÇÃO:\")\n",
    "print(f\"Critério: Unit1/Unit2 = Regressão Logística | <40% = Regressão Linear | ≥40% = Híbrida\")\n",
    "print(f\"-\" * 85)\n",
    "\n",
    "for var_info in sorted(vars_with_missing, key=lambda x: x['missing_pct']):\n",
    "    var = var_info['variavel']\n",
    "    missing_pct = var_info['missing_pct']\n",
    "    missing_count = var_info['missing_count']\n",
    "    \n",
    "    print(f\"{var:<15} {missing_pct:<8.1f}% ({missing_count:>8,} valores)\")\n",
    "    \n",
    "    # Separar Unit1 e Unit2 para regressão logística\n",
    "    if var in ['Unit1', 'Unit2']:\n",
    "        logistic_regression_vars.append(var)\n",
    "    elif missing_pct < 40:\n",
    "        linear_regression_vars.append(var)\n",
    "    else:\n",
    "        hybrid_strategy_vars.append(var)\n",
    "\n",
    "print(f\"\\nRESUMO DAS ESTRATÉGIAS:\")\n",
    "print(f\"  • Regressão Logística (categóricas Unit1/Unit2): {len(logistic_regression_vars)} variáveis\")\n",
    "print(f\"  • Regressão Linear Simples (<40% missing numéricas): {len(linear_regression_vars)} variáveis\")\n",
    "print(f\"  • Estratégia Híbrida (≥40% missing numéricas): {len(hybrid_strategy_vars)} variáveis\")\n",
    "\n",
    "print(f\"\\nVariáveis para Regressão Logística: {logistic_regression_vars}\")\n",
    "print(f\"Variáveis para Regressão Linear: {linear_regression_vars}\")\n",
    "print(f\"Variáveis para Estratégia Híbrida: {hybrid_strategy_vars}\")\n",
    "\n",
    "# Selecionar variáveis preditoras (sem missing ou baixo missing)\n",
    "all_vars_to_impute = logistic_regression_vars + linear_regression_vars + hybrid_strategy_vars\n",
    "predictor_vars = []\n",
    "for col in X_train_advanced_imputed.select_dtypes(include=[np.number]).columns:\n",
    "    missing_pct = (X_train_advanced_imputed[col].isnull().sum() / len(X_train_advanced_imputed)) * 100\n",
    "    if missing_pct == 0 or (missing_pct < 20 and col not in all_vars_to_impute):\n",
    "        predictor_vars.append(col)\n",
    "\n",
    "print(f\"\\nVariáveis preditoras selecionadas: {predictor_vars}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd99f40",
   "metadata": {},
   "source": [
    "#### 4.3.3 Regressão Logística para Categóricas\n",
    "\n",
    "Aqui aplicaremos o modelo de regressão logistica para imputação de Unit1 e Unit2. Mantendo a coerência do Dataset onde é mandatório que Unit1 + Unit2 = 1 para todas as instâncias (Paciente só pode ir para um dos tipos de UTI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d7854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit1 missing: 472,083 valores\n",
      "Unit2 missing: 472,083 valores\n",
      "Ambas missing: 472,083 valores\n",
      "\n",
      "ETAPA 1: Regressão Logística para Unit1\n",
      "ETAPA 2: Unit2 como complemento de Unit1\n",
      "Unit1 imputado: 472,083 valores\n",
      "Unit2 imputado: 472,083 valores (complemento)\n",
      "Distribuição Unit1 imputada: 0=169,833 | 1=302,250\n",
      "Distribuição Unit2 imputada: 0=302,250 | 1=169,833\n",
      "Verificação Unit1 + Unit2 = 1: ✓ VÁLIDA\n",
      "\n",
      "VERIFICAÇÃO PÓS-IMPUTAÇÃO LOGÍSTICA:\n",
      "  • Unit1: 0 valores missing restantes\n",
      "    Distribuição final: {0.0: np.int64(544591), 1.0: np.int64(664606)}\n",
      "  • Unit2: 0 valores missing restantes\n",
      "    Distribuição final: {0.0: np.int64(664606), 1.0: np.int64(544591)}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ETAPA 1: REGRESSÃO LOGÍSTICA PARA VARIÁVEIS CATEGÓRICAS (Unit1, Unit2)\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Identificar valores missing\n",
    "unit1_missing_mask = X_train_advanced_imputed['Unit1'].isnull()\n",
    "unit2_missing_mask = X_train_advanced_imputed['Unit2'].isnull()\n",
    "both_missing_mask = unit1_missing_mask & unit2_missing_mask\n",
    "\n",
    "unit1_missing_count = unit1_missing_mask.sum()\n",
    "unit2_missing_count = unit2_missing_mask.sum()\n",
    "both_missing_count = both_missing_mask.sum()\n",
    "\n",
    "print(f\"Unit1 missing: {unit1_missing_count:,} valores\")\n",
    "print(f\"Unit2 missing: {unit2_missing_count:,} valores\") \n",
    "print(f\"Ambas missing: {both_missing_count:,} valores\")\n",
    "\n",
    "print(f\"\\nETAPA 1: Regressão Logística para Unit1\")\n",
    "\n",
    "# Preparar dados para treino (onde Unit1 não é missing)\n",
    "complete_mask = ~X_train_advanced_imputed['Unit1'].isnull()\n",
    "training_size = min(100000, complete_mask.sum())\n",
    "\n",
    "training_indices = np.random.choice(\n",
    "    X_train_advanced_imputed[complete_mask].index,\n",
    "    size=training_size,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "# Features numéricas para predição (excluir Unit1/Unit2)\n",
    "numeric_predictors = [col for col in predictor_vars if col not in logistic_regression_vars]\n",
    "\n",
    "# Treinar modelo logístico para Unit1\n",
    "X_features = X_train_advanced_imputed.loc[training_indices, numeric_predictors]\n",
    "y_target = X_train_advanced_imputed.loc[training_indices, 'Unit1']\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_model.fit(X_features, y_target)\n",
    "\n",
    "# Prever Unit1 para registros missing\n",
    "X_missing_features = X_train_advanced_imputed.loc[both_missing_mask, numeric_predictors]\n",
    "predicted_unit1_proba = logistic_model.predict_proba(X_missing_features)[:, 1]\n",
    "predicted_unit1 = (predicted_unit1_proba > 0.5).astype(int)\n",
    "\n",
    "print(f\"ETAPA 2: Unit2 como complemento de Unit1\")\n",
    "# Unit2 como complemento lógico de Unit1\n",
    "predicted_unit2 = 1 - predicted_unit1\n",
    "\n",
    "# Aplicar imputações\n",
    "X_train_advanced_imputed.loc[both_missing_mask, 'Unit1'] = predicted_unit1\n",
    "X_train_advanced_imputed.loc[both_missing_mask, 'Unit2'] = predicted_unit2\n",
    "\n",
    "print(f\"Unit1 imputado: {both_missing_count:,} valores\")\n",
    "print(f\"Unit2 imputado: {both_missing_count:,} valores (complemento)\")\n",
    "\n",
    "# Estatísticas da imputação\n",
    "unit1_0_count = (predicted_unit1 == 0).sum()\n",
    "unit1_1_count = (predicted_unit1 == 1).sum()\n",
    "print(f\"Distribuição Unit1 imputada: 0={unit1_0_count:,} | 1={unit1_1_count:,}\")\n",
    "print(f\"Distribuição Unit2 imputada: 0={unit1_1_count:,} | 1={unit1_0_count:,}\")\n",
    "\n",
    "# Verificar relação complementar\n",
    "unit1_final = X_train_advanced_imputed.loc[both_missing_mask, 'Unit1']\n",
    "unit2_final = X_train_advanced_imputed.loc[both_missing_mask, 'Unit2']\n",
    "sum_check = (unit1_final + unit2_final == 1).all()\n",
    "print(f\"Verificação Unit1 + Unit2 = 1: {'✓ VÁLIDA' if sum_check else '✗ INVÁLIDA'}\")\n",
    "    \n",
    "# Verificação pós-imputação logística\n",
    "print(f\"\\nVERIFICAÇÃO PÓS-IMPUTAÇÃO LOGÍSTICA:\")\n",
    "for var in logistic_regression_vars:\n",
    "    if var in X_train_advanced_imputed.columns:\n",
    "        remaining_missing = X_train_advanced_imputed[var].isnull().sum()\n",
    "        print(f\"  • {var}: {remaining_missing} valores missing restantes\")\n",
    "        \n",
    "        # Distribuição final\n",
    "        if remaining_missing == 0:\n",
    "            value_counts = X_train_advanced_imputed[var].value_counts().sort_index()\n",
    "            print(f\"    Distribuição final: {dict(value_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8198a75",
   "metadata": {},
   "source": [
    "#### 4.3.4 Regressão Linear para <40% de Missing\n",
    "Aplicar regressão linear para variáveis numéricas com <40% de missing (DBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f67684c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA 2: REGRESSÃO LINEAR SIMPLES (< 40% missing)\n",
      "\n",
      "\n",
      "---------- IMPUTANDO DBP (Regressão Simples) ----------\n",
      "Missing: 356,506 valores (29.5%)\n",
      "Regressão aplicada: 356,506 valores imputados\n",
      "Valores restantes missing: 0\n",
      "Range imputado: [3.53, 257.85]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ETAPA 2: REGRESSÃO LINEAR SIMPLES (< 40% missing)\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(f\"ETAPA 2: REGRESSÃO LINEAR SIMPLES (< 40% missing)\\n\")\n",
    "\n",
    "for target_var in linear_regression_vars:\n",
    "    print(f\"\\n---------- IMPUTANDO {target_var} (Regressão Simples) ----------\")\n",
    "    \n",
    "    # Identificar valores missing\n",
    "    missing_mask = X_train_advanced_imputed[target_var].isnull()\n",
    "    total_missing = missing_mask.sum()\n",
    "    missing_pct = (total_missing / len(X_train_advanced_imputed)) * 100\n",
    "    print(f\"Missing: {total_missing:,} valores ({missing_pct:.1f}%)\")\n",
    "\n",
    "    # Preparar dados para regressão\n",
    "    complete_mask = ~X_train_advanced_imputed[target_var].isnull()\n",
    "    training_size = min(100000, complete_mask.sum())  # Até 100k para treino\n",
    "    \n",
    "    training_indices = np.random.choice(\n",
    "        X_train_advanced_imputed[complete_mask].index,\n",
    "        size=training_size,\n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Features e target para treino\n",
    "    X_features = X_train_advanced_imputed.loc[training_indices, predictor_vars]\n",
    "    y_target = X_train_advanced_imputed.loc[training_indices, target_var]\n",
    "    \n",
    "    # Treinar modelo de regressão\n",
    "    reg_model = LinearRegression()\n",
    "    reg_model.fit(X_features, y_target)\n",
    "    \n",
    "    # Prever todos os valores missing\n",
    "    X_missing_features = X_train_advanced_imputed.loc[missing_mask, predictor_vars]\n",
    "    predicted_values = reg_model.predict(X_missing_features)\n",
    "    \n",
    "    # Aplicar imputação\n",
    "    X_train_advanced_imputed.loc[missing_mask, target_var] = predicted_values\n",
    "    \n",
    "    # Verificar resultado\n",
    "    final_missing = X_train_advanced_imputed[target_var].isnull().sum()\n",
    "    print(f\"Regressão aplicada: {total_missing:,} valores imputados\")\n",
    "    print(f\"Valores restantes missing: {final_missing}\")\n",
    "    print(f\"Range imputado: [{predicted_values.min():.2f}, {predicted_values.max():.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55862465",
   "metadata": {},
   "source": [
    "#### 4.3.5 KNNImputer + Regressão Linear para >=40% de Missing\n",
    "Aplicação do KNNImputer com 3 vizinhos para amostra de ~5% dos valores da coluna e Regressão Linear para os outros ~95%.\n",
    "\n",
    "Esse código abaixo demora em torno de 5-6min para executar. Tomar ciência disso antes rodar a célula de código abaixo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d936d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== IMPUTANDO Temp ==========\n",
      "Total de valores missing: 789,252\n",
      "\n",
      "ETAPA 1 - KNN Imputer (39,462 valores - 5%)\n",
      "  KNN aplicado com sucesso: 39,462 valores\n",
      "\n",
      "ETAPA 2 - Regressão Linear (749,790 valores - 95%)\n",
      "  Regressão aplicada com sucesso: 749,790 valores\n",
      "  Valores missing restantes: 0\n",
      "  Imputação híbrida completa para Temp!\n",
      "\n",
      "========== IMPUTANDO BUN ==========\n",
      "Total de valores missing: 1,123,758\n",
      "\n",
      "ETAPA 1 - KNN Imputer (50,000 valores - 5%)\n",
      "  KNN aplicado com sucesso: 50,000 valores\n",
      "\n",
      "ETAPA 2 - Regressão Linear (1,073,758 valores - 95%)\n",
      "  Regressão aplicada com sucesso: 1,073,758 valores\n",
      "  Valores missing restantes: 0\n",
      "  Imputação híbrida completa para BUN!\n",
      "\n",
      "========== IMPUTANDO WBC ==========\n",
      "Total de valores missing: 1,129,584\n",
      "\n",
      "ETAPA 1 - KNN Imputer (50,000 valores - 5%)\n",
      "  KNN aplicado com sucesso: 50,000 valores\n",
      "\n",
      "ETAPA 2 - Regressão Linear (1,079,584 valores - 95%)\n",
      "  Regressão aplicada com sucesso: 1,079,584 valores\n",
      "  Valores missing restantes: 0\n",
      "  Imputação híbrida completa para WBC!\n",
      "\n",
      "========== IMPUTANDO Platelets ==========\n",
      "Total de valores missing: 1,135,407\n",
      "\n",
      "ETAPA 1 - KNN Imputer (50,000 valores - 5%)\n",
      "  KNN aplicado com sucesso: 50,000 valores\n",
      "\n",
      "ETAPA 2 - Regressão Linear (1,085,407 valores - 95%)\n",
      "  Regressão aplicada com sucesso: 1,085,407 valores\n",
      "  Valores missing restantes: 0\n",
      "  Imputação híbrida completa para Platelets!\n",
      "Imputação Concluída!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ETAPA 3: ESTRATÉGIA HÍBRIDA (≥ 40% missing)  \n",
    "# =============================================================================\n",
    "\n",
    "# Imputação avançada híbrida: KNN + Regressão Linear\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Implementar estratégia híbrida para cada variável\n",
    "for target_var in hybrid_strategy_vars:\n",
    "    print(f\"\\n========== IMPUTANDO {target_var} ==========\")\n",
    "    \n",
    "    # Identificar valores missing\n",
    "    missing_mask = X_train_advanced_imputed[target_var].isnull()\n",
    "    total_missing = missing_mask.sum()\n",
    "    print(f\"Total de valores missing: {total_missing:,}\")\n",
    "    \n",
    "    # ETAPA 1: Imputação com KNN (5% dos missing values - otimizado)\n",
    "    knn_sample_size = min(50000, int(total_missing * 0.05))  # Máximo 50k valores\n",
    "    print(f\"\\nETAPA 1 - KNN Imputer ({knn_sample_size:,} valores - 5%)\")\n",
    "    \n",
    "    # Selecionar amostra aleatória dos índices missing para KNN\n",
    "    missing_indices = X_train_advanced_imputed[missing_mask].index\n",
    "    knn_indices = np.random.choice(missing_indices, size=knn_sample_size, replace=False)\n",
    "    \n",
    "    # Preparar subset para KNN (incluir valores não-missing para treino)\n",
    "    mask_not_missing = ~X_train_advanced_imputed[target_var].isnull()\n",
    "    knn_training_size = min(10000, mask_not_missing.sum())  # Reduzir para 10k treino\n",
    "    training_indices = np.random.choice(\n",
    "        X_train_advanced_imputed[mask_not_missing].index, \n",
    "        size=knn_training_size, \n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Combinar índices para KNN: treino + amostra para imputação\n",
    "    knn_all_indices = np.concatenate([training_indices, knn_indices])\n",
    "    knn_subset = X_train_advanced_imputed.loc[knn_all_indices, predictor_vars + [target_var]].copy()\n",
    "    \n",
    "    # Aplicar KNN apenas no subset\n",
    "    knn_imputer = KNNImputer(n_neighbors=3, weights='uniform')\n",
    "    knn_imputed = knn_imputer.fit_transform(knn_subset)\n",
    "    \n",
    "    # Extrair valores imputados para a variável alvo\n",
    "    target_col_idx = list(knn_subset.columns).index(target_var)\n",
    "    knn_imputed_values = knn_imputed[-knn_sample_size:, target_col_idx]\n",
    "    \n",
    "    # Atualizar valores no dataset\n",
    "    X_train_advanced_imputed.loc[knn_indices, target_var] = knn_imputed_values\n",
    "    print(f\"  KNN aplicado com sucesso: {knn_sample_size:,} valores\")\n",
    "    \n",
    "    # ETAPA 2: Imputação com Regressão Linear (95% restante)\n",
    "    remaining_missing_mask = X_train_advanced_imputed[target_var].isnull()\n",
    "    remaining_missing_count = remaining_missing_mask.sum()\n",
    "    print(f\"\\nETAPA 2 - Regressão Linear ({remaining_missing_count:,} valores - 95%)\")\n",
    "    \n",
    "    # Preparar dados para regressão (usar todos os dados completos)\n",
    "    complete_mask = ~X_train_advanced_imputed[target_var].isnull()\n",
    "    reg_training_size = min(50000, complete_mask.sum())\n",
    "    \n",
    "    reg_training_indices = np.random.choice(\n",
    "        X_train_advanced_imputed[complete_mask].index,\n",
    "        size=reg_training_size,\n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Features e target para treino\n",
    "    X_features = X_train_advanced_imputed.loc[reg_training_indices, predictor_vars]\n",
    "    y_target = X_train_advanced_imputed.loc[reg_training_indices, target_var]\n",
    "    \n",
    "    # Treinar modelo de regressão\n",
    "    reg_model = LinearRegression()\n",
    "    reg_model.fit(X_features, y_target)\n",
    "    \n",
    "    # Prever valores restantes\n",
    "    X_missing_features = X_train_advanced_imputed.loc[remaining_missing_mask, predictor_vars]\n",
    "    predicted_values = reg_model.predict(X_missing_features)\n",
    "    \n",
    "    X_train_advanced_imputed.loc[remaining_missing_mask, target_var] = predicted_values\n",
    "    print(f\"  Regressão aplicada com sucesso: {remaining_missing_count:,} valores\")\n",
    "            \n",
    "    \n",
    "    # Verificar se imputação foi completa\n",
    "    final_missing = X_train_advanced_imputed[target_var].isnull().sum()\n",
    "    print(f\"  Valores missing restantes: {final_missing}\")\n",
    "    print(f\"  Imputação híbrida completa para {target_var}!\")\n",
    "\n",
    "print(\"Imputação Concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f67ae7",
   "metadata": {},
   "source": [
    "#### 4.3.6 (Não Rodar por agora) Aplicando os Limites Pós-Imputação com 2 modelos\n",
    "\n",
    "Definimos o range de valores segundo a análise feita na seção 4.2 para não permitir que nenhum outlier imputado ultrapasse o intervalo observado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APLICAÇÃO DE CAPS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"APLICAÇÃO DE CAPS PÓS-IMPUTAÇÃO\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "# Definir ranges tratados do outliers_summary (Seção 4.2)\n",
    "caps_ranges = {\n",
    "    'Temp': {'min': 28.00, 'max': 42.00},\n",
    "    'BUN': {'min': 1.00, 'max': 268.00},\n",
    "    'WBC': {'min': 0.10, 'max': 440.00},\n",
    "    'Platelets': {'min': 2.00, 'max': 2322.00},\n",
    "    'DBP': {'min': 20.00, 'max': 300.00}\n",
    "}\n",
    "\n",
    "# Aplicar caps nas variáveis imputadas\n",
    "total_caps_applied = 0\n",
    "\n",
    "for var in caps_ranges.keys():\n",
    "    if var in X_train_advanced_imputed.columns:\n",
    "        min_cap = caps_ranges[var]['min']\n",
    "        max_cap = caps_ranges[var]['max']\n",
    "        \n",
    "        # Contabilizar valores fora dos limites antes da correção\n",
    "        below_min = (X_train_advanced_imputed[var] < min_cap).sum()\n",
    "        above_max = (X_train_advanced_imputed[var] > max_cap).sum()\n",
    "        total_corrections = below_min + above_max\n",
    "        \n",
    "        if total_corrections > 0:\n",
    "            print(f\"  • {var}: {below_min:,} valores < {min_cap}, {above_max:,} valores > {max_cap}\")\n",
    "            \n",
    "            # Aplicar caps\n",
    "            X_train_advanced_imputed[var] = X_train_advanced_imputed[var].clip(\n",
    "                lower=min_cap, \n",
    "                upper=max_cap\n",
    "            )\n",
    "            \n",
    "            total_caps_applied += total_corrections\n",
    "        else:\n",
    "            print(f\"  • {var}: Nenhuma correção necessária\")\n",
    "\n",
    "print(f\"\\nTotal de caps aplicados: {total_caps_applied:,}\")\n",
    "\n",
    "# Verificar ranges após caps\n",
    "print(f\"\\nRANGES APÓS APLICAÇÃO DE CAPS:\")\n",
    "for var in caps_ranges.keys():\n",
    "    if var in X_train_advanced_imputed.columns:\n",
    "        min_val = X_train_advanced_imputed[var].min()\n",
    "        max_val = X_train_advanced_imputed[var].max()\n",
    "        print(f\"  • {var}: {min_val:.2f} - {max_val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf38c5",
   "metadata": {},
   "source": [
    "#### 4.3.6 Verificação Final Pós-Imputação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782dd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICAÇÃO FINAL PÓS-IMPUTAÇÃO\n",
      "============================================================\n",
      "\n",
      "VALIDAÇÃO DE RANGES PÓS-IMPUTAÇÃO:\n",
      "  • DBP: min=3.53, max=300.00, mean=62.69\n",
      "  • Temp: min=23.00, max=50.00, mean=36.96\n",
      "  • BUN: min=-6.65, max=268.00, mean=24.17\n",
      "  • WBC: min=0.10, max=440.00, mean=11.31\n",
      "  • Platelets: min=-223.76, max=2322.00, mean=196.36\n",
      "  • Unit1: min=0.00, max=1.00, mean=0.55\n",
      "  • Unit2: min=0.00, max=1.00, mean=0.45\n",
      "\n",
      "VERIFICAÇÃO GERAL DE MISSING:\n",
      "NENHUMA VARIÁVEL COM MISSING RESTANTE!\n",
      "\n",
      "Dataset após imputações: (1209197, 16)\n",
      "Missing values finais: 0 (0.000%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nVALIDAÇÃO DE RANGES PÓS-IMPUTAÇÃO:\")\n",
    "\n",
    "# Variáveis processadas\n",
    "numeric_processed = linear_regression_vars + hybrid_strategy_vars + logistic_regression_vars\n",
    "for var in numeric_processed:\n",
    "    if var in X_train_advanced_imputed.columns:\n",
    "        min_val = X_train_advanced_imputed[var].min()\n",
    "        max_val = X_train_advanced_imputed[var].max()\n",
    "        mean_val = X_train_advanced_imputed[var].mean()\n",
    "        print(f\"  • {var}: min={min_val:.2f}, max={max_val:.2f}, mean={mean_val:.2f}\")\n",
    "\n",
    "\n",
    "# Verificar se ainda há variáveis com missing\n",
    "print(f\"\\nVERIFICAÇÃO GERAL DE MISSING:\")\n",
    "total_vars_with_missing = 0\n",
    "for col in X_train_advanced_imputed.columns:\n",
    "    missing_count = X_train_advanced_imputed[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / len(X_train_advanced_imputed)) * 100\n",
    "        print(f\"  • {col}: {missing_count:,} valores ({missing_pct:.1f}%)\")\n",
    "        total_vars_with_missing += 1\n",
    "\n",
    "\n",
    "print(f\"\\nDataset após imputações: {X_train_advanced_imputed.shape}\")\n",
    "\n",
    "# Status final do missing\n",
    "final_missing = X_train_advanced_imputed.isnull().sum().sum()\n",
    "total_values = X_train_advanced_imputed.size\n",
    "final_missing_pct = (final_missing / total_values) * 100\n",
    "\n",
    "print(f\"Missing values finais: {final_missing:,} ({final_missing_pct:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc4c04",
   "metadata": {},
   "source": [
    "### 4.4 Validação da Qualidade Pós-Limpeza\n",
    "\n",
    "Aplicação de regressão logística para imputação de variáveis categóricas Unit1 e Unit2, mantendo a relação complementar Unit1 + Unit2 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff98118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDAÇÃO DA QUALIDADE PÓS-LIMPEZA:\n",
      "1. VERIFICAÇÃO DE COMPLETUDE:\n",
      "   • Total de valores missing: 0\n",
      "   • Percentual de missing: 0.0000%\n",
      "   • Completude do dataset: 100.0000%\n",
      "\n",
      "3. VERIFICAÇÃO DE DISTRIBUIÇÕES:\n",
      "   • Variáveis numéricas analisadas: 16\n",
      "   • Estatísticas das principais variáveis:\n",
      "     Variável     Mean     Median   Std      Min      Max      Skew  \n",
      "     ------------------------------------------------------------\n",
      "     Hour         25.8     20.0     29.1     0.0      335.0    4.08  \n",
      "     HR           84.5     83.5     16.7     20.0     280.0    0.46  \n",
      "     O2Sat        97.3     98.0     2.8      20.0     100.0    -4.34 \n",
      "     Temp         37.0     36.9     0.5      23.0     50.0     -0.30 \n",
      "     SBP          123.4    121.0    21.8     20.0     300.0    0.64  \n",
      "     MAP          82.2     80.0     15.5     20.0     300.0    1.13  \n",
      "     DBP          62.7     61.0     13.0     3.5      300.0    1.14  \n",
      "     Resp         18.6     18.0     4.8      1.0      100.0    1.10  \n",
      "     BUN          24.2     23.6     6.8      -6.7     268.0    5.20  \n",
      "     WBC          11.3     11.2     2.4      0.1      440.0    35.67 \n",
      "     Platelets    196.4    195.8    30.5     -223.8   2322.0   4.52  \n",
      "     Gender       0.6      1.0      0.5      0.0      1.0      -0.24 \n",
      "     Unit1        0.5      1.0      0.5      0.0      1.0      -0.20 \n",
      "     Unit2        0.5      0.0      0.5      0.0      1.0      0.20  \n",
      "     HospAdmTime  -57.6    -6.5     163.4    -5366.9  24.0     -12.03\n",
      "     ICULOS       27.3     21.0     29.3     1.0      336.0    4.09  \n",
      "\n",
      "4. VERIFICAÇÃO DE INTEGRIDADE:\n",
      "   • Shape do X_train: (1209197, 16)\n",
      "   • Shape do y_train: (1209197,)\n",
      "   • Índices alinhados: True\n"
     ]
    }
   ],
   "source": [
    "# Validação da qualidade dos dados após todas as etapas de limpeza\n",
    "\n",
    "print(\"VALIDAÇÃO DA QUALIDADE PÓS-LIMPEZA:\")\n",
    "\n",
    "X_train_final_cleaned = X_train_advanced_imputed.copy()\n",
    "y_train_final_cleaned = y_train_cleaned.copy()\n",
    "\n",
    "# 1. Verificação de Completude\n",
    "print(\"1. VERIFICAÇÃO DE COMPLETUDE:\")\n",
    "total_missing = X_train_final_cleaned.isnull().sum().sum()\n",
    "total_values = X_train_final_cleaned.size\n",
    "missing_pct = (total_missing / total_values) * 100\n",
    "\n",
    "print(f\"   • Total de valores missing: {total_missing:,}\")\n",
    "print(f\"   • Percentual de missing: {missing_pct:.4f}%\")\n",
    "print(f\"   • Completude do dataset: {100-missing_pct:.4f}%\")\n",
    "\n",
    "if total_missing > 0:\n",
    "    print(\"   • Variáveis com missing restante:\")\n",
    "    for col in X_train_final_cleaned.columns:\n",
    "        missing_count = X_train_final_cleaned[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            missing_pct_col = (missing_count / len(X_train_final_cleaned)) * 100\n",
    "            print(f\"     - {col}: {missing_count:,} ({missing_pct_col:.2f}%)\")\n",
    "\n",
    "\n",
    "# 3. Verificação de Distribuições\n",
    "print(f\"\\n3. VERIFICAÇÃO DE DISTRIBUIÇÕES:\")\n",
    "\n",
    "# Análise estatística básica para variáveis numéricas\n",
    "numeric_cols = X_train_final_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"   • Variáveis numéricas analisadas: {len(numeric_cols)}\")\n",
    "\n",
    "distributions_summary = {}\n",
    "for col in numeric_cols:  # Primeiras 5 variáveis para exemplo\n",
    "    data = X_train_final_cleaned[col].dropna()\n",
    "    if len(data) > 0:\n",
    "        distributions_summary[col] = {\n",
    "            'mean': data.mean(),\n",
    "            'median': data.median(),  \n",
    "            'std': data.std(),\n",
    "            'min': data.min(),\n",
    "            'max': data.max(),\n",
    "            'skewness': data.skew()\n",
    "        }\n",
    "\n",
    "print(f\"   • Estatísticas das principais variáveis:\")\n",
    "print(f\"     {'Variável':<12} {'Mean':<8} {'Median':<8} {'Std':<8} {'Min':<8} {'Max':<8} {'Skew':<6}\")\n",
    "print(\"     \" + \"-\"*60)\n",
    "\n",
    "for var, stats in distributions_summary.items():\n",
    "    print(f\"     {var:<12} {stats['mean']:<8.1f} {stats['median']:<8.1f} {stats['std']:<8.1f} {stats['min']:<8.1f} {stats['max']:<8.1f} {stats['skewness']:<6.2f}\")\n",
    "\n",
    "# 4. Verificação de Integridade Referencial\n",
    "print(f\"\\n4. VERIFICAÇÃO DE INTEGRIDADE:\")\n",
    "print(f\"   • Shape do X_train: {X_train_final_cleaned.shape}\")\n",
    "print(f\"   • Shape do y_train: {y_train_final_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547ba43",
   "metadata": {},
   "source": [
    "## 5. Construção dos Dados (Feature Engineering)\n",
    "\n",
    "**Objetivo:** Criar novas variáveis ou atributos derivados dos dados existentes que possam melhorar o poder preditivo do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b47e5",
   "metadata": {},
   "source": [
    "### 5.1 Criação de função para validação da criação da feature\n",
    "\n",
    "Desenvolvimento de índices e ratios clinicamente estabelecidos para detecção de sepsis (ex: razão neutrófilos/linfócitos, índices de choque).\n",
    "\n",
    "A função demora um pouco a terminar sua execução por causa do modelo utilizado (~1min45s por feature para uma amostra de 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f3254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset base para Feature Engineering: (1209197, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Dataset base para feature engineering\n",
    "X_train_fe = X_train_final_cleaned.copy()\n",
    "y_train_fe = y_train_final_cleaned.copy()\n",
    "\n",
    "print(f\"Dataset base para Feature Engineering: {X_train_fe.shape}\")\n",
    "\n",
    "# 1. FUNÇÃO DE VALIDAÇÃO POR Modelo\n",
    "# Tenta-se fazer previsões, sem normalização/padronização, utilizando o dataset resultante da limpeza e \n",
    "# o que possui as features que se quer criar e compara-se os ganhos/perdas \n",
    "\n",
    "def validate_feature(X_original, X_with_new_feature, y, feature_name, cv_folds=3, \n",
    "                     sample_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Valida se uma nova feature melhora as métricas do modelo\n",
    "    \"\"\"\n",
    "    print(f\"\\nVALIDANDO FEATURE: {feature_name}\")\n",
    "    \n",
    "    _, X_orig_sample, _, X_new_sample, _, y_sample = train_test_split(\n",
    "        X_original, X_with_new_feature, y,\n",
    "        test_size=sample_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Modelo simples para validação rápida\n",
    "    rf = RandomForestClassifier(n_estimators=50, random_state=random_state, n_jobs=-1)\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Métricas com dataset original\n",
    "    precision_orig = cross_val_score(rf, X_orig_sample, y_sample, cv=cv, scoring='precision', n_jobs=-1)\n",
    "    recall_orig = cross_val_score(rf, X_orig_sample, y_sample, cv=cv, scoring='recall', n_jobs=-1)\n",
    "    f1_orig = cross_val_score(rf, X_orig_sample, y_sample, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "    # Métricas com nova feature\n",
    "    precision_new = cross_val_score(rf, X_new_sample, y_sample, cv=cv, scoring='precision', n_jobs=-1)\n",
    "    recall_new = cross_val_score(rf, X_new_sample, y_sample, cv=cv, scoring='recall', n_jobs=-1)\n",
    "    f1_new = cross_val_score(rf, X_new_sample, y_sample, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "    # Calcular melhorias\n",
    "    precision_improvement = precision_new.mean() - precision_orig.mean()\n",
    "    recall_improvement = recall_new.mean() - recall_orig.mean()\n",
    "    f1_improvement = f1_new.mean() - f1_orig.mean()\n",
    "    \n",
    "    print(f\"  Precision: {precision_orig.mean():.4f} → {precision_new.mean():.4f} ({precision_improvement:+.4f})\")\n",
    "    print(f\"  Recall:    {recall_orig.mean():.4f} → {recall_new.mean():.4f} ({recall_improvement:+.4f})\")\n",
    "    print(f\"  F1-Score:  {f1_orig.mean():.4f} → {f1_new.mean():.4f} ({f1_improvement:+.4f})\")\n",
    "    \n",
    "    # Critério de aceitação: melhoria em pelo menos 1 métrica sem deteriorar outras significativamente\n",
    "    improvements = [precision_improvement, recall_improvement, f1_improvement]\n",
    "    positive_improvements = sum(1 for imp in improvements if imp > 0.001)  # Melhoria mínima de 0.1%\n",
    "    negative_improvements = sum(1 for imp in improvements if imp < -0.005)  # Deterioração máxima de 0.5%\n",
    "    \n",
    "    is_good = positive_improvements >= 1 and negative_improvements == 0\n",
    "    \n",
    "    print(f\"  DECISÃO: {'✅ ACEITAR' if is_good else '❌ REJEITAR'}\")\n",
    "    \n",
    "    return is_good, {\n",
    "        'precision_improvement': precision_improvement,\n",
    "        'recall_improvement': recall_improvement,\n",
    "        'f1_improvement': f1_improvement\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf11848",
   "metadata": {},
   "source": [
    "### 5.2 Features Temporais\n",
    "\n",
    "Criação de variáveis derivadas das informações temporais para capturar padrões de risco ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6c71a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDANDO FEATURE: Critical_Risk_Window\n",
      "  Precision: 0.5657 → 0.6016 (+0.0359)\n",
      "  Recall:    0.0093 → 0.0104 (+0.0011)\n",
      "  F1-Score:  0.0183 → 0.0203 (+0.0021)\n",
      "  DECISÃO: ✅ ACEITAR\n",
      "\n",
      "VALIDANDO FEATURE: Time_Category\n",
      "  Precision: 0.6016 → 0.6346 (+0.0330)\n",
      "  Recall:    0.0104 → 0.0107 (+0.0003)\n",
      "  F1-Score:  0.0203 → 0.0210 (+0.0006)\n",
      "  DECISÃO: ✅ ACEITAR\n",
      "\n",
      "ACEITAS (2):\n",
      "  • Critical_Risk_Window\n",
      "  • Time_Category\n",
      "\n",
      "REJEITADAS (0):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature 1: Janela de Risco Crítico (>100h baseado na EDA)\n",
    "\n",
    "X_test = X_train_fe.copy()\n",
    "X_test['Critical_Risk_Window'] = (X_test['Hour'] > 100).astype(int)\n",
    "\n",
    "is_good, metrics = validate_feature(X_train_fe, X_test, y_train_fe, 'Critical_Risk_Window')\n",
    "\n",
    "if is_good:\n",
    "    X_train_fe['Critical_Risk_Window'] = X_test['Critical_Risk_Window']\n",
    "\n",
    "# Feature 2: Categorização de Urgência por Tempo\n",
    "\n",
    "# Criar categorias mais simples: Early, Medium, High Risk\n",
    "X_test['Time_Category'] = pd.cut(\n",
    "    X_test['Hour'],\n",
    "    bins=[-1, 24, 100, float('inf')], \n",
    "    labels=[0, 1, 2],  # Early, Medium, High\n",
    "    include_lowest=True\n",
    ").astype(int)\n",
    "\n",
    "is_good, metrics = validate_feature(X_train_fe, X_test, y_train_fe, 'Time_Category')\n",
    "\n",
    "if is_good:\n",
    "    X_train_fe['Time_Category'] = X_test['Time_Category']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d933b",
   "metadata": {},
   "source": [
    "**Features Criadas**\n",
    "\n",
    "1. Critical_Risk_Window\n",
    "  - Precision: 0.5657 → 0.6016 (+0.0359)\n",
    "  - Recall:    0.0093 → 0.0104 (+0.0011)\n",
    "  - F1-Score:  0.0183 → 0.0203 (+0.0021)\n",
    "\n",
    "2. Time_Category\n",
    "  - Precision: 0.5657 → 0.6464 (+0.0807)\n",
    "  - Recall:    0.0093 → 0.0105 (+0.0012)\n",
    "  - F1-Score:  0.0183 → 0.0207 (+0.0024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63655ae0",
   "metadata": {},
   "source": [
    "### 5.3 Interações entre as Demais Variáveis \n",
    "\n",
    "Criação de features que capturam interações sinérgicas entre variáveis clínicas relacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd20a35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas SBP ou MAP não encontradas\n",
      "\n",
      "VALIDANDO FEATURE: Shock_Index\n",
      "  Precision: 0.6346 → 0.5934 (-0.0412)\n",
      "  Recall:    0.0107 → 0.0099 (-0.0008)\n",
      "  F1-Score:  0.0210 → 0.0195 (-0.0015)\n",
      "  DECISÃO: ❌ REJEITAR\n"
     ]
    }
   ],
   "source": [
    "# REDUÇÃO DE REDUNDÂNCIA: FUSÃO SBP + MAP  (variáveis com alta correlação: >0.7)\n",
    "\n",
    "# Verificar correlação\n",
    "if 'SBP' not in X_train_fe.columns or 'MAP' not in X_train_fe.columns:\n",
    "    print('Colunas SBP ou MAP não encontradas')\n",
    "else:\n",
    "    corr_sbp_map = X_train_fe['SBP'].corr(X_train_fe['MAP'])\n",
    "    print(f\"Correlação SBP vs MAP: {corr_sbp_map:.4f}\")\n",
    "\n",
    "    # Criar feature fusionada (MAP é mais diretamente relevante clinicamente)\n",
    "    # Usar MAP como base e ajustar com informação de SBP\n",
    "    X_train_fe['Pressure_Unified'] = 0.7 * X_train_fe['MAP'] + 0.3 * X_train_fe['SBP']\n",
    "\n",
    "    # Validar fusão\n",
    "    is_good, metrics = validate_feature(\n",
    "        X_train_fe[['SBP', 'MAP']], \n",
    "        X_train_fe[['Pressure_Unified']], \n",
    "        y_train_fe, \n",
    "        'Pressure_Unified'\n",
    "    )\n",
    "\n",
    "    if is_good:\n",
    "        print(\"Fusão aceita - removendo SBP e MAP originais\")\n",
    "        X_train_fe.drop(columns=['SBP', 'MAP'], inplace=True)\n",
    "    else:\n",
    "        print(\"Fusão rejeitada - mantendo variáveis originais\")\n",
    "        X_train_fe.drop(columns=['Pressure_Unified'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5e133",
   "metadata": {},
   "source": [
    "**Features Criadas**\n",
    "\n",
    "1. Pressure_Unified (média ponderada de SBP+MAP):\n",
    "\n",
    "  - Precision: 0.0231 → 0.0616 (+0.0385)\n",
    "  - Recall:    0.0009 → 0.0009 (+0.0000)\n",
    "  - F1-Score:  0.0018 → 0.0018 (+0.0000)\n",
    "\n",
    "O resultado foi remoção de SBP e MAP e a criação de Pressure_Unified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e5a52",
   "metadata": {},
   "source": [
    "### 5.4 Análise do Resultado do Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d56d3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ANÁLISE QUANTITATIVA:\n",
      "Features originais (após limpeza): 16\n",
      "Features finais (após engineering): 17\n",
      "Saldo features criadas: 1\n",
      "\n",
      "2. FEATURES CRIADAS E VALIDADAS:\n",
      "Features aceitas por validação de métricas:\n",
      "   1. Pressure_Unified\n",
      "   2. Critical_Risk_Window\n",
      "   3. Time_Category\n",
      "\n",
      "3. ANÁLISE DE CORRELAÇÃO COM TARGET:\n",
      "Correlações das novas features com SepsisLabel:\n",
      "   1. Critical_Risk_Window: 0.1233\n",
      "   2. Time_Category: 0.0818\n",
      "   3. Pressure_Unified: 0.0164\n",
      "\n",
      "4. VALIDAÇÃO FINAL DE QUALIDADE:\n",
      "  • Total de valores missing: 0\n",
      "  • Alinhamento com target: True\n",
      "  • Distribuição target: 0=1,187,303, 1=21,894\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train_fe.head())\n",
    "\n",
    "# 1. ANÁLISE QUANTITATIVA DAS FEATURES CRIADAS==\n",
    "\n",
    "print(\"\\n1. ANÁLISE QUANTITATIVA:\")\n",
    "original_features = X_train_final_cleaned.shape[1]\n",
    "final_features = X_train_fe.shape[1]\n",
    "new_features = final_features - original_features\n",
    "\n",
    "print(f\"Features originais (após limpeza): {original_features}\")\n",
    "print(f\"Features finais (após engineering): {final_features}\")\n",
    "print(f\"Saldo features criadas: {new_features}\")\n",
    "\n",
    "# 2. LISTA DAS FEATURES VALIDADAS\n",
    "\n",
    "print(\"\\n2. FEATURES CRIADAS E VALIDADAS:\")\n",
    "\n",
    "all_new_features = []\n",
    "for col in X_train_fe.columns:\n",
    "    if col not in X_train_final_cleaned.columns:\n",
    "        all_new_features.append(col)\n",
    "\n",
    "if all_new_features:\n",
    "    print(\"Features aceitas por validação de métricas:\")\n",
    "    for i, feature in enumerate(all_new_features, 1):\n",
    "        print(f\"  {i:2d}. {feature}\")\n",
    "else:\n",
    "    print(\"Nenhuma feature adicional foi validada como benéfica\")\n",
    "\n",
    "# 3. ANÁLISE DE CORRELAÇÃO COM TARGET\n",
    "\n",
    "print(\"\\n3. ANÁLISE DE CORRELAÇÃO COM TARGET:\")\n",
    "\n",
    "# Calcular correlação das novas features com SepsisLabel\n",
    "correlations = []\n",
    "for col in all_new_features:\n",
    "    if col in X_train_fe.columns:\n",
    "        try:\n",
    "            corr = X_train_fe[col].corr(y_train_fe)\n",
    "            if not np.isnan(corr):\n",
    "                correlations.append((col, abs(corr)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if correlations:\n",
    "    # Ordenar por correlação absoluta\n",
    "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"Correlações das novas features com SepsisLabel:\")\n",
    "    for i, (feature, corr) in enumerate(correlations):\n",
    "        print(f\"  {i+1:2d}. {feature}: {corr:.4f}\")\n",
    "else:\n",
    "    print(\"Nenhuma nova feature para análise de correlação\")\n",
    "\n",
    "# 4. VALIDAÇÃO FINAL DE QUALIDADE\n",
    "\n",
    "print(\"\\n4. VALIDAÇÃO FINAL DE QUALIDADE:\")\n",
    "\n",
    "# Verificar se há problemas no dataset final\n",
    "total_missing = X_train_fe.isnull().sum().sum()\n",
    "infinite_values = np.isinf(X_train_fe.select_dtypes(include=[np.number])).sum().sum()\n",
    "\n",
    "print(f\"  • Total de valores missing: {total_missing:,}\")\n",
    "print(f\"  • Alinhamento com target: {X_train_fe.index.equals(y_train_fe.index)}\")\n",
    "\n",
    "# Distribuição do target\n",
    "target_dist = y_train_fe.value_counts()\n",
    "print(f\"  • Distribuição target: 0={target_dist[0]:,}, 1={target_dist[1]:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461dc2e4",
   "metadata": {},
   "source": [
    "## 6. Formatação dos Dados\n",
    "\n",
    "**Objetivo:** Preparar os dados no formato necessário para os algoritmos de modelagem, incluindo transformações para aproximar distribuições normais, normalização e padronização de variáveis.\n",
    "\n",
    "**Estratégia de Transformações:**\n",
    "* Teste sistemático de transformações (Log, Box-Cox, Yeo-Johnson, Square Root)\n",
    "* Validação estatística da normalidade (Anderson-Darling, Kolmogorov-Smirnov)  \n",
    "* Comparação visual das distribuições antes/depois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a184124",
   "metadata": {},
   "source": [
    "### 6.1 Transformações Gaussianas e Padronização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d039f",
   "metadata": {},
   "source": [
    "#### 6.1.1 Funções para Testar e Validar Transformações \n",
    "\n",
    "Função que cria os dados das distribuições transformadas e métricas associadas.\n",
    "Possui duas funções auxiliares:\n",
    "   - `calculate_normality_metrics()`: usa testes estatísticos (Anderson-Darling, Kolmogorov-Smirnov) bem como Assimetria e Curtose para dar um score de normalidade\n",
    "   - `plot_transformations()`: faz o plot Q-Q das distribuições transformadas comparando com a orginial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ade6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import boxcox, anderson, kstest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def validate_normality_transformations(data, column_name, sample_size=300000, \n",
    "                                     plot_results=True, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Testa múltiplas transformações (Logarítmica, Raiz Quadrada, Box-Cox, Yeo-Johnson) para aproximar dados de distribuição normal\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data : pd.Series or np.array\n",
    "        Dados originais a serem transformados\n",
    "    column_name : str\n",
    "        Nome da variável para relatórios\n",
    "    sample_size : int\n",
    "        Tamanho da amostra para testes\n",
    "    plot_results : bool\n",
    "        Se deve plotar as distribuições\n",
    "    alpha : float\n",
    "        Nível de significância para testes estatísticos\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    results : dict \n",
    "        Resultados detalhados de todas as transformações\n",
    "    Contains\n",
    "    - original: Dados originais e métricas\n",
    "    - best_transformation: Nome da melhor transformação baseada nas métricas\n",
    "    - transformations: Dados transformados e métricas para cada método\n",
    "    Example\n",
    "        - results[transformations]['log']['metrics']: Métricas para medir normalidade\n",
    "        - results[transformations]['yeo-johnson']['data']: Dados transformados\n",
    "        - results[transformations]['yeo-johnson']['formula']: Parâmetros da distribuição\n",
    "        - results[transformations]['yeo-johnson']['lambda']: Valor lambda (yeo-johson e boxcox)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Amostra para performance (mantém distribuição)\n",
    "    if len(data) > sample_size:\n",
    "        data_sample = data.sample(n=sample_size, random_state=42).copy()\n",
    "    else:\n",
    "        data_sample = data.copy()\n",
    "    \n",
    "    # Remover valores inválidos (precaução)\n",
    "    data_clean = data_sample.dropna()\n",
    "    data_clean = data_clean[np.isfinite(data_clean)]\n",
    "\n",
    "    # Dicionário para armazenar resultados\n",
    "    results = {\n",
    "        'original': {'data': data_clean.copy()},\n",
    "        'transformations': {}\n",
    "    }\n",
    "    \n",
    "    if (data_clean > 0).all():\n",
    "        # TRANSFORMAÇÃO 1: Logaritmo (não suporta valores <=0)\n",
    "        log_data = np.log(data_clean)\n",
    "        results['transformations']['log'] = {'data': log_data, 'formula': 'log(x)'}\n",
    "\n",
    "    if (data_clean >= 0).all():\n",
    "        # TRANSFORMAÇÃO 2: Square Root (não suporta valores <0)  \n",
    "        sqrt_data = np.sqrt(data_clean)\n",
    "        results['transformations']['sqrt'] = {'data': sqrt_data, 'formula': 'sqrt(x)'}\n",
    "\n",
    "    if (data_clean > 0).all():\n",
    "        # TRANSFORMAÇÃO 3: Box-Cox (não suporta valores <=0)\n",
    "        boxcox_data, lambda_bc = boxcox(data_clean)\n",
    "        results['transformations']['boxcox'] = {\n",
    "            'data': boxcox_data, \n",
    "            'formula': f'boxcox(x, λ={lambda_bc:.3f})',\n",
    "            'lambda': lambda_bc\n",
    "        }\n",
    "\n",
    "    # TRANSFORMAÇÃO 4: Yeo-Johnson (aceita todo valor Real)\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "    yj_data = pt.fit_transform(data_clean.values.reshape(-1, 1)).flatten()\n",
    "    results['transformations']['yeo_johnson'] = {\n",
    "        'data': yj_data,\n",
    "        'formula': f'yeo-johnson(x, λ={pt.lambdas_[0]:.3f})',\n",
    "        'lambda': pt.lambdas_[0]\n",
    "    }\n",
    "    \n",
    "    # Calcular métricas para dados originais\n",
    "    results['original']['metrics'] = calculate_normality_metrics(data_clean, 'Original', alpha=alpha)\n",
    "    \n",
    "    # Calcular métricas para todas as transformações\n",
    "    for transf_name, transf_data in results['transformations'].items():\n",
    "        transf_data['metrics'] = calculate_normality_metrics(\n",
    "            transf_data['data'], transf_name.title(), alpha=alpha\n",
    "        )\n",
    "    \n",
    "    # Encontrar melhor transformação\n",
    "    all_metrics = [results['original']['metrics']]\n",
    "    all_metrics.extend([t['metrics'] for t in results['transformations'].values()])\n",
    "    \n",
    "    best_transformation = max(all_metrics, key=lambda x: x['normality_score'])\n",
    "    results['best_transformation'] = best_transformation['name']\n",
    "\n",
    "    print(f\"\\nMELHOR TRANSFORMAÇÃO: {best_transformation['name'].upper()}\")\n",
    "    \n",
    "    # Plot das distribuições (se solicitado)\n",
    "    if plot_results:\n",
    "        plot_transformations(results, column_name)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Função para calcular métricas de normalidade\n",
    "def calculate_normality_metrics(data_vals, name, alpha=0.05):\n",
    "    metrics = {'name': name}\n",
    "    \n",
    "    # Anderson-Darling\n",
    "    anderson_result = anderson(data_vals, dist='norm')\n",
    "    # Critical value para alpha=0.05 (índice 2)\n",
    "    critical_value = anderson_result.critical_values[2]  \n",
    "    metrics['anderson_stat'] = anderson_result.statistic\n",
    "    metrics['anderson_critical'] = critical_value\n",
    "    metrics['anderson_normal'] = anderson_result.statistic < critical_value\n",
    "    \n",
    "    # Kolmogorov-Smirnov\n",
    "    normalized_data = (data_vals - np.mean(data_vals)) / np.std(data_vals)\n",
    "    ks_stat, ks_p = kstest(normalized_data, 'norm')\n",
    "    metrics['ks_stat'] = ks_stat\n",
    "    metrics['ks_pvalue'] = ks_p\n",
    "    metrics['ks_normal'] = ks_p > alpha\n",
    "    \n",
    "    # Skewness e Kurtosis\n",
    "    metrics['skewness'] = stats.skew(data_vals)\n",
    "    metrics['kurtosis'] = stats.kurtosis(data_vals)\n",
    "    metrics['skew_normal'] = abs(metrics['skewness']) < 1.0  # Critério: |skew| < 1\n",
    "    metrics['kurt_normal'] = abs(metrics['kurtosis']) < 3.0  # Critério: |kurt| < 3\n",
    "    \n",
    "    # Score combinado de normalidade (0-4, maior = mais normal)\n",
    "    score = sum([\n",
    "        metrics.get('anderson_normal', False), \n",
    "        metrics.get('ks_normal', False),\n",
    "        metrics.get('skew_normal', False),\n",
    "        metrics.get('kurt_normal', False)\n",
    "    ])\n",
    "    metrics['normality_score'] = score\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_transformations(results, column_name):\n",
    "    \"\"\"Plota histogramas e Q-Q plots das transformações\"\"\"\n",
    "    \n",
    "    # Contar transformações disponíveis\n",
    "    n_transforms = 1 + len(results['transformations'])  # +1 para original\n",
    "    \n",
    "    # Configurar subplots\n",
    "    fig, axes = plt.subplots(2, min(4, n_transforms), figsize=(16, 8))\n",
    "    if n_transforms == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    elif n_transforms > 4:\n",
    "        # Se mais de 4, mostrar apenas os 4 melhores\n",
    "        all_metrics = [results['original']['metrics']]\n",
    "        all_metrics.extend([t['metrics'] for t in results['transformations'].values()])\n",
    "        best_4 = sorted(all_metrics, key=lambda x: x['normality_score'], reverse=True)[:4]\n",
    "        n_transforms = 4\n",
    "    \n",
    "    fig.suptitle(f'Transformações de Normalidade - {column_name}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plot_idx = 0\n",
    "    \n",
    "    # Plot dados originais\n",
    "    data_orig = results['original']['data']\n",
    "    metrics_orig = results['original']['metrics']\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0, plot_idx].hist(data_orig, bins=50, alpha=0.7, color='blue', density=True)\n",
    "    axes[0, plot_idx].set_title(f\"Original (Score: {metrics_orig['normality_score']})\")\n",
    "    axes[0, plot_idx].set_ylabel('Density')\n",
    "    \n",
    "    # Q-Q plot\n",
    "    stats.probplot(data_orig, dist=\"norm\", plot=axes[1, plot_idx])\n",
    "    axes[1, plot_idx].set_title('Q-Q Plot Original')\n",
    "    \n",
    "    plot_idx += 1\n",
    "    \n",
    "    # Plot transformações (limitado a 3 para caber na figura)\n",
    "    transform_items = list(results['transformations'].items())\n",
    "    if len(transform_items) > 3:\n",
    "        # Pegar as 3 melhores transformações\n",
    "        transform_metrics = [(name, data['metrics']) for name, data in transform_items]\n",
    "        best_3_transforms = sorted(transform_metrics, \n",
    "                                 key=lambda x: x[1]['normality_score'], \n",
    "                                 reverse=True)[:3]\n",
    "        transform_names = [name for name, _ in best_3_transforms]\n",
    "    else:\n",
    "        transform_names = list(results['transformations'].keys())\n",
    "    \n",
    "    for transf_name in transform_names:\n",
    "        if plot_idx >= min(4, n_transforms):\n",
    "            break\n",
    "\n",
    "        transf_data = results['transformations'][transf_name]['data']\n",
    "        metrics = results['transformations'][transf_name]['metrics']\n",
    "\n",
    "        # Histogram\n",
    "        axes[0, plot_idx].hist(transf_data, bins=50, alpha=0.7, density=True)\n",
    "        axes[0, plot_idx].set_title(f\"{transf_name.title()} (Score: {metrics['normality_score']})\")\n",
    "\n",
    "        # Q-Q plot\n",
    "        stats.probplot(transf_data, dist=\"norm\", plot=axes[1, plot_idx])\n",
    "        axes[1, plot_idx].set_title(f'Q-Q Plot {transf_name.title()}')\n",
    "\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # Esconder axes não utilizados\n",
    "    for idx in range(plot_idx, axes.shape[1]):\n",
    "        axes[0, idx].set_visible(False)\n",
    "        axes[1, idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76908287",
   "metadata": {},
   "source": [
    "#### 6.1.2 Simulando as Transformações para Todas as Variáveis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ca56f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analisando: Hour\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: YEO_JOHNSON\n",
      "\n",
      "Analisando: HR\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: YEO_JOHNSON\n",
      "\n",
      "Analisando: HR\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: O2Sat\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: O2Sat\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: BOXCOX\n",
      "\n",
      "Analisando: Temp\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: BOXCOX\n",
      "\n",
      "Analisando: Temp\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: DBP\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: DBP\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: LOG\n",
      "\n",
      "Analisando: Resp\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: LOG\n",
      "\n",
      "Analisando: Resp\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: SQRT\n",
      "\n",
      "Analisando: BUN\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: SQRT\n",
      "\n",
      "Analisando: BUN\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: YEO_JOHNSON\n",
      "\n",
      "Analisando: WBC\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: YEO_JOHNSON\n",
      "\n",
      "Analisando: WBC\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: BOXCOX\n",
      "\n",
      "Analisando: Platelets\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: BOXCOX\n",
      "\n",
      "Analisando: Platelets\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Gender\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Gender\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Unit1\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Unit1\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Unit2\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Unit2\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: HospAdmTime\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: HospAdmTime\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: ICULOS\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: ICULOS\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: LOG\n",
      "\n",
      "Analisando: Pressure_Unified\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: LOG\n",
      "\n",
      "Analisando: Pressure_Unified\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Critical_Risk_Window\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Critical_Risk_Window\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Time_Category\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "\n",
      "Analisando: Time_Category\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "Variável        Score_Orig  Melhor Transform Score_Final  Melhoria  Recomendação\n",
      "------------------------------------------------------------------------------------------\n",
      "Hour            0           Yeo_Johnson     2            +2.0       🟢 APLICAR\n",
      "O2Sat           0           Boxcox          2            +2.0       🟢 APLICAR\n",
      "DBP             0           Log             2            +2.0       🟢 APLICAR\n",
      "Resp            0           Sqrt            2            +2.0       🟢 APLICAR\n",
      "ICULOS          0           Log             2            +2.0       🟢 APLICAR\n",
      "BUN             0           Yeo_Johnson     1            +1.0       🟡 CONSIDERAR\n",
      "WBC             0           Boxcox          1            +1.0       🟡 CONSIDERAR\n",
      "HR              2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Temp            1           Original        1            +0.0       🔴 MANTER ORIGINAL\n",
      "Platelets       0           Original        0            +0.0       🔴 MANTER ORIGINAL\n",
      "Gender          2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Unit1           2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Unit2           2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "HospAdmTime     0           Original        0            +0.0       🔴 MANTER ORIGINAL\n",
      "Pressure_Unifi  2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Critical_Risk_  0           Original        0            +0.0       🔴 MANTER ORIGINAL\n",
      "Time_Category   2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "\n",
      "IMPLEMENTAR ESTAS TRANSFORMAÇÕES:\n",
      "   • Hour: Yeo_Johnson → yeo-johnson(x, λ=0.167)\n",
      "   • O2Sat: Boxcox → boxcox(x, λ=18.567)\n",
      "   • DBP: Log → log(x)\n",
      "   • Resp: Sqrt → sqrt(x)\n",
      "   • ICULOS: Log → log(x)\n",
      "\n",
      "MELHOR TRANSFORMAÇÃO: ORIGINAL\n",
      "Variável        Score_Orig  Melhor Transform Score_Final  Melhoria  Recomendação\n",
      "------------------------------------------------------------------------------------------\n",
      "Hour            0           Yeo_Johnson     2            +2.0       🟢 APLICAR\n",
      "O2Sat           0           Boxcox          2            +2.0       🟢 APLICAR\n",
      "DBP             0           Log             2            +2.0       🟢 APLICAR\n",
      "Resp            0           Sqrt            2            +2.0       🟢 APLICAR\n",
      "ICULOS          0           Log             2            +2.0       🟢 APLICAR\n",
      "BUN             0           Yeo_Johnson     1            +1.0       🟡 CONSIDERAR\n",
      "WBC             0           Boxcox          1            +1.0       🟡 CONSIDERAR\n",
      "HR              2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Temp            1           Original        1            +0.0       🔴 MANTER ORIGINAL\n",
      "Platelets       0           Original        0            +0.0       🔴 MANTER ORIGINAL\n",
      "Gender          2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Unit1           2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Unit2           2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "HospAdmTime     0           Original        0            +0.0       🔴 MANTER ORIGINAL\n",
      "Pressure_Unifi  2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "Critical_Risk_  0           Original        0            +0.0       🔴 MANTER ORIGINAL\n",
      "Time_Category   2           Original        2            +0.0       🔴 MANTER ORIGINAL\n",
      "\n",
      "IMPLEMENTAR ESTAS TRANSFORMAÇÕES:\n",
      "   • Hour: Yeo_Johnson → yeo-johnson(x, λ=0.167)\n",
      "   • O2Sat: Boxcox → boxcox(x, λ=18.567)\n",
      "   • DBP: Log → log(x)\n",
      "   • Resp: Sqrt → sqrt(x)\n",
      "   • ICULOS: Log → log(x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Selecionar variáveis numéricas para análise de normalidade\n",
    "numeric_columns = X_train_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Dicionário para armazenar resultados de todas as variáveis\n",
    "all_normality_results = {}\n",
    "transformation_summary = []\n",
    "\n",
    "for col in numeric_columns:\n",
    "    print(f\"\\nAnalisando: {col}\")\n",
    "    \n",
    "    # Verificar se há dados suficientes\n",
    "    valid_data = X_train_fe[col].dropna()\n",
    "    if len(valid_data) > 1000:\n",
    "        results = validate_normality_transformations(\n",
    "            data=valid_data,\n",
    "            column_name=col, \n",
    "            sample_size=len(valid_data), \n",
    "            plot_results=False  # Sem plots para análise rápida\n",
    "        )\n",
    "        \n",
    "        if results:\n",
    "            all_normality_results[col] = results\n",
    "            \n",
    "            # Resumir resultado\n",
    "            best_transform = results['best_transformation']\n",
    "            original_score = results['original']['metrics']['normality_score']\n",
    "            \n",
    "            if best_transform != 'Original':\n",
    "                best_score = results['transformations'][best_transform.lower()]['metrics']['normality_score']\n",
    "                improvement = best_score - original_score\n",
    "                formula = results['transformations'][best_transform.lower()]['formula']\n",
    "            else:\n",
    "                best_score = original_score\n",
    "                improvement = 0\n",
    "                formula = \"Sem transformação\"\n",
    "            \n",
    "            transformation_summary.append({\n",
    "                'variable': col,\n",
    "                'original_score': original_score,\n",
    "                'best_transformation': best_transform, \n",
    "                'best_score': best_score,\n",
    "                'improvement': improvement,\n",
    "                'formula': formula\n",
    "            })\n",
    "\n",
    "# Relatório consolidado\n",
    "\n",
    "# Ordenar por maior melhoria\n",
    "transformation_summary.sort(key=lambda x: x['improvement'], reverse=True)\n",
    "\n",
    "print(f\"{'Variável':<15} {'Score_Orig':<11} {'Melhor Transform':<15} {'Score_Final':<12} {'Melhoria':<9} {'Recomendação'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "for item in transformation_summary:\n",
    "    var = item['variable'][:14]\n",
    "    orig_score = item['original_score']\n",
    "    best_transf = item['best_transformation'][:14]\n",
    "    best_score = item['best_score']\n",
    "    improvement = item['improvement']\n",
    "    formula = item['formula'][:30]\n",
    "    \n",
    "    # Determinar recomendação\n",
    "    if improvement >= 2:\n",
    "        recommendation = \"🟢 APLICAR\"\n",
    "        recommendations.append((item['variable'], best_transf, formula))\n",
    "    elif improvement >= 1:\n",
    "        recommendation = \"🟡 CONSIDERAR\"\n",
    "    else:\n",
    "        recommendation = \"🔴 MANTER ORIGINAL\"\n",
    "    \n",
    "    print(f\"{var:<15} {orig_score:<11} {best_transf:<15} {best_score:<12} {improvement:+.1f}{'':<6} {recommendation}\")\n",
    "\n",
    "if recommendations:\n",
    "    print(f\"\\nIMPLEMENTAR ESTAS TRANSFORMAÇÕES:\")\n",
    "    for var, transform, formula in recommendations:\n",
    "        print(f\"   • {var}: {transform} → {formula}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed90864",
   "metadata": {},
   "source": [
    "#### 6.1.3 Plot Q-Q de Variável\n",
    "\n",
    "Aqui podemos visualizar as distribuições simuladas antes de aplicar para ter-se um conhecimento mais intuitivo.\n",
    "\n",
    "Por fatores de efetividade, apenas trocar o nome da variável `column_name` da célula abaixo para o nome da coluna que deseja plotar, assim evita-se sobrecarregar o output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75d51c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MELHOR TRANSFORMAÇÃO: BOXCOX\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Troque o nome da variável abaixo e execute a célula para ver os Plots\n",
    "\n",
    "column_name = 'O2Sat'  # Exemplo: 'O2Sat', 'BUN', 'WBC', 'Hour', etc.\n",
    "hour_results = validate_normality_transformations(\n",
    "    data=X_train_fe[column_name], \n",
    "    column_name=column_name,\n",
    "    sample_size=len(X_train_fe),  # Usar todos os dados\n",
    "    plot_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b8223",
   "metadata": {},
   "source": [
    "#### 6.1.4 Aplicando as Transformações e Padronizando\n",
    "\n",
    "Aqui apenas aplicamos as mudanças dessa etapa. \n",
    "\n",
    "Por hora usaremos o StandardScaler para padronizar pois queremos preservar outliers e seu impacto até o momento e essa transformação\n",
    "funciona bem para *features* que estão em unidades e escalas diferentes.\n",
    "\n",
    "Além disso, a escala não será aplicada em features que são categóricas (por não haver necessidade) e nem\n",
    "em variáveis de tempo a fim de preservar a intuição inicial do problema que é o tempo ter maior influência na predição.\n",
    "\n",
    "Outras abordagens possíveis:\n",
    " - SVM/Logistic: Usar StandardScaler\n",
    " - Neural Networks: Usar MinMax para manter no intervalo [0,1] ou outro intervalo regular\n",
    " - Diminuir influência de outliers: RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d446ca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hour     HR  O2Sat       Temp        DBP  Resp        BUN        WBC  \\\n",
      "0    32   87.0   98.0  37.000000  49.000000  16.0  23.029861  11.539392   \n",
      "1    16  114.0  100.0  36.940000  52.337797  20.0  21.368639  13.287783   \n",
      "2    29   93.0   93.0  37.053491  61.000000  19.0  26.098248  12.112435   \n",
      "3     6  104.0   96.0  38.200000  56.000000  18.0  22.549949  12.642132   \n",
      "4    41   80.0   99.0  36.992742  55.000000  17.0  25.683570  11.032947   \n",
      "\n",
      "    Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  Pressure_Unified  \\\n",
      "0  198.297293     0.0    0.0    1.0       -64.69    33.0            83.100   \n",
      "1  201.370434     0.0    1.0    0.0        -0.03    17.0            83.469   \n",
      "2  190.559233     1.0    0.0    1.0      -177.25    32.0            89.900   \n",
      "3  191.116526     1.0    0.0    1.0       -23.51     7.0            84.700   \n",
      "4  198.269082     0.0    1.0    0.0       -64.40    42.0           104.800   \n",
      "\n",
      "   Critical_Risk_Window  Time_Category  \n",
      "0                     0              1  \n",
      "1                     0              0  \n",
      "2                     0              1  \n",
      "3                     0              0  \n",
      "4                     0              1  \n"
     ]
    }
   ],
   "source": [
    "# Estado atual do dataset nesse ponto\n",
    "print(X_train_fe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b81c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizando as seguintes variáveis: {'DBP': 'Log', 'Resp': 'Sqrt', 'BUN': 'Yeo_Johnson', 'WBC': 'Boxcox'}\n",
      "   Hour     HR  O2Sat       Temp       DBP      Resp       BUN       WBC  \\\n",
      "0    32   87.0   98.0  37.000000  3.891820  4.000000  5.882295  3.611720   \n",
      "1    16  114.0  100.0  36.940000  3.957719  4.472136  5.664192  3.912217   \n",
      "2    29   93.0   93.0  37.053491  4.110874  4.358899  6.260822  3.713520   \n",
      "3     6  104.0   96.0  38.200000  4.025352  4.242641  5.820315  3.804664   \n",
      "4    41   80.0   99.0  36.992742  4.007333  4.123106  6.211342  3.518765   \n",
      "\n",
      "    Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  Pressure_Unified  \\\n",
      "0  198.297293     0.0    0.0    1.0       -64.69    33.0            83.100   \n",
      "1  201.370434     0.0    1.0    0.0        -0.03    17.0            83.469   \n",
      "2  190.559233     1.0    0.0    1.0      -177.25    32.0            89.900   \n",
      "3  191.116526     1.0    0.0    1.0       -23.51     7.0            84.700   \n",
      "4  198.269082     0.0    1.0    0.0       -64.40    42.0           104.800   \n",
      "\n",
      "   Critical_Risk_Window  Time_Category  \n",
      "0                     0              1  \n",
      "1                     0              0  \n",
      "2                     0              1  \n",
      "3                     0              0  \n",
      "4                     0              1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_transformed = X_train_fe.copy()\n",
    "\n",
    "columns_to_transform = {var_name: all_normality_results[var_name]['best_transformation'] \n",
    "                        for var_name in all_normality_results.keys() \n",
    "                        if all_normality_results[var_name]['best_transformation'] != 'Original'}\n",
    "\n",
    "# Variáveis excluídas da normalização após visualização no Q-Q plot\n",
    "# (distribuição bimodal ou outras características que não se beneficiam de normalização)\n",
    "columns_to_transform.pop('Hour', None) # preservar tempo original\n",
    "columns_to_transform.pop('ICULOS', None) # preservar tempo original\n",
    "columns_to_transform.pop('O2Sat', None) # distribuição multimodal\n",
    "\n",
    "# Aplicando a normalização\n",
    "if columns_to_transform:\n",
    "    print(f\"\\nNormalizando as seguintes variáveis: {columns_to_transform}\")\n",
    "    for col, transform_type in columns_to_transform.items():\n",
    "\n",
    "        data = X_train_fe[col]\n",
    "        var_name = col\n",
    "        transform_type = transform_type.lower()\n",
    "\n",
    "        if transform_type == 'log' and (data > 0).all():\n",
    "            X_train_transformed[var_name] = np.log(X_train_fe[var_name].replace(0, np.nan))\n",
    "            \n",
    "        elif transform_type == 'sqrt' and (data >= 0).all():\n",
    "            X_train_transformed[var_name] = np.sqrt(X_train_fe[var_name])\n",
    "            \n",
    "        elif transform_type == 'boxcox' and (data > 0).all():\n",
    "            transformed_data, lambda_val = boxcox(data)\n",
    "            X_train_transformed.loc[data.index, var_name] = transformed_data\n",
    "            \n",
    "        elif transform_type == 'yeo_johnson':\n",
    "            pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "            transformed_data = pt.fit_transform(data.values.reshape(-1, 1)).flatten()\n",
    "            X_train_transformed.loc[data.index, var_name] = transformed_data\n",
    "    \n",
    "# Dataset após transformações gaussianas\n",
    "print(X_train_transformed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d7e50d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hour        HR     O2Sat      Temp       DBP      Resp       BUN       WBC  \\\n",
      "0    32  0.150030  0.258944  0.087663 -1.118286 -0.520987 -0.114361  0.182238   \n",
      "1    16  1.769803  0.978068 -0.033352 -0.791981  0.349546 -0.406008  1.044907   \n",
      "2    29  0.509979 -1.538866  0.195551 -0.033613  0.140758  0.391805  0.474485   \n",
      "3     6  1.169887 -0.460180  2.507962 -0.457088 -0.073601 -0.197241  0.736143   \n",
      "4    41 -0.269912  0.618506  0.073025 -0.546309 -0.294002  0.325640 -0.084621   \n",
      "\n",
      "   Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  Pressure_Unified  \\\n",
      "0   0.063513     0.0    0.0    1.0       -64.69    33.0         -0.697808   \n",
      "1   0.164413     0.0    1.0    0.0        -0.03    17.0         -0.675300   \n",
      "2  -0.190549     1.0    0.0    1.0      -177.25    32.0         -0.283014   \n",
      "3  -0.172252     1.0    0.0    1.0       -23.51     7.0         -0.600210   \n",
      "4   0.062587     0.0    1.0    0.0       -64.40    42.0          0.625874   \n",
      "\n",
      "   Critical_Risk_Window  Time_Category  \n",
      "0                     0              1  \n",
      "1                     0              0  \n",
      "2                     0              1  \n",
      "3                     0              0  \n",
      "4                     0              1  \n"
     ]
    }
   ],
   "source": [
    "# Padronização\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "X_train_scaled = X_train_transformed.copy()\n",
    "\n",
    "# Aplicar para todas as variáveis de dados clínicos que foram preservados até agora\n",
    "# Exclui: variáveis de tempo e categóricas (One-Hot Encoded)  \n",
    "columns_to_scale = ['HR', 'O2Sat', 'Temp', 'DBP', 'Resp', 'BUN', 'WBC', 'Platelets', 'Pressure_Unified']\n",
    "\n",
    "# StandardScaler (Z-Score) - Mais comum\n",
    "scaler_standard = StandardScaler()\n",
    "scaled_columns = pd.DataFrame(\n",
    "    scaler_standard.fit_transform(X_train_transformed[columns_to_scale]),\n",
    "    columns=columns_to_scale,\n",
    "    index=X_train_transformed.index\n",
    ")\n",
    "\n",
    "X_train_scaled.update(scaled_columns)\n",
    "\n",
    "# Estado final do dataset após padronização\n",
    "print(X_train_scaled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78947d7e",
   "metadata": {},
   "source": [
    "### 6.2 Balanceamento de Classes\n",
    "\n",
    "Implementação de técnicas para lidar com o severo desbalanceamento entre classes (98.2% vs 1.8%).\n",
    "\n",
    "**Técnicas a Comparar**:\n",
    "\n",
    "1. **Undersampling**: Reduz classe majoritária (não-sepse)\n",
    "   - **RandomUnderSampler**: Remoção aleatória\n",
    "   - **TomekLinks**: Remove pontos próximos à fronteira\n",
    "   - **EditedNearestNeighbors**: Remove amostras mal classificadas\n",
    "\n",
    "2. **Oversampling**: Aumenta classe minoritária (sepse)  \n",
    "   - **RandomOverSampler**: Duplicação aleatória\n",
    "   - **SMOTE**: Synthetic Minority Oversampling\n",
    "   - **ADASYN**: Adaptive Synthetic Sampling\n",
    "\n",
    "3. **Métodos Híbridos**: Combinam ambos\n",
    "   - **SMOTETomek**: SMOTE + remoção Tomek Links\n",
    "   - **SMOTEENN**: SMOTE + Edited Nearest Neighbors\n",
    "\n",
    "**Vantagens do Undersampling para Sepsis**:\n",
    "- **Preserva qualidade** dos dados reais de sepse\n",
    "- **Reduz tempo computacional** (menos dados)\n",
    "- **Evita overfitting** em dados sintéticos\n",
    "- **Mantém características** clínicas importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd89bef",
   "metadata": {},
   "source": [
    "#### 6.2.1 Análise de Estratégias de Balanceamento\n",
    "\n",
    "Comparação de diferentes abordagens: oversampling, undersampling e métodos combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e30e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for RandomUnderSampler: 10.6568 seconds\n",
      "Execution time for TomekLinks: 13.5812 seconds\n",
      "Execution time for EditedNearestNeighbours: 12.6360 seconds\n",
      "Execution time for RandomOverSampler: 6.3757 seconds\n",
      "Execution time for SMOTE: 6.8890 seconds\n",
      "Execution time for ADASYN: 6.6832 seconds\n",
      "Execution time for SMOTETomek: 37.3137 seconds\n",
      "Execution time for SMOTEENN: 36.4313 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "class_counts = y_train_fe.value_counts().sort_index()\n",
    "class_props = y_train_fe.value_counts(normalize=True).sort_index()\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "# Criar amostra estratificada de 10% para acelerar análise\n",
    "sample_size = 0.1\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X_train_scaled, y_train_cleaned, \n",
    "    test_size=1-sample_size, \n",
    "    random_state=42, \n",
    "    stratify=y_train_cleaned\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Configurar técnicas de balanceamento\n",
    "techniques = {\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42),\n",
    "    'TomekLinks': TomekLinks(),\n",
    "    'EditedNearestNeighbours': EditedNearestNeighbours(),\n",
    "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42),\n",
    "    'SMOTEENN': SMOTEENN(random_state=42)\n",
    "}\n",
    "\n",
    "# Modelo para avaliação rápida\n",
    "rf_eval = RandomForestClassifier(n_estimators=30, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Testar cada técnica na amostra\n",
    "balancing_results = []\n",
    "for name, technique in techniques.items():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        X_balanced, y_balanced = technique.fit_resample(X_sample, y_sample)\n",
    "        \n",
    "        # Avaliação com cross-validation\n",
    "        cv_scores = cross_val_score(rf_eval, X_balanced, y_balanced, \n",
    "                                  cv=3, scoring='f1', n_jobs=-1)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        class_dist = pd.Series(y_balanced).value_counts().sort_index()\n",
    "        print(f'Execution time for {name}: {execution_time:.4f} seconds')\n",
    "\n",
    "        balancing_results.append({\n",
    "            'technique': name,\n",
    "            'f1_score': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'final_samples': len(X_balanced),\n",
    "            'class_0': class_dist[0],\n",
    "            'class_1': class_dist[1],\n",
    "            'time_seconds': execution_time\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# Ordenar resultados por F1-score\n",
    "balancing_results.sort(key=lambda x: x['f1_score'], reverse=True)\n",
    "\n",
    "# Aplicar melhor técnica no dataset completo\n",
    "if balancing_results:\n",
    "    best_technique_name = balancing_results[0]['technique']\n",
    "    best_technique = techniques[best_technique_name]\n",
    "    \n",
    "    # Aplicar no dataset completo\n",
    "    X_train_balanced, y_train_balanced = best_technique.fit_resample(X_train_scaled, y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51f3fa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranking das Técnicas (F1-Score):\n",
      "   1º RandomOverSampler: 0.9994\n",
      "   2º SMOTEENN: 0.9898\n",
      "   3º SMOTETomek: 0.9887\n",
      "   4º SMOTE: 0.9886\n",
      "   5º ADASYN: 0.9392\n",
      "   6º RandomUnderSampler: 0.7016\n",
      "   7º EditedNearestNeighbours: 0.0347\n",
      "   8º TomekLinks: 0.0162\n",
      "\n",
      "Melhor Técnica Aplicada: RandomOverSampler\n",
      "   Distribuição Final:\n",
      "   Classe 0 (Sem Sepse): 1,187,303 (50.0%)\n",
      "   Classe 1 (Com Sepse): 1,187,303 (50.0%)\n",
      "   Nova Razão: 1.0:1\n",
      "   Tamanho do Dataset: 2,374,606 registros\n",
      "\n",
      "Mudanças na Distribuição:\n",
      "   Classe 0: -49.1%\n",
      "   Classe 1: +2662.0%\n",
      "\n",
      "Tabela Completa dos Resultados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>technique</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>0.9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.9886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>EditedNearestNeighbours</td>\n",
       "      <td>0.0347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>TomekLinks</td>\n",
       "      <td>0.0162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                technique  f1_score\n",
       "0     1        RandomOverSampler    0.9994\n",
       "1     2                 SMOTEENN    0.9898\n",
       "2     3               SMOTETomek    0.9887\n",
       "3     4                    SMOTE    0.9886\n",
       "4     5                   ADASYN    0.9392\n",
       "5     6       RandomUnderSampler    0.7016\n",
       "6     7  EditedNearestNeighbours    0.0347\n",
       "7     8               TomekLinks    0.0162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exibir resultados da análise de balanceamento\n",
    "if balancing_results:\n",
    "    results_df = pd.DataFrame(balancing_results)\n",
    "    results_df = results_df.sort_values('f1_score', ascending=False)\n",
    "    results_df['rank'] = range(1, len(results_df) + 1)\n",
    "    \n",
    "    \n",
    "    # Mostrar distribuição original\n",
    "    original_counts = y_sample.value_counts().sort_index()\n",
    "    original_props = original_counts / original_counts.sum()\n",
    "    \n",
    "    # Mostrar ranking das técnicas\n",
    "    print(f\"\\nRanking das Técnicas (F1-Score):\")\n",
    "    for i, row in results_df.iterrows():\n",
    "        print(f\"   {row['rank']}º {row['technique']}: {row['f1_score']:.4f}\")\n",
    "    \n",
    "    # Mostrar comparação final\n",
    "    final_counts = pd.Series(y_train_balanced).value_counts().sort_index()\n",
    "    final_props = final_counts / final_counts.sum()\n",
    "    final_ratio = final_counts[0] / final_counts[1] if len(final_counts) > 1 else 1\n",
    "    \n",
    "    print(f\"\\nMelhor Técnica Aplicada: {best_technique_name}\")\n",
    "    print(f\"   Distribuição Final:\")\n",
    "    print(f\"   Classe 0 (Sem Sepse): {final_counts[0]:,} ({final_props[0]:.1%})\")\n",
    "    print(f\"   Classe 1 (Com Sepse): {final_counts[1]:,} ({final_props[1]:.1%})\")\n",
    "    print(f\"   Nova Razão: {final_ratio:.1f}:1\")\n",
    "    print(f\"   Tamanho do Dataset: {len(y_train_balanced):,} registros\")\n",
    "    \n",
    "    # Mostra mudanças percentuais\n",
    "    prop_change_0 = ((final_props[0] - original_props[0]) / original_props[0]) * 100\n",
    "    prop_change_1 = ((final_props[1] - original_props[1]) / original_props[1]) * 100\n",
    "    \n",
    "    print(f\"\\nMudanças na Distribuição:\")\n",
    "    print(f\"   Classe 0: {prop_change_0:+.1f}%\")\n",
    "    print(f\"   Classe 1: {prop_change_1:+.1f}%\")\n",
    "    \n",
    "    \n",
    "    # Mostrar DataFrame com todos os resultados\n",
    "    print(\"\\nTabela Completa dos Resultados:\")\n",
    "    display(results_df[['rank', 'technique', 'f1_score']].round(4))\n",
    "    \n",
    "else:\n",
    "    print(\"Nenhum resultado de balanceamento encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a7ea5",
   "metadata": {},
   "source": [
    "#### 6.2.2 Discussão dos Resultados da Análise de Balanceamento\n",
    "\n",
    "Aplicação da técnica de balanceamento selecionada com base na análise comparativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957c521",
   "metadata": {},
   "source": [
    "**Como output comparação obtivemos**:\n",
    "\n",
    "    - Melhor Técnica: RandomOverSampler\n",
    "    - F1-Score: 0,9994 (excelente performance)\n",
    "    - Resultado: Dataset perfeitamente balanceado (50%/50%)\n",
    "    - Tamanho final: 2.374.606 registros\n",
    "\n",
    "Ranking das Técnicas (F1-Score):\n",
    "* RandomOverSampler (0,9994) \n",
    "* SMOTEENN (0,9898) \n",
    "* SMOTETomek (0,9887)\n",
    "* SMOTE (0,9886) \n",
    "* ADASYN (0,9392) \n",
    "* RandomUnderSampler (0,7016)\n",
    "* EditedNearestNeighbours (0,0347) \n",
    "* TomekLinks (0,0162) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc256b2",
   "metadata": {},
   "source": [
    "No entanto, perceba que a maioria dessas técnicas tem um desempenho muito ruim, seja por under ou overfitting:\n",
    "- RandomOverSampler: Simplesmente duplica aleatoriamente os elementos da classe minoritária até equilibrar. Então o modelo acaba por memorizar os exemplos e isso fica mais evidente quando usamos uma validação cruzada, que um mesmo exemplo pode estar no treino e no teste ao mesmo tempo devido à duplicaçao.\n",
    "- SMOTE e derivados: Cria exemplos entre vizinhos mais próximos da mesma classe. Mesmo problema do RandomOverSampler além de acrescentar casos que podem não ser fieis à realidade\n",
    "- ADASYN: Minimiza o problema do OverSampler tentando aprimorar a fronteira de decisão mas possui o mesmo problema dos demais de criam dados sintéticos.\n",
    "- EditedNearesNeighbours: Remove pontos que possivelmente serviriam para delimitar a fronteira de decisão, o resultado é um modelo que aprende errado e escolhe errado na maioria das vezes\n",
    "- TomekLinks: Mesmo problema do ENN por remover justamente os casos que serviriam para o modelo onde separar cada classe.\n",
    "\n",
    "Por causa do severo desbalanceamento, a maioria das técnicas sofre com alta variância, porquê o modelo decora os exemplos se tentarmos criar exemplos sintéticos (pois são muitos), ou alto viés, porquê remove-se justamente os que serviriam para generalizar.\n",
    "\n",
    "Considerando o grande número de instâncias (~1.2M) e um desbalanceamento de 1:54 aproximadamente. A estratégia que demonstra-se mais confiável é a de remoção de instãncias da classe majoritária aleatoriamente, porém não tanto ao ponto de igualar as proporções pois perderíamos muitos dados. Devemos visar uma remoção que tente diminuir só um pouco a desproporção e deixar que o modelo aprenda com o dataset praticamente do jeito que está. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbdd97",
   "metadata": {},
   "source": [
    "#### 6.2.3 Aplicação de Under Sampling Simples\n",
    "\n",
    "Pensando em ainda manter o desbalanceamento para não perdemos muitos dados, porém diminuir o suficiente para aumentar a capacidade de generalização do modelo. Vamos optar por reduzir o tamanho da classe majoritária em 30% como primeira opção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6955ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição original:\n",
      "Classe minoritária (sepse): 21,894\n",
      "Classe majoritária (não-sepse): 1,187,303\n",
      "Razão original: 54.2:1\n",
      "\n",
      "Resultados do undersampling:\n",
      "Classe 0 (não-sepse): 831,112 (97.4%)\n",
      "Classe 1 (sepse): 21,894 (2.6%)\n",
      "Nova razão: 38.0:1\n",
      "Tamanho total do dataset: 853,006\n",
      "Redução do dataset original: 29.5%\n",
      "\n",
      "    Hour        HR     O2Sat      Temp       DBP      Resp       BUN       WBC  \\\n",
      "0     8 -1.109794 -0.460180 -0.936182  2.159974 -0.073601 -0.277186 -1.393580   \n",
      "1    47  0.569971 -2.437770  0.173477  0.430943 -0.997324  0.309171  0.245616   \n",
      "2     6  0.150030  0.978068  0.016114 -0.198683 -0.073601 -0.310739  0.121368   \n",
      "3    39 -0.269912  0.258944  0.289355 -0.115460  0.752015  0.298591 -0.003965   \n",
      "4   127  0.569971 -0.460180  0.007012  1.055050 -0.520987  0.702140 -0.180545   \n",
      "\n",
      "   Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  Pressure_Unified  \\\n",
      "0   0.450716     1.0    1.0    0.0       -12.06     9.0          3.657535   \n",
      "1  -0.275108     1.0    1.0    0.0        -0.05    48.0          0.534375   \n",
      "2  -0.191266     1.0    1.0    0.0        -0.02     7.0         -0.783207   \n",
      "3  -3.152920     0.0    0.0    1.0       -75.85    43.0          0.546575   \n",
      "4   0.030433     0.0    0.0    1.0        -0.03   128.0          1.620161   \n",
      "\n",
      "   Critical_Risk_Window  Time_Category  \n",
      "0                     0              0  \n",
      "1                     0              1  \n",
      "2                     0              0  \n",
      "3                     0              1  \n",
      "4                     1              2  \n"
     ]
    }
   ],
   "source": [
    "# Implementação de undersampling inteligente baseado em proporcionalidade\n",
    "# Separar classes para manipulação independente\n",
    "minority_class = X_train_scaled[y_train_cleaned == 1]\n",
    "majority_class = X_train_scaled[y_train_cleaned == 0]\n",
    "\n",
    "minority_class_target = y_train_cleaned[y_train_cleaned == 1]\n",
    "majority_class_target = y_train_cleaned[y_train_cleaned == 0]\n",
    "\n",
    "print(f\"Distribuição original:\")\n",
    "print(f\"Classe minoritária (sepse): {len(minority_class):,}\")\n",
    "print(f\"Classe majoritária (não-sepse): {len(majority_class):,}\")\n",
    "print(f\"Razão original: {len(majority_class) / len(minority_class):.1f}:1\")\n",
    "\n",
    "# Redução da classe majoritária preservando o desbalanceamento evitando excesso\n",
    "n_samples_majority = int(0.7 * len(majority_class))\n",
    "\n",
    "# Amostragem estratificada por grupos clínicos relevantes se disponível\n",
    "# Caso contrário, amostragem aleatória com seed para reproducibilidade\n",
    "majority_class_subset = majority_class.sample(n=n_samples_majority, random_state=42)\n",
    "majority_class_target_subset = majority_class_target.loc[majority_class_subset.index]\n",
    "\n",
    "# Combinar classes balanceadas\n",
    "X_train_undersampled = pd.concat([majority_class_subset, minority_class])\n",
    "y_train_undersampled = pd.concat([majority_class_target_subset, minority_class_target])\n",
    "\n",
    "# Embaralhar o dataset final para evitar bias de ordenação\n",
    "shuffle_idx = np.random.RandomState(42).permutation(len(X_train_undersampled))\n",
    "X_train_undersampled = X_train_undersampled.iloc[shuffle_idx].reset_index(drop=True)\n",
    "y_train_undersampled = y_train_undersampled.iloc[shuffle_idx].reset_index(drop=True)\n",
    "\n",
    "# Validação dos resultados\n",
    "final_counts = y_train_undersampled.value_counts().sort_index()\n",
    "final_props = final_counts / final_counts.sum()\n",
    "final_ratio = final_counts[0] / final_counts[1]\n",
    "\n",
    "print(f\"\\nResultados do undersampling:\")\n",
    "print(f\"Classe 0 (não-sepse): {final_counts[0]:,} ({final_props[0]:.1%})\")\n",
    "print(f\"Classe 1 (sepse): {final_counts[1]:,} ({final_props[1]:.1%})\")\n",
    "print(f\"Nova razão: {final_ratio:.1f}:1\")\n",
    "print(f\"Tamanho total do dataset: {len(X_train_undersampled):,}\")\n",
    "print(f\"Redução do dataset original: {((len(X_train_transformed) - len(X_train_undersampled)) / len(X_train_transformed)) * 100:.1f}%\")\n",
    "\n",
    "\n",
    "print('\\n',X_train_undersampled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f08b9",
   "metadata": {},
   "source": [
    "## 7. Criação dos Datasets Finais e Export\n",
    "\n",
    "Verificação final da qualidade e consistência dos dados preparados, seguida do salvamento dos datasets processados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea5d27",
   "metadata": {},
   "source": [
    "#### 7.1 Criação do Dataset Final  + Dataset Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3dc44ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras 5 linhas do dataset final (features + target):\n",
      "   Hour        HR     O2Sat      Temp       DBP      Resp       BUN       WBC  \\\n",
      "0     8 -1.109794 -0.460180 -0.936182  2.159974 -0.073601 -0.277186 -1.393580   \n",
      "1    47  0.569971 -2.437770  0.173477  0.430943 -0.997324  0.309171  0.245616   \n",
      "2     6  0.150030  0.978068  0.016114 -0.198683 -0.073601 -0.310739  0.121368   \n",
      "3    39 -0.269912  0.258944  0.289355 -0.115460  0.752015  0.298591 -0.003965   \n",
      "4   127  0.569971 -0.460180  0.007012  1.055050 -0.520987  0.702140 -0.180545   \n",
      "\n",
      "   Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  Pressure_Unified  \\\n",
      "0   0.450716     1.0    1.0    0.0       -12.06     9.0          3.657535   \n",
      "1  -0.275108     1.0    1.0    0.0        -0.05    48.0          0.534375   \n",
      "2  -0.191266     1.0    1.0    0.0        -0.02     7.0         -0.783207   \n",
      "3  -3.152920     0.0    0.0    1.0       -75.85    43.0          0.546575   \n",
      "4   0.030433     0.0    0.0    1.0        -0.03   128.0          1.620161   \n",
      "\n",
      "   Critical_Risk_Window  Time_Category  SepsisLabel  \n",
      "0                     0              0          0.0  \n",
      "1                     0              1          0.0  \n",
      "2                     0              0          0.0  \n",
      "3                     0              1          0.0  \n",
      "4                     1              2          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Criação dos datasets finais de treino\n",
    "X_train_final = X_train_undersampled.copy()\n",
    "y_train_final = y_train_undersampled.copy()\n",
    "\n",
    "# Criação do dataset final unificado (features + target)\n",
    "dataset_final = X_train_final\n",
    "dataset_final['SepsisLabel'] = y_train_final\n",
    "\n",
    "# Visualização das primeiras linhas do dataset final unificado\n",
    "print(\"Primeiras 5 linhas do dataset final (features + target):\")\n",
    "print(dataset_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935457c5",
   "metadata": {},
   "source": [
    "#### 7.2 Estatísticas do Dataset final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0f6dd45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train_final: (853006, 18)\n",
      "Shape y_train_final: (853006,)\n",
      "Tipos de dados em X_train_final: {dtype('float64'): 15, dtype('int64'): 3}\n",
      "Tipo de dados em y_train_final: float64\n",
      "Total de valores ausentes: 0\n",
      "\n",
      "Resumo Final do Pipeline de Preparação de Dados:\n",
      "Dataset original: 1,241,768 amostras\n",
      "Dataset final: 853,006 amostras\n",
      "Redução: 31.3%\n",
      "Distribuição da variável target:\n",
      "  Classe 0: 831,112 (97.4%)\n",
      "  Classe 1: 21,894 (2.6%)\n",
      "\n",
      "Estatísticas Descritivas (primeiras 5 variáveis):\n",
      "            Hour         HR      O2Sat       Temp        DBP\n",
      "count  853006.00  853006.00  853006.00  853006.00  853006.00\n",
      "mean       26.03       0.00      -0.00       0.00      -0.00\n",
      "std        29.60       1.00       1.00       1.00       1.00\n",
      "min         0.00      -3.87     -27.79     -28.15     -12.71\n",
      "25%         9.00      -0.69      -0.46      -0.43      -0.63\n",
      "50%        20.00      -0.06       0.26      -0.03      -0.03\n",
      "75%        33.00       0.57       0.62       0.42       0.59\n",
      "max       335.00      11.73       0.98      26.31       7.85\n"
     ]
    }
   ],
   "source": [
    "# Shapes e tipos\n",
    "print(f\"Shape X_train_final: {X_train_final.shape}\")\n",
    "print(f\"Shape y_train_final: {y_train_final.shape}\")\n",
    "print(f\"Tipos de dados em X_train_final: {X_train_final.dtypes.value_counts().to_dict()}\")\n",
    "print(f\"Tipo de dados em y_train_final: {y_train_final.dtype}\")\n",
    "\n",
    "# Verificar valores ausentes\n",
    "missing_final = X_train_final.isnull().sum().sum()\n",
    "print(f\"Total de valores ausentes: {missing_final}\")\n",
    "\n",
    "# Resumo final do pipeline\n",
    "print(f\"\\nResumo Final do Pipeline de Preparação de Dados:\")\n",
    "print(f\"Dataset original: {len(X_train):,} amostras\")\n",
    "print(f\"Dataset final: {len(dataset_final):,} amostras\")\n",
    "print(f\"Redução: {((len(X_train) - len(dataset_final)) / len(X_train)) * 100:.1f}%\")\n",
    "\n",
    "# Distribuição da variável target\n",
    "target_distribution = y_train_final.value_counts().sort_index()\n",
    "target_proportions = y_train_final.value_counts(normalize=True).sort_index()\n",
    "print(f\"Distribuição da variável target:\")\n",
    "print(f\"  Classe 0: {target_distribution[0]:,} ({target_proportions[0]:.1%})\")\n",
    "print(f\"  Classe 1: {target_distribution[1]:,} ({target_proportions[1]:.1%})\")\n",
    "\n",
    "# Estatísticas descritivas básicas\n",
    "print(f\"\\nEstatísticas Descritivas (primeiras 5 variáveis):\")\n",
    "print(X_train_final.iloc[:, :5].describe().round(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2746a94",
   "metadata": {},
   "source": [
    "#### 7.3 Exportação Para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda1f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final exportado para: dataset_sepsis_train_prepared.csv\n",
      "Tamanho do arquivo: 117.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Exportação do dataset final unificado para CSV\n",
    "output_path = \"dataset_sepsis_train_prepared.csv\"\n",
    "print(f\"Dataset final exportado para: {output_path}\")\n",
    "\n",
    "dataset_final.to_csv(output_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
