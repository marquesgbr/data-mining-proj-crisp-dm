# ğŸ¥ PrediÃ§Ã£o de Sepse com Machine Learning
## Projeto de MineraÃ§Ã£o de Dados - Metodologia CRISP-DM

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PhysioNet](https://img.shields.io/badge/Dataset-PhysioNet%202019-red.svg)](https://physionet.org/content/challenge-2019/)

Este projeto implementa um pipeline completo de Machine Learning seguindo a metodologia CRISP-DM para prediÃ§Ã£o precoce de sepse em pacientes de UTI, utilizando o dataset do PhysioNet 2019 Challenge.


---

## ğŸ“‹ Ãndice

- [Dataset](#-dataset)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Metodologia CRISP-DM](#-metodologia-crisp-dm)
- [Modelos Implementados](#-modelos-implementados)
- [PrÃ©-processamento](#-prÃ©-processamento)
- [Resultados](#-resultados)
- [InstalaÃ§Ã£o e Uso](#-instalaÃ§Ã£o-e-uso)
- [DicionÃ¡rio de VariÃ¡veis](#-dicionÃ¡rio-de-variÃ¡veis)

---

## ğŸ“Š Dataset

O dataset utilizado Ã© do **PhysioNet 2019 Challenge**, contendo dados de pacientes internados em UTI com mÃºltiplas variÃ¡veis clÃ­nicas coletadas ao longo do tempo.

### CaracterÃ­sticas Principais

- **Total de registros**: 1.552.210 observaÃ§Ãµes (40.336 pacientes)
- **Features**: 40 variÃ¡veis clÃ­nicas (sinais vitais, exames laboratoriais, dados demogrÃ¡ficos)
- **Target**: PrediÃ§Ã£o binÃ¡ria de sepse (SepsisLabel: 0=NÃ£o-Sepsis, 1=Sepsis)
- **Desbalanceamento**: ~98.2% NÃ£o-Sepsis vs 1.8% Sepsis
- **Dados temporais**: MÃºltiplas mediÃ§Ãµes por paciente ao longo da internaÃ§Ã£o (Hour 0-335+)
- **Missing values**: PresenÃ§a significativa de valores ausentes em variÃ¡veis clÃ­nicas
- **DivisÃ£o**: 80% treino (31.475 pacientes) / 20% teste (8.861 pacientes)

### CritÃ©rio Sepsis-3

A classificaÃ§Ã£o de sepse segue a definiÃ§Ã£o **Sepsis-3**, que considera disfunÃ§Ã£o orgÃ¢nica potencialmente fatal causada por resposta desregulada do hospedeiro Ã  infecÃ§Ã£o.

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
data-mining-proj-crisp-dm/
â”‚
â”œâ”€â”€ ğŸ“ modeling/                          # Notebooks e scripts de modelagem
â”‚   â”œâ”€â”€ 1-KNN_model_eval.ipynb           # K-Nearest Neighbors
â”‚   â”œâ”€â”€ 2-LVQ_model_eval.ipynb           # Learning Vector Quantization
â”‚   â”œâ”€â”€ 3-DecisionTree_model_eval.ipynb  # Ãrvore de DecisÃ£o
â”‚   â”œâ”€â”€ 4-RandomForest_model_eval.ipynb  # Random Forest
â”‚   â”œâ”€â”€ 5-SVM_model_eval.ipynb           # Support Vector Machine
â”‚   â”œâ”€â”€ 5b-SVM_model_eval_OPTUNA.ipynb   # SVM com Optuna
â”‚   â”œâ”€â”€ 6-XGBoost_model_eval.ipynb       # XGBoost
â”‚   â”œâ”€â”€ 7-LightGBM_model_eval.ipynb      # LightGBM
â”‚   â”œâ”€â”€ 8-MLP_model_eval.ipynb           # Multi-Layer Perceptron
â”‚   â”œâ”€â”€ 9-Stacking_model_eval.ipynb      # Stacking Ensemble
â”‚   â”œâ”€â”€ 10-Neural_Committee_model_eval.ipynb  # ComitÃª de Redes Neurais
â”‚   â”œâ”€â”€ plot_results.ipynb               # ComparaÃ§Ã£o de resultados
â”‚   â”œâ”€â”€ plot_roc_curves.ipynb            # GeraÃ§Ã£o de curvas ROC
â”‚   â”œâ”€â”€ manual_implement_models.py       # Modelos customizados
â”‚   â”œâ”€â”€ ml_utils.py                      # Utilidades de ML
â”‚   â”œâ”€â”€ search_utils.py                  # RandomizedSearchCV utilities
â”‚   â”œâ”€â”€ search_utils_optuna.py           # Optuna optimization utilities
â”‚   â”œâ”€â”€ ğŸ“ results/                      # Resultados em JSON
â”‚   â”œâ”€â”€ ğŸ“ searches/                     # HistÃ³rico de buscas
â”‚   â””â”€â”€ ğŸ“ models/                       # Modelos treinados salvos
â”‚
â”œâ”€â”€ ğŸ“ img/                               # Imagens e grÃ¡ficos
â”‚
â”œâ”€â”€ 1-eda-sepsis.ipynb                   # AnÃ¡lise ExploratÃ³ria de Dados
â”œâ”€â”€ 2-data-prep-sepsis-v2.ipynb          # PrÃ©-processamento (versÃ£o final)
â”œâ”€â”€ 3-model_eval.ipynb                   # AvaliaÃ§Ã£o inicial de modelos
â”‚
â”œâ”€â”€ dataset_sepsis.csv                   # Dataset original completo
â”œâ”€â”€ dataset_sepsis_train.csv             # Dataset de treino (sem prep)
â”œâ”€â”€ dataset_sepsis_test.csv              # Dataset de teste (sem prep)
â”œâ”€â”€ dataset_sepsis_train_pid_prep_v2.csv # Treino prÃ©-processado (v2)
â”œâ”€â”€ dataset_sepsis_test_pid_prep_v2.csv  # Teste prÃ©-processado (v2)
â”‚
â”œâ”€â”€ split_dataset.py                     # Script de divisÃ£o treino/teste
â”œâ”€â”€ eda-sepsis.py                        # EDA em script Python
â”œâ”€â”€ requirements.txt                     # DependÃªncias do projeto
â”œâ”€â”€ LICENSE                              # LicenÃ§a MIT
â””â”€â”€ README.md                            # Este arquivo
```

---

## ğŸ”„ Metodologia CRISP-DM

Este projeto segue rigorosamente as 6 fases da metodologia **CRISP-DM** (Cross-Industry Standard Process for Data Mining):

### 1. ğŸ“Œ Business Understanding
**Objetivo**: Desenvolver um sistema de prediÃ§Ã£o precoce de sepse para auxiliar mÃ©dicos na tomada de decisÃ£o clÃ­nica, reduzindo mortalidade e custos hospitalares.

- **Problema**: Sepse Ã© uma das principais causas de morte em UTIs (~30% mortalidade)
- **Meta**: Construir modelo preditivo com alta sensibilidade (recall) para detecÃ§Ã£o precoce
- **MÃ©trica primÃ¡ria**: F1-Score (balanceamento entre precisÃ£o e recall)
- **RestriÃ§Ãµes**: Dataset altamente desbalanceado, presenÃ§a significativa de missing values

### 2. ğŸ“Š Data Understanding
**Notebooks**: `1-eda-sepsis.ipynb`

- AnÃ¡lise estatÃ­stica descritiva completa
- VisualizaÃ§Ã£o de distribuiÃ§Ãµes e correlaÃ§Ãµes
- AnÃ¡lise de missing values (atÃ© 96% em algumas variÃ¡veis)
- IdentificaÃ§Ã£o de padrÃµes temporais
- AnÃ¡lise de desbalanceamento de classes

### 3. ğŸ”§ Data Preparation
**Notebooks**: `2-data-prep-sepsis-v2.ipynb`

#### Pipeline de PrÃ©-processamento:

1. **CriaÃ§Ã£o de Patient ID**: IdentificaÃ§Ã£o Ãºnica baseada em Hour=0 + mudanÃ§a de Age
2. **ImputaÃ§Ã£o por Paciente**: Forward/Backward fill temporal preservando continuidade clÃ­nica
3. **SeleÃ§Ã£o de VariÃ¡veis**:
   - **AnÃ¡lise de Separabilidade**: Separabilidade = |mediana_sepsis - mediana_nÃ£o_sepsis| / std_pooled
   - **Teste Mann-Whitney**: SignificÃ¢ncia estatÃ­stica (p < 0.05)
   - **Missing Threshold**: Descarte de variÃ¡veis com >60% missing + baixa separabilidade
   - **RedundÃ¢ncia**: RemoÃ§Ã£o de SBP/DBP (mantido MAP)
   
4. **TransformaÃ§Ãµes de Normalidade**:
   - **Platelets**: Box-Cox (Î» â‰ˆ 0.3)
   - **WBC**: Yeo-Johnson (Î» â‰ˆ 0.8)
   - **BUN, MAP, Creatinine, Glucose**: Logaritmo natural
   
5. **Balanceamento**: Undersampling da classe majoritÃ¡ria (5% dos NÃ£o-Sepsis)
6. **NormalizaÃ§Ã£o**: StandardScaler (Z-score) em todas as features numÃ©ricas

#### VariÃ¡veis Finais Selecionadas:
- Sinais Vitais: HR, O2Sat, Temp, Resp, MAP
- Exames: BUN, Creatinine, Glucose, Hct, Hgb, WBC, Platelets
- Temporal: Hour, ICULOS, HospAdmTime
- DemogrÃ¡fica: Gender

### 4. ğŸ¤– Modeling
**Notebooks**: `modeling/1-*.ipynb` atÃ© `modeling/10-*.ipynb`

#### Modelos Implementados:

| Categoria | Modelos |
|-----------|---------|
| **Baseados em InstÃ¢ncia** | KNN, LVQ (Learning Vector Quantization) |
| **Baseados em Ãrvore** | Decision Tree, Random Forest, XGBoost, LightGBM |
| **Kernel Methods** | SVM (Linear, RBF, Polynomial) |
| **Redes Neurais** | MLP (Multi-Layer Perceptron) |
| **Ensemble AvanÃ§ado** | Stacking HeterogÃªneo, ComitÃª de Redes Neurais |

#### EstratÃ©gia de OtimizaÃ§Ã£o:

- **RandomizedSearchCV**: 20 buscas Ã— 80 iteraÃ§Ãµes cada (base)
- **Optuna**: Busca Bayesiana para SVM (experimento)
- **Cross-Validation**: 5-fold Stratified CV
- **MÃ©trica de OtimizaÃ§Ã£o**: F1-Score macro
- **Amostragem**: 5% do dataset de treino para acelerar buscas

### 5. ğŸ“ˆ Evaluation
**Notebooks**: `modeling/plot_results.ipynb`, `modeling/plot_roc_curves.ipynb`

#### MÃ©tricas Avaliadas:

- **F1-Score**: MÃ©trica primÃ¡ria (balanceamento precisÃ£o/recall)
- **Precision & Recall**: AnÃ¡lise de trade-offs
- **G-Mean**: âˆš(Sensitivity Ã— Specificity) para dados desbalanceados
- **AUC-ROC**: Capacidade discriminativa geral
- **Confusion Matrix**: AnÃ¡lise de erros tipo I e II
- **Youden's Index**: Melhor threshold da curva ROC

#### VisualizaÃ§Ãµes:

- Curvas ROC com probabilidades preditas reais
- ComparaÃ§Ã£o de mÃ©tricas entre modelos
- AnÃ¡lise de overfitting (treino vs validaÃ§Ã£o)
- DistribuiÃ§Ã£o de probabilidades por classe
- Matrizes de confusÃ£o normalizadas

### 6. ğŸš€ Deployment
**Status**: Projeto acadÃªmico finalizado

- Todos os modelos exportados em formato `.pkl` (joblib)
- Resultados salvos em JSON para reprodutibilidade
- Pipeline de prÃ©-processamento documentado
- CÃ³digo modular e reutilizÃ¡vel

---

## ğŸ¤– Modelos Implementados

### 1. K-Nearest Neighbors (KNN)
- **HiperparÃ¢metros**: n_neighbors, metric (euclidean/manhattan), weights (uniform/distance)
- **Resultado**: F1-Score ~0.59, alto overfitting (treino â‰ˆ1.0, validaÃ§Ã£o ~0.35-0.60)
- **ObservaÃ§Ã£o**: Extrema sensibilidade a k, memorizaÃ§Ã£o do dataset

### 2. Learning Vector Quantization (LVQ)
- **ImplementaÃ§Ã£o**: Customizada (classe LVQClassifier)
- **HiperparÃ¢metros**: prototypes_per_class, n_epochs, learning_rate
- **Resultado**: Desempenho moderado, boa interpretabilidade

### 3. Decision Tree
- **HiperparÃ¢metros**: max_depth, min_samples_split, min_samples_leaf, criterion
- **Resultado**: F1-Score ~0.53, quedas abruptas em validaÃ§Ã£o
- **ObservaÃ§Ã£o**: ConfiguraÃ§Ãµes especÃ­ficas causam Ã¡rvores excessivamente complexas/simples

### 4. Random Forest â­
- **HiperparÃ¢metros**: n_estimators, max_depth, min_samples_split, max_features
- **Resultado**: **Melhor desempenho geral** - F1-Score ~0.60 (Â±0.012)
- **ObservaÃ§Ã£o**: ValidaÃ§Ã£o estÃ¡vel apesar de oscilaÃ§Ãµes no treino (robustez do ensemble)

### 5. Support Vector Machine (SVM)
- **Kernels testados**: Linear, RBF, Polynomial
- **HiperparÃ¢metros**: C, gamma, degree
- **Resultado**: F1-Score ~0.52, extrema sensibilidade aos hiperparÃ¢metros
- **ObservaÃ§Ã£o**: Janela estreita de configuraÃ§Ãµes Ã³timas

### 6. XGBoost
- **HiperparÃ¢metros**: n_estimators, max_depth, learning_rate, subsample, colsample_bytree
- **Resultado**: F1-Score ~0.55, overfitting visÃ­vel (treino ~0.9, validaÃ§Ã£o ~0.5)
- **ObservaÃ§Ã£o**: Exact greedy algorithm se ajusta fortemente aos dados de treino

### 7. LightGBM
- **HiperparÃ¢metros**: Similar ao XGBoost + num_leaves, min_child_samples
- **Resultado**: F1-Score ~0.55, oscilaÃ§Ãµes pronunciadas
- **ObservaÃ§Ã£o**: Leaf-wise growth gera picos mais acentuados que XGBoost

### 8. Multi-Layer Perceptron (MLP)
- **Arquiteturas**: 1-3 camadas ocultas, 50-200 neurÃ´nios
- **HiperparÃ¢metros**: hidden_layer_sizes, alpha, learning_rate_init, activation
- **Resultado**: F1-Score ~0.54, requer ajuste fino de regularizaÃ§Ã£o

### 9. Stacking Ensemble
- **ImplementaÃ§Ã£o**: Classe HeterogeneousStackingCommittee
- **Base Learners**: Decision Tree (shallow) + MLP (weak) + XGBoost (conservador)
- **Meta-Learner**: Logistic Regression (C=1-50)
- **Resultado**: F1-Score ~0.56, combina forÃ§as de paradigmas diferentes

### 10. Neural Committee
- **ImplementaÃ§Ã£o**: Classe NeuralNetworkCommittee (VotingClassifier de 3 MLPs)
- **Arquiteturas**: MLP1 (relu), MLP2 (tanh), MLP3 (logistic) com configs individuais
- **VotaÃ§Ã£o**: Soft voting (predict_proba)
- **Resultado**: F1-Score ~0.55, ensemble homogÃªneo de redes neurais

---

### ObservaÃ§Ãµes Principais

1. **Random Forest** dominou pela estabilidade (menor desvio padrÃ£o) e robustez do ensemble
2. **KNN** surpreendeu com alto F1-Score mas com **overfitting severo** (treino â‰ˆ1.0)
3. **Gradient Boosting** (XGBoost, LightGBM) teve desempenho similar mas com maior overfitting
4. **Ensembles avanÃ§ados** (Stacking, Neural Committee) nÃ£o superaram Random Forest neste dataset
5. **Todos os modelos** lutaram com a natureza desbalanceada e missing values do dataset

---

## ğŸ’» InstalaÃ§Ã£o e Uso

### Requisitos

- Python 3.8+
- 8GB RAM mÃ­nimo (16GB recomendado para modelos ensemble)

### InstalaÃ§Ã£o

```bash
# 1. Clonar o repositÃ³rio
git clone https://github.com/seu-usuario/data-mining-proj-crisp-dm.git
cd data-mining-proj-crisp-dm

# 2. Criar ambiente virtual
python -m venv .venv

# 3. Ativar ambiente virtual
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

# 4. Instalar dependÃªncias
pip install -r requirements.txt
```

### Executar Pipeline Completo

```bash
# 1. Dividir dataset (se necessÃ¡rio)
python split_dataset.py

# 2. Executar EDA (opcional)
jupyter notebook 1-eda-sepsis.ipynb

# 3. PrÃ©-processar dados
jupyter notebook 2-data-prep-sepsis-v2.ipynb

# 4. Treinar modelos individuais
jupyter notebook modeling/4-RandomForest_model_eval.ipynb

# 5. Gerar curvas ROC
jupyter notebook modeling/plot_roc_curves.ipynb

# 6. Comparar resultados
jupyter notebook modeling/plot_results.ipynb
```

### Uso RÃ¡pido - Carregar Modelo Treinado

```python
import joblib
import pandas as pd
from sklearn.preprocessing import StandardScaler

# Carregar modelo
model = joblib.load('modeling/models/random_forest_best_model.joblib')

# Carregar dados de teste prÃ©-processados
X_test = pd.read_csv('dataset_sepsis_test_pid_prep_v2.csv')
y_test = X_test['SepsisLabel']
X_test = X_test.drop('SepsisLabel', axis=1)

# PrediÃ§Ã£o
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

# AvaliaÃ§Ã£o
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))
```

---

## ğŸ“š DicionÃ¡rio de VariÃ¡veis

### ğŸ•’ Identificadores e Tempo
- **Hour**: Hora desde a admissÃ£o na UTI (0-335+ horas)
- **ICULOS**: DuraÃ§Ã£o da estadia na UTI em horas
- **HospAdmTime**: Tempo entre admissÃ£o hospitalar e UTI (horas, negativos = admissÃ£o direta)
- **PATIENT_ID** (criado): Identificador Ãºnico de paciente

### â¤ï¸ Sinais Vitais (Vital Signs)
- **HR**: FrequÃªncia cardÃ­aca (batimentos/min)
- **O2Sat**: SaturaÃ§Ã£o de oxigÃªnio perifÃ©rico (%)
- **Temp**: Temperatura corporal (Â°C)
- **SBP**: PressÃ£o arterial sistÃ³lica (mmHg) [removida - redundante com MAP]
- **MAP**: PressÃ£o arterial mÃ©dia (mmHg) â­ **Mantida**
- **DBP**: PressÃ£o arterial diastÃ³lica (mmHg) [removida - redundante com MAP]
- **Resp**: Taxa respiratÃ³ria (respiraÃ§Ãµes/min)

### ğŸ« Gases SanguÃ­neos (Blood Gases) [Maioria removida por >60% missing]
- ~~EtCO2~~: CO2 expirado
- ~~BaseExcess~~: Excesso de base
- ~~HCO3~~: Bicarbonato
- ~~FiO2~~: FraÃ§Ã£o inspirada de oxigÃªnio
- ~~pH~~: pH arterial
- ~~PaCO2~~: PressÃ£o parcial de CO2
- ~~SaO2~~: SaturaÃ§Ã£o de oxigÃªnio arterial

### ğŸ§ª Exames Laboratoriais (Laboratory Tests)
**Mantidos (boa separabilidade)**:
- **BUN**: Ureia (mg/dL) - FunÃ§Ã£o renal
- **Creatinine**: Creatinina (mg/dL) - FunÃ§Ã£o renal â­
- **Glucose**: Glicose (mg/dL) - Metabolismo

**Removidos (alta missing + baixa separabilidade)**:
- ~~AST~~: Aspartato aminotransferase
- ~~Alkalinephos~~: Fosfatase alcalina
- ~~Calcium~~: CÃ¡lcio
- ~~Chloride~~: Cloreto
- ~~Bilirubin_direct~~: Bilirrubina direta
- ~~Lactate~~: Lactato [surpreendentemente baixa separabilidade]
- ~~Magnesium~~: MagnÃ©sio
- ~~Phosphate~~: Fosfato
- ~~Potassium~~: PotÃ¡ssio
- ~~Bilirubin_total~~: Bilirrubina total
- ~~TroponinI~~: Troponina I

### ğŸ©¸ Hematologia (Hematology)
**Mantidos**:
- **Hct**: HematÃ³crito (%) - Volume de hemÃ¡cias
- **Hgb**: Hemoglobina (g/dL) - Capacidade de oxigenaÃ§Ã£o
- **WBC**: Contagem de leucÃ³citos (1000/uL) - InfecÃ§Ã£o/inflamaÃ§Ã£o â­
- **Platelets**: Contagem de plaquetas (1000/uL) - CoagulaÃ§Ã£o â­

**Removidos**:
- ~~PTT~~: Tempo de tromboplastina parcial
- ~~Fibrinogen~~: FibrinogÃªnio

### ğŸ‘¤ InformaÃ§Ãµes DemogrÃ¡ficas
- **Age**: Idade (anos) [removida - baixa separabilidade]
- **Gender**: GÃªnero (0=Feminino, 1=Masculino) â­ **Mantida**
- ~~Unit1~~: UTI MÃ©dica [removida - >90% missing]
- ~~Unit2~~: UTI CirÃºrgica/CardiolÃ³gica [removida - >90% missing]

### ğŸ¯ VariÃ¡vel Alvo
- **SepsisLabel**: RÃ³tulo de sepse (0=NÃ£o-Sepsis, 1=Sepsis)


## ğŸ“– ReferÃªncias

1. **PhysioNet 2019 Challenge**: [https://physionet.org/content/challenge-2019/](https://physionet.org/content/challenge-2019/)
2. **Sepsis-3 Definition**: Singer M, et al. JAMA. 2016;315(8):801-810
3. **CRISP-DM Methodology**: [https://www.datascience-pm.com/crisp-dm-2/](https://www.datascience-pm.com/crisp-dm-2/)
4. **Scikit-learn Documentation**: [https://scikit-learn.org/](https://scikit-learn.org/)
5. **Imbalanced-learn**: [https://imbalanced-learn.org/](https://imbalanced-learn.org/)

---

## ğŸ“ ObservaÃ§Ãµes Finais

Este projeto estÃ¡ **oficialmente finalizado** (Dezembro 2025). AtualizaÃ§Ãµes esporÃ¡dicas podem ocorrer para:
- ExperimentaÃ§Ã£o de novos modelos
- OtimizaÃ§Ãµes de hiperparÃ¢metros
- Melhorias na documentaÃ§Ã£o
- CorreÃ§Ãµes de bugs

Para questÃµes ou sugestÃµes, abra uma **issue** no GitHub.
