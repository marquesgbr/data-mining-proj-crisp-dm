{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ba373a",
   "metadata": {},
   "source": [
    "### 1.1 Importar Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa60bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n",
      "Pandas: 2.3.2\n",
      "NumPy: 2.3.3\n",
      "Scikit-learn: 1.7.2\n",
      "XGBoost: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, roc_curve)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform, randint\n",
    "from joblib import dump, load\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar funções dos módulos customizados\n",
    "from ml_utils import gmean_score, evaluate_model, load_and_prepare_datasets\n",
    "from search_utils import (plot_search_history, multiple_randomized_search,\n",
    "                          plot_search_history_from_loaded, \n",
    "                          load_search_results, get_best_params_from_saved,\n",
    "                          save_search_results, save_final_results)\n",
    "\n",
    "# Configurações de plotagem\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"XGBoost: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fcd8c",
   "metadata": {},
   "source": [
    "### 1.2 Definir Nome do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e20e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nome do modelo para uso em salvamento e exibição\n",
    "MODEL_NAME = \"Stacking\"\n",
    "print(f\"Modelo: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab4a6c",
   "metadata": {},
   "source": [
    "### 1.3 Definir Comitê Heterogêneo (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe0ec8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comitê Heterogêneo (Stacking) com Decision Tree, Random Forest e XGBoost definido com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# COMITÊ HETEROGÊNEO (STACKING) - IMPLEMENTAÇÃO\n",
    "# ======================================================================\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class HeterogeneousStackingCommittee(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, \n",
    "                 # Parâmetros Decision Tree (variáveis)\n",
    "                 dt_max_depth=None, dt_min_samples_split=2, dt_min_samples_leaf=1,\n",
    "                 # Parâmetros Decision Tree (fixos)\n",
    "                 dt_criterion='gini', dt_max_features='sqrt',\n",
    "                 # Parâmetros Random Forest (variáveis)\n",
    "                 rf_n_estimators=100, rf_max_depth=None,\n",
    "                 # Parâmetros Random Forest (fixos)\n",
    "                 rf_criterion='gini', rf_max_features='sqrt',\n",
    "                 rf_min_samples_split=16, rf_min_samples_leaf=1,\n",
    "                 # Parâmetros XGBoost (variáveis)\n",
    "                 xgb_n_estimators=100, xgb_max_depth=6, xgb_learning_rate=0.3,\n",
    "                 # Parâmetros XGBoost (fixos - melhores valores)\n",
    "                 xgb_subsample=0.6527464393047274, xgb_colsample_bytree=0.6502374440504688,\n",
    "                 xgb_min_child_weight=1, xgb_gamma=0.13697900853304845,\n",
    "                 xgb_reg_alpha=0.778102210605468, xgb_reg_lambda=1.518712387770365,\n",
    "                 # Parâmetros do meta-estimador\n",
    "                 meta_C=1.0, meta_max_iter=1000,\n",
    "                 # Configurações gerais\n",
    "                 cv=5, random_state=None):\n",
    "        \"\"\"\n",
    "        Comitê Heterogêneo usando StackingClassifier com árvores de decisão\n",
    "        \n",
    "        Estimadores base: Decision Tree, Random Forest, XGBoost\n",
    "        Meta-estimador: Logistic Regression\n",
    "        \"\"\"\n",
    "        # Parâmetros Decision Tree\n",
    "        self.dt_max_depth = dt_max_depth\n",
    "        self.dt_min_samples_split = dt_min_samples_split\n",
    "        self.dt_min_samples_leaf = dt_min_samples_leaf\n",
    "        self.dt_criterion = dt_criterion\n",
    "        self.dt_max_features = dt_max_features\n",
    "        \n",
    "        self.rf_n_estimators = rf_n_estimators\n",
    "        self.rf_max_depth = rf_max_depth\n",
    "        self.rf_criterion = rf_criterion\n",
    "        self.rf_max_features = rf_max_features\n",
    "        self.rf_min_samples_split = rf_min_samples_split\n",
    "        self.rf_min_samples_leaf = rf_min_samples_leaf\n",
    "        \n",
    "        # Parâmetros XGBoost\n",
    "        self.xgb_n_estimators = xgb_n_estimators\n",
    "        self.xgb_max_depth = xgb_max_depth\n",
    "        self.xgb_learning_rate = xgb_learning_rate\n",
    "        self.xgb_subsample = xgb_subsample\n",
    "        self.xgb_colsample_bytree = xgb_colsample_bytree\n",
    "        self.xgb_min_child_weight = xgb_min_child_weight\n",
    "        self.xgb_gamma = xgb_gamma\n",
    "        self.xgb_reg_alpha = xgb_reg_alpha\n",
    "        self.xgb_reg_lambda = xgb_reg_lambda\n",
    "        \n",
    "        # Parâmetros do meta-estimador\n",
    "        self.meta_C = meta_C\n",
    "        self.meta_max_iter = meta_max_iter\n",
    "        \n",
    "        # Configurações gerais\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Definir estimadores base com parâmetros otimizáveis\n",
    "        base_estimators = [\n",
    "            ('decision_tree', DecisionTreeClassifier(\n",
    "                max_depth=self.dt_max_depth,\n",
    "                min_samples_split=self.dt_min_samples_split,\n",
    "                min_samples_leaf=self.dt_min_samples_leaf,\n",
    "                criterion=self.dt_criterion,\n",
    "                max_features=self.dt_max_features,\n",
    "                random_state=self.random_state\n",
    "            )),\n",
    "            ('random_forest', RandomForestClassifier(\n",
    "                n_estimators=self.rf_n_estimators,\n",
    "                max_depth=self.rf_max_depth,\n",
    "                criterion=self.rf_criterion,\n",
    "                max_features=self.rf_max_features,\n",
    "                min_samples_split=self.rf_min_samples_split,\n",
    "                min_samples_leaf=self.rf_min_samples_leaf,\n",
    "                random_state=self.random_state\n",
    "            )),\n",
    "            ('xgboost', xgb.XGBClassifier(\n",
    "                n_estimators=self.xgb_n_estimators,\n",
    "                max_depth=self.xgb_max_depth,\n",
    "                learning_rate=self.xgb_learning_rate,\n",
    "                subsample=self.xgb_subsample,\n",
    "                colsample_bytree=self.xgb_colsample_bytree,\n",
    "                min_child_weight=self.xgb_min_child_weight,\n",
    "                gamma=self.xgb_gamma,\n",
    "                reg_alpha=self.xgb_reg_alpha,\n",
    "                reg_lambda=self.xgb_reg_lambda,\n",
    "                objective='binary:logistic',\n",
    "                eval_metric='logloss',\n",
    "                random_state=self.random_state,\n",
    "                verbosity=0\n",
    "            ))\n",
    "        ]\n",
    "        \n",
    "        # Meta-estimador (Logistic Regression)\n",
    "        meta_estimator = LogisticRegression(\n",
    "            C=self.meta_C,\n",
    "            max_iter=self.meta_max_iter,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        # Criar o StackingClassifier\n",
    "        self.stacking_classifier = StackingClassifier(\n",
    "            estimators=base_estimators,\n",
    "            final_estimator=meta_estimator,\n",
    "            cv=self.cv,\n",
    "            stack_method='predict_proba',  # Usar probabilidades\n",
    "            n_jobs=1  # Evitar conflitos de paralelização\n",
    "        )\n",
    "        \n",
    "        # Treinar o ensemble\n",
    "        self.stacking_classifier.fit(X, y)\n",
    "        self.classes_ = self.stacking_classifier.classes_\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.stacking_classifier.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.stacking_classifier.predict_proba(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))\n",
    "\n",
    "print(\"Comitê Heterogêneo (Stacking) com Decision Tree, Random Forest e XGBoost definido com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88b273",
   "metadata": {},
   "source": [
    "### 1.4 Carregar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de treino: (853006, 19)\n",
      "Dataset de teste: (215171, 19)\n",
      "\n",
      "Distribuição das classes:\n",
      "Treino: {0.0: 831112, 1.0: 21894}\n",
      "Teste: {0.0: 209675, 1.0: 5496}\n",
      "\n",
      "Distribuição das classes:\n",
      "Treino: {0.0: 831112, 1.0: 21894}\n",
      "Teste: {0.0: 209675, 1.0: 5496}\n"
     ]
    }
   ],
   "source": [
    "# Carregamento e preparação inicial dos dados\n",
    "print(\"Carregando datasets...\")\n",
    "\n",
    "# Carregar e preparar datasets usando função do módulo\n",
    "(X_train, X_test, y_train, y_test, \n",
    " X_train_scaled, X_test_scaled, \n",
    " train_data, test_data, scaler) = load_and_prepare_datasets()\n",
    "\n",
    "print(f\"Dataset de treino: {train_data.shape}\")\n",
    "print(f\"Dataset de teste: {test_data.shape}\")\n",
    "\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "print(\"Treino:\", y_train.value_counts().to_dict())\n",
    "print(\"Teste:\", y_test.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e2b91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "O2Sat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SBP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DBP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Resp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BUN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unit1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unit2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HospAdmTime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ICULOS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Critical_Risk_Window",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Time_Category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SepsisLabel",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "35d75c7f-cfa3-4f39-8c69-412f6b51502f",
       "rows": [
        [
         "0",
         "8",
         "-1.1097944366836745",
         "-0.4601797972892955",
         "-0.936182396179708",
         "2.87336491135296",
         "3.044200612267326",
         "2.159974443333858",
         "-0.0736012350859598",
         "-0.2771860514420799",
         "-1.39357951670772",
         "0.4507157624350807",
         "1.0",
         "1.0",
         "0.0",
         "-12.06",
         "9.0",
         "0",
         "0",
         "0.0"
        ],
        [
         "1",
         "47",
         "0.5699710093354073",
         "-2.437770480712409",
         "0.1734770445575556",
         "0.3939602121785264",
         "0.6507831363841678",
         "0.4309426287535458",
         "-0.9973237405476244",
         "0.3091707774149635",
         "0.2456159065449318",
         "-0.2751078157149356",
         "1.0",
         "1.0",
         "0.0",
         "-0.05",
         "48.0",
         "0",
         "1",
         "0.0"
        ],
        [
         "2",
         "6",
         "0.1500296478306369",
         "0.978067972472969",
         "0.0161139406337461",
         "-0.9834868429183812",
         "-0.5538501262934915",
         "-0.1986829337362194",
         "-0.0736012350859598",
         "-0.310738624275361",
         "0.1213677719195975",
         "-0.1912664785221958",
         "1.0",
         "1.0",
         "0.0",
         "-0.02",
         "7.0",
         "0",
         "0",
         "0.0"
        ],
        [
         "3",
         "39",
         "-0.2699117136741334",
         "0.2589440875918367",
         "0.2893547834449668",
         "0.8531092305441623",
         "0.4050938398230071",
         "-0.1154602785560446",
         "0.7520149316733524",
         "0.2985914374982416",
         "-0.003964924479364",
         "-3.1529195642522194",
         "0.0",
         "0.0",
         "1.0",
         "-75.85",
         "43.0",
         "0",
         "1",
         "0.0"
        ],
        [
         "4",
         "127",
         "0.5699710093354073",
         "-0.4601797972892955",
         "0.0070124212356604",
         "0.7612794268710351",
         "1.8342546872935597",
         "1.0550498228769023",
         "-0.5209867333216573",
         "0.7021396354059021",
         "-0.1805445000968947",
         "0.0304330288288612",
         "0.0",
         "0.0",
         "1.0",
         "-0.03",
         "128.0",
         "1",
         "2",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>BUN</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>Critical_Risk_Window</th>\n",
       "      <th>Time_Category</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.109794</td>\n",
       "      <td>-0.460180</td>\n",
       "      <td>-0.936182</td>\n",
       "      <td>2.873365</td>\n",
       "      <td>3.044201</td>\n",
       "      <td>2.159974</td>\n",
       "      <td>-0.073601</td>\n",
       "      <td>-0.277186</td>\n",
       "      <td>-1.393580</td>\n",
       "      <td>0.450716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>0.569971</td>\n",
       "      <td>-2.437770</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.393960</td>\n",
       "      <td>0.650783</td>\n",
       "      <td>0.430943</td>\n",
       "      <td>-0.997324</td>\n",
       "      <td>0.309171</td>\n",
       "      <td>0.245616</td>\n",
       "      <td>-0.275108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.150030</td>\n",
       "      <td>0.978068</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>-0.983487</td>\n",
       "      <td>-0.553850</td>\n",
       "      <td>-0.198683</td>\n",
       "      <td>-0.073601</td>\n",
       "      <td>-0.310739</td>\n",
       "      <td>0.121368</td>\n",
       "      <td>-0.191266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.269912</td>\n",
       "      <td>0.258944</td>\n",
       "      <td>0.289355</td>\n",
       "      <td>0.853109</td>\n",
       "      <td>0.405094</td>\n",
       "      <td>-0.115460</td>\n",
       "      <td>0.752015</td>\n",
       "      <td>0.298591</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>-3.152920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-75.85</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>0.569971</td>\n",
       "      <td>-0.460180</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.761279</td>\n",
       "      <td>1.834255</td>\n",
       "      <td>1.055050</td>\n",
       "      <td>-0.520987</td>\n",
       "      <td>0.702140</td>\n",
       "      <td>-0.180545</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hour        HR     O2Sat      Temp       SBP       MAP       DBP      Resp  \\\n",
       "0     8 -1.109794 -0.460180 -0.936182  2.873365  3.044201  2.159974 -0.073601   \n",
       "1    47  0.569971 -2.437770  0.173477  0.393960  0.650783  0.430943 -0.997324   \n",
       "2     6  0.150030  0.978068  0.016114 -0.983487 -0.553850 -0.198683 -0.073601   \n",
       "3    39 -0.269912  0.258944  0.289355  0.853109  0.405094 -0.115460  0.752015   \n",
       "4   127  0.569971 -0.460180  0.007012  0.761279  1.834255  1.055050 -0.520987   \n",
       "\n",
       "        BUN       WBC  Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  \\\n",
       "0 -0.277186 -1.393580   0.450716     1.0    1.0    0.0       -12.06     9.0   \n",
       "1  0.309171  0.245616  -0.275108     1.0    1.0    0.0        -0.05    48.0   \n",
       "2 -0.310739  0.121368  -0.191266     1.0    1.0    0.0        -0.02     7.0   \n",
       "3  0.298591 -0.003965  -3.152920     0.0    0.0    1.0       -75.85    43.0   \n",
       "4  0.702140 -0.180545   0.030433     0.0    0.0    1.0        -0.03   128.0   \n",
       "\n",
       "   Critical_Risk_Window  Time_Category  SepsisLabel  \n",
       "0                     0              0          0.0  \n",
       "1                     0              1          0.0  \n",
       "2                     0              0          0.0  \n",
       "3                     0              1          0.0  \n",
       "4                     1              2          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef93427",
   "metadata": {},
   "source": [
    "## 2. Sampling para Busca de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a10ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARAÇÃO DE AMOSTRA PARA BUSCA DE HIPERPARÂMETROS ===\n",
      "Dataset original de treino: 853,006 amostras\n",
      "Amostra para busca de hiperparâmetros: 8,531 amostras\n",
      "Redução: 99.0%\n",
      "\n",
      "Distribuição das classes na amostra:\n",
      "Amostra: {0.0: 8312, 1.0: 219}\n",
      "Original: {0.0: 831112, 1.0: 21894}\n",
      "Dataset original de treino: 853,006 amostras\n",
      "Amostra para busca de hiperparâmetros: 8,531 amostras\n",
      "Redução: 99.0%\n",
      "\n",
      "Distribuição das classes na amostra:\n",
      "Amostra: {0.0: 8312, 1.0: 219}\n",
      "Original: {0.0: 831112, 1.0: 21894}\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# SAMPLING ESTRATIFICADO PARA BUSCA DE HIPERPARÂMETROS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=== PREPARAÇÃO DE AMOSTRA PARA BUSCA DE HIPERPARÂMETROS ===\")\n",
    "\n",
    "# Amostra estratificada do dataset de treino (muito pequena devido à complexidade)\n",
    "_, X_sample, _, y_sample = train_test_split(\n",
    "    X_train_scaled, y_train, \n",
    "    test_size=0.01, \n",
    "    stratify=y_train,\n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "print(f\"Dataset original de treino: {X_train_scaled.shape[0]:,} amostras\")\n",
    "print(f\"Amostra para busca de hiperparâmetros: {X_sample.shape[0]:,} amostras\")\n",
    "print(f\"Redução: {(1 - X_sample.shape[0]/X_train_scaled.shape[0])*100:.1f}%\")\n",
    "\n",
    "print(\"\\nDistribuição das classes na amostra:\")\n",
    "print(\"Amostra:\", pd.Series(y_sample).value_counts().to_dict())\n",
    "print(\"Original:\", y_train.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045f5bf",
   "metadata": {},
   "source": [
    "## 3.1 Definir Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5214135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração da validação cruzada estratificada\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda55987",
   "metadata": {},
   "source": [
    "## 4. Stacking - Busca de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "296f34c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BUSCA DE HIPERPARÂMETROS - Stacking ===\n",
      "Iniciando busca de hiperparâmetros para Stacking...\n",
      "Executando 20 buscas com 2 iterações cada...\n",
      "\n",
      "Busca 1/20...\n",
      "Melhor score desta busca: 0.0265\n",
      "Melhor configuração desta busca: {'dt_max_depth': 4, 'dt_min_samples_leaf': 18, 'dt_min_samples_split': 34, 'meta_C': np.float64(3.176949833122895), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 233, 'xgb_learning_rate': np.float64(1.7410978906984163), 'xgb_max_depth': 8, 'xgb_n_estimators': 269}\n",
      "Melhor score geral até agora: 0.0265\n",
      "\n",
      "Busca 2/20...\n",
      "Melhor score desta busca: 0.0265\n",
      "Melhor configuração desta busca: {'dt_max_depth': 4, 'dt_min_samples_leaf': 18, 'dt_min_samples_split': 34, 'meta_C': np.float64(3.176949833122895), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 233, 'xgb_learning_rate': np.float64(1.7410978906984163), 'xgb_max_depth': 8, 'xgb_n_estimators': 269}\n",
      "Melhor score geral até agora: 0.0265\n",
      "\n",
      "Busca 2/20...\n",
      "Melhor score desta busca: 0.0263\n",
      "Melhor configuração desta busca: {'dt_max_depth': 17, 'dt_min_samples_leaf': 17, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.280028077503617), 'meta_max_iter': 3000, 'rf_max_depth': 35, 'rf_n_estimators': 222, 'xgb_learning_rate': np.float64(0.6598564029633305), 'xgb_max_depth': 5, 'xgb_n_estimators': 289}\n",
      "Melhor score geral até agora: 0.0265\n",
      "\n",
      "Busca 3/20...\n",
      "Melhor score desta busca: 0.0263\n",
      "Melhor configuração desta busca: {'dt_max_depth': 17, 'dt_min_samples_leaf': 17, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.280028077503617), 'meta_max_iter': 3000, 'rf_max_depth': 35, 'rf_n_estimators': 222, 'xgb_learning_rate': np.float64(0.6598564029633305), 'xgb_max_depth': 5, 'xgb_n_estimators': 289}\n",
      "Melhor score geral até agora: 0.0265\n",
      "\n",
      "Busca 3/20...\n",
      "Melhor score desta busca: 0.0341\n",
      "Melhor configuração desta busca: {'dt_max_depth': 7, 'dt_min_samples_leaf': 7, 'dt_min_samples_split': 28, 'meta_C': np.float64(9.563356430296048), 'meta_max_iter': 100, 'rf_max_depth': 17, 'rf_n_estimators': 242, 'xgb_learning_rate': np.float64(0.9392907175242635), 'xgb_max_depth': 8, 'xgb_n_estimators': 312}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 4/20...\n",
      "Melhor score desta busca: 0.0341\n",
      "Melhor configuração desta busca: {'dt_max_depth': 7, 'dt_min_samples_leaf': 7, 'dt_min_samples_split': 28, 'meta_C': np.float64(9.563356430296048), 'meta_max_iter': 100, 'rf_max_depth': 17, 'rf_n_estimators': 242, 'xgb_learning_rate': np.float64(0.9392907175242635), 'xgb_max_depth': 8, 'xgb_n_estimators': 312}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 4/20...\n",
      "Melhor score desta busca: 0.0170\n",
      "Melhor configuração desta busca: {'dt_max_depth': 46, 'dt_min_samples_leaf': 38, 'dt_min_samples_split': 5, 'meta_C': np.float64(5.658385782961916), 'meta_max_iter': 3000, 'rf_max_depth': 18, 'rf_n_estimators': 108, 'xgb_learning_rate': np.float64(0.8386241593408649), 'xgb_max_depth': 3, 'xgb_n_estimators': 368}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 5/20...\n",
      "Melhor score desta busca: 0.0170\n",
      "Melhor configuração desta busca: {'dt_max_depth': 46, 'dt_min_samples_leaf': 38, 'dt_min_samples_split': 5, 'meta_C': np.float64(5.658385782961916), 'meta_max_iter': 3000, 'rf_max_depth': 18, 'rf_n_estimators': 108, 'xgb_learning_rate': np.float64(0.8386241593408649), 'xgb_max_depth': 3, 'xgb_n_estimators': 368}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 5/20...\n",
      "Melhor score desta busca: 0.0178\n",
      "Melhor configuração desta busca: {'dt_max_depth': 3, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.5234404719761026), 'meta_max_iter': 2000, 'rf_max_depth': 11, 'rf_n_estimators': 173, 'xgb_learning_rate': np.float64(0.9283889850897893), 'xgb_max_depth': 10, 'xgb_n_estimators': 306}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 6/20...\n",
      "Melhor score desta busca: 0.0178\n",
      "Melhor configuração desta busca: {'dt_max_depth': 3, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.5234404719761026), 'meta_max_iter': 2000, 'rf_max_depth': 11, 'rf_n_estimators': 173, 'xgb_learning_rate': np.float64(0.9283889850897893), 'xgb_max_depth': 10, 'xgb_n_estimators': 306}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 6/20...\n",
      "Melhor score desta busca: 0.0085\n",
      "Melhor configuração desta busca: {'dt_max_depth': 38, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 8, 'meta_C': np.float64(1.6653645914541049), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 172, 'xgb_learning_rate': np.float64(0.7916547652645569), 'xgb_max_depth': 6, 'xgb_n_estimators': 338}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 7/20...\n",
      "Melhor score desta busca: 0.0085\n",
      "Melhor configuração desta busca: {'dt_max_depth': 38, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 8, 'meta_C': np.float64(1.6653645914541049), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 172, 'xgb_learning_rate': np.float64(0.7916547652645569), 'xgb_max_depth': 6, 'xgb_n_estimators': 338}\n",
      "Melhor score geral até agora: 0.0341\n",
      "\n",
      "Busca 7/20...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Múltiplas execuções do RandomizedSearchCV\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIniciando busca de hiperparâmetros para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m model_search, model_all_searches, best_params = \u001b[43mmultiple_randomized_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHeterogeneousStackingCommittee\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_searches\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter_per_search\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Processamento sequencial\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Seleção da Melhor Configuração\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- RESULTADOS \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 158\u001b[39m, in \u001b[36mmultiple_randomized_search\u001b[39m\u001b[34m(estimator, param_distributions, X, y, cv_strategy, n_searches, n_iter_per_search, scoring, random_state, n_jobs, verbose)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# RandomizedSearchCV para esta execução\u001b[39;00m\n\u001b[32m    146\u001b[39m search = RandomizedSearchCV(\n\u001b[32m    147\u001b[39m     estimator=estimator,\n\u001b[32m    148\u001b[39m     param_distributions=param_distributions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m     verbose=\u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Menos verbose para múltiplas execuções\u001b[39;00m\n\u001b[32m    156\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Armazenar resultados desta busca\u001b[39;00m\n\u001b[32m    161\u001b[39m search_results = {\n\u001b[32m    162\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msearch_idx\u001b[39m\u001b[33m'\u001b[39m: search_idx,\n\u001b[32m    163\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_score\u001b[39m\u001b[33m'\u001b[39m: search.best_score_,\n\u001b[32m    164\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_params\u001b[39m\u001b[33m'\u001b[39m: search.best_params_,\n\u001b[32m    165\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcv_results\u001b[39m\u001b[33m'\u001b[39m: search.cv_results_\n\u001b[32m    166\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mHeterogeneousStackingCommittee.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.stacking_classifier = StackingClassifier(\n\u001b[32m    113\u001b[39m     estimators=base_estimators,\n\u001b[32m    114\u001b[39m     final_estimator=meta_estimator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m     n_jobs=\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Evitar conflitos de paralelização\u001b[39;00m\n\u001b[32m    118\u001b[39m )\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Treinar o ensemble\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstacking_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m.stacking_classifier.classes_\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:706\u001b[39m, in \u001b[36mStackingClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m._label_encoder.classes_\n\u001b[32m    704\u001b[39m     y_encoded = \u001b[38;5;28mself\u001b[39m._label_encoder.transform(y)\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:253\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cv, \u001b[33m\"\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m cv.random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    251\u001b[39m         cv.random_state = np.random.RandomState()\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     predictions = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.stack_method_ = [\n\u001b[32m    271\u001b[39m     meth\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.stack_method_, all_estimators)\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    274\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1234\u001b[39m, in \u001b[36mcross_val_predict\u001b[39m\u001b[34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[39m\n\u001b[32m   1231\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m   1233\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m-> \u001b[39m\u001b[32m1234\u001b[39m predictions = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m inv_test_indices = np.empty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m   1248\u001b[39m inv_test_indices[test_indices] = np.arange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1319\u001b[39m, in \u001b[36m_fit_and_predict\u001b[39m\u001b[34m(estimator, X, y, train, test, fit_params, method)\u001b[39m\n\u001b[32m   1317\u001b[39m     estimator.fit(X_train, **fit_params)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[32m   1321\u001b[39m predictions = func(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    186\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     tree._fit(\n\u001b[32m    197\u001b[39m         X,\n\u001b[32m    198\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    202\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 4.1 BUSCA DE HIPERPARAMETROS \n",
    "# ======================================================================\n",
    "\n",
    "print(f\"=== BUSCA DE HIPERPARÂMETROS - {MODEL_NAME} ===\")\n",
    "\n",
    "# Definição do Espaço de Hiperparâmetros para Stacking\n",
    "param_distributions = {\n",
    "    # Parâmetros Decision Tree (busca)\n",
    "    'dt_max_depth': randint(3, 50),\n",
    "    'dt_min_samples_split': randint(2, 40),\n",
    "    'dt_min_samples_leaf': randint(1, 50),\n",
    "    # Parâmetros Decision Tree fixos: criterion='gini', max_features='sqrt'\n",
    "    \n",
    "    # Parâmetros Random Forest (busca)\n",
    "    'rf_n_estimators': randint(5, 300),\n",
    "    'rf_max_depth': randint(3, 50),\n",
    "    # Parâmetros Random Forest fixos: criterion='gini', max_features='sqrt', min_samples_split=16, min_samples_leaf=1\n",
    "    \n",
    "    # Parâmetros XGBoost (busca apenas n_estimators, max_depth, learning_rate)\n",
    "    # Demais parâmetros fixos nos melhores valores encontrados\n",
    "    'xgb_n_estimators': randint(140, 381),\n",
    "    'xgb_max_depth': randint(3, 11),\n",
    "    'xgb_learning_rate': uniform(0.5, 1.5),\n",
    "    \n",
    "    # Parâmetros do Meta-estimador (Logistic Regression)\n",
    "    'meta_C': uniform(0.001, 10),  # Regularização: valores menores = mais regularização\n",
    "    'meta_max_iter': [100, 500, 1000, 2000, 3000],  # Iterações máximas para convergência\n",
    "}\n",
    "\n",
    "# Múltiplas execuções do RandomizedSearchCV\n",
    "print(f\"Iniciando busca de hiperparâmetros para {MODEL_NAME}...\")\n",
    "model_search, model_all_searches, best_params = multiple_randomized_search(\n",
    "    estimator=HeterogeneousStackingCommittee(random_state=42, cv=3),\n",
    "    param_distributions=param_distributions,\n",
    "    X=X_sample,                  \n",
    "    y=y_sample,\n",
    "    cv_strategy=cv_strategy,\n",
    "    n_searches=20,  \n",
    "    n_iter_per_search=2,       \n",
    "    scoring='f1',\n",
    "    n_jobs=1,  # Processamento sequencial\n",
    ")\n",
    "\n",
    "# Seleção da Melhor Configuração\n",
    "print(f\"\\n--- RESULTADOS {MODEL_NAME} ---\")\n",
    "print(\"Melhores hiperparâmetros:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nMelhor F1-Score (CV): {model_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e072ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registro de Desempenho - plotar evolução\n",
    "plot_search_history(model_all_searches, model_search, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c802f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 4.5 ANÁLISE DAS MELHORES CONFIGURAÇÕES ENCONTRADAS\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"=== TOP CONFIGURAÇÕES - {MODEL_NAME} ===\")\n",
    "\n",
    "# Extrair os melhores resultados de cada busca\n",
    "best_configs = []\n",
    "\n",
    "for i, search_result in enumerate(model_all_searches):\n",
    "    config = {\n",
    "        'Busca': i + 1,\n",
    "        'F1_Score': search_result['best_score'],\n",
    "        'RF_N_Est': search_result['best_params']['rf_n_estimators'],\n",
    "        'RF_Depth': search_result['best_params']['rf_max_depth'],\n",
    "        'SVM_C': search_result['best_params']['svm_C'],\n",
    "        'SVM_Gamma': search_result['best_params']['svm_gamma'],\n",
    "        'KNN_K': search_result['best_params']['knn_n_neighbors'],\n",
    "        'MLP_Layers': str(search_result['best_params']['mlp_hidden_layers']),\n",
    "        'Meta_C': search_result['best_params']['meta_C'],\n",
    "        'CV_Folds': search_result['best_params']['cv']\n",
    "    }\n",
    "    best_configs.append(config)\n",
    "\n",
    "# Converter para DataFrame e ordenar por F1-Score\n",
    "results_df = pd.DataFrame(best_configs)\n",
    "results_df = results_df.sort_values('F1_Score', ascending=False).reset_index(drop=True)\n",
    "results_df['Ranking'] = range(1, len(results_df) + 1)\n",
    "\n",
    "# Reordenar colunas\n",
    "results_df = results_df[['Ranking', 'Busca', 'F1_Score', 'RF_N_Est', 'RF_Depth', \n",
    "                        'SVM_C', 'SVM_Gamma', 'KNN_K', 'MLP_Layers', 'Meta_C', 'CV_Folds']]\n",
    "\n",
    "# Mostrar tabela formatada\n",
    "print(\"Configurações encontradas (ordenadas por F1-Score Binário):\")\n",
    "print(\"-\" * 150)\n",
    "print(results_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Estatísticas resumidas\n",
    "print(f\"\\n--- ESTATÍSTICAS DAS CONFIGURAÇÕES ---\")\n",
    "print(f\"Melhor F1-Score: {results_df['F1_Score'].max():.4f}\")\n",
    "print(f\"F1-Score médio: {results_df['F1_Score'].mean():.4f}\")\n",
    "print(f\"Desvio padrão: {results_df['F1_Score'].std():.4f}\")\n",
    "print(f\"F1-Score mínimo: {results_df['F1_Score'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc179c4e",
   "metadata": {},
   "source": [
    "## 5. Salvar Resultados de Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar Resultados da Busca de Hiperparâmetros usando função do módulo\n",
    "search_df = save_search_results(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_search=model_search,\n",
    "    model_all_searches=model_all_searches,\n",
    "    n_searches=5,\n",
    "    n_iter_per_search=3,\n",
    "    scoring='f1',\n",
    "    cv_folds=3,\n",
    "    top_params_columns=['rf_n_estimators', 'svm_C', 'knn_n_neighbors', 'meta_C', 'cv'],\n",
    "    searches_folder='searches'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda1278",
   "metadata": {},
   "source": [
    "## 5.2 Carregar Resultado de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4.2 Carregar Resultados Salvos (Função Auxiliar)\n",
    "# Exemplo de uso da função (não executar se já temos os resultados)\n",
    "loaded_results = load_search_results(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f841878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a história da busca a partir dos resultados carregados\n",
    "plot_search_history_from_loaded(loaded_results, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### 4.3 Recuperar Melhores Parâmetros para Uso Posterior\n",
    "# Exemplo de uso (descomente se precisar carregar parâmetros salvos):\n",
    "if 'loaded_results' in locals():\n",
    "    best_params = get_best_params_from_saved(MODEL_NAME)\n",
    "    if best_params:\n",
    "        print(f\"✅ Parâmetros carregados: {best_params}\")\n",
    "    best_score = loaded_results['summary']['best_overall_score']\n",
    "    print(f\"✅ Melhor F1-Score carregado: {best_score:.4f}\")\n",
    "else:\n",
    "    best_params = model_search.best_params_\n",
    "    best_score = model_search.best_score_\n",
    "    print(f\"✅ Usando parâmetros da busca atual: {best_params}\")\n",
    "    print(f\"✅ Melhor F1-Score da busca atual: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821aef65",
   "metadata": {},
   "source": [
    "## 6. Treinar Modelo Final e Salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento Final com melhores hiperparâmetros\n",
    "best_model = HeterogeneousStackingCommittee(**best_params, random_state=42)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nModelo final {MODEL_NAME} treinado: {best_model}\")\n",
    "\n",
    "# Criar pasta se não existir\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Salvar modelo treinado\n",
    "dump(best_model, f'models/{MODEL_NAME.lower()}_trained.joblib')\n",
    "print(f\"Modelo salvo: models/{MODEL_NAME.lower()}_trained.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b617a75",
   "metadata": {},
   "source": [
    "## 7. Avaliação Final e Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo\n",
    "loaded_model = load(f'models/{MODEL_NAME.lower()}_trained.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17206097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"=== AVALIAÇÃO E SALVAMENTO DOS RESULTADOS - {MODEL_NAME} ===\")\n",
    "\n",
    "# Criar pastas se não existirem\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Avaliação completa do modelo\n",
    "print(\"\\nAvaliando performance do modelo...\")\n",
    "\n",
    "if 'loaded_model' in locals():\n",
    "    model = loaded_model\n",
    "else:\n",
    "    model = best_model\n",
    "\n",
    "X_train_eval = X_train_scaled\n",
    "y_train_eval = y_train\n",
    "X_test_eval = X_test_scaled\n",
    "y_test_eval = y_test\n",
    "\n",
    "# Avaliar modelo\n",
    "train_metrics, test_metrics, y_pred = evaluate_model(\n",
    "    model, X_train_eval, X_test_eval, y_train_eval, y_test_eval, MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86722da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados finais usando função do módulo\n",
    "model_final_results = save_final_results(\n",
    "    model_name=MODEL_NAME,\n",
    "    best_params=best_params,\n",
    "    best_score=best_score,\n",
    "    train_metrics=train_metrics,\n",
    "    test_metrics=test_metrics,\n",
    "    y_pred=y_pred,\n",
    "    y_test=y_test_eval,\n",
    "    X_train_scaled=X_train_eval,\n",
    "    X_test_scaled=X_test_eval,\n",
    "    results_folder='results'\n",
    ")\n",
    "\n",
    "# Mostrar resumo\n",
    "print(f\"\\n--- RESUMO {MODEL_NAME} ---\")\n",
    "print(f\"F1-Score CV: {model_final_results['best_cv_score']:.4f}\")\n",
    "print(f\"F1-Score Teste: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Acurácia Teste: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precisão Teste: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall Teste: {test_metrics['recall']:.4f}\")\n",
    "print(f\"G-Mean Teste: {test_metrics['gmean']:.4f}\")\n",
    "if test_metrics['auc_roc']:\n",
    "    print(f\"AUC-ROC Teste: {test_metrics['auc_roc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
