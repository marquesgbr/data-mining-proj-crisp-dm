{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ba373a",
   "metadata": {},
   "source": [
    "### 1.1 Importar Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffa60bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n",
      "Pandas: 2.3.2\n",
      "NumPy: 2.3.3\n",
      "Scikit-learn: 1.7.2\n",
      "XGBoost: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, roc_curve)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform, randint\n",
    "from joblib import dump, load\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes de plotagem\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"XGBoost: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88319bbd",
   "metadata": {},
   "source": [
    "### 1.2 Definir Comit√™ Heterog√™neo (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe0ec8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comit√™ Heterog√™neo (Stacking) com Decision Tree, Random Forest e XGBoost definido com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# COMIT√ä HETEROG√äNEO (STACKING) - IMPLEMENTA√á√ÉO\n",
    "# ======================================================================\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class HeterogeneousStackingCommittee(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, \n",
    "                 # Par√¢metros Decision Tree (vari√°veis)\n",
    "                 dt_max_depth=None, dt_min_samples_split=2, dt_min_samples_leaf=1,\n",
    "                 # Par√¢metros Decision Tree (fixos)\n",
    "                 dt_criterion='gini', dt_max_features='sqrt',\n",
    "                 # Par√¢metros Random Forest (vari√°veis)\n",
    "                 rf_n_estimators=100, rf_max_depth=None,\n",
    "                 # Par√¢metros Random Forest (fixos)\n",
    "                 rf_criterion='gini', rf_max_features='sqrt',\n",
    "                 rf_min_samples_split=16, rf_min_samples_leaf=1,\n",
    "                 # Par√¢metros XGBoost (vari√°veis)\n",
    "                 xgb_n_estimators=100, xgb_max_depth=6, xgb_learning_rate=0.3,\n",
    "                 # Par√¢metros XGBoost (fixos - melhores valores)\n",
    "                 xgb_subsample=0.6527464393047274, xgb_colsample_bytree=0.6502374440504688,\n",
    "                 xgb_min_child_weight=1, xgb_gamma=0.13697900853304845,\n",
    "                 xgb_reg_alpha=0.778102210605468, xgb_reg_lambda=1.518712387770365,\n",
    "                 # Par√¢metros do meta-estimador\n",
    "                 meta_C=1.0, meta_max_iter=1000,\n",
    "                 # Configura√ß√µes gerais\n",
    "                 cv=5, random_state=None):\n",
    "        \"\"\"\n",
    "        Comit√™ Heterog√™neo usando StackingClassifier com √°rvores de decis√£o\n",
    "        \n",
    "        Estimadores base: Decision Tree, Random Forest, XGBoost\n",
    "        Meta-estimador: Logistic Regression\n",
    "        \"\"\"\n",
    "        # Par√¢metros Decision Tree\n",
    "        self.dt_max_depth = dt_max_depth\n",
    "        self.dt_min_samples_split = dt_min_samples_split\n",
    "        self.dt_min_samples_leaf = dt_min_samples_leaf\n",
    "        self.dt_criterion = dt_criterion\n",
    "        self.dt_max_features = dt_max_features\n",
    "        \n",
    "        self.rf_n_estimators = rf_n_estimators\n",
    "        self.rf_max_depth = rf_max_depth\n",
    "        self.rf_criterion = rf_criterion\n",
    "        self.rf_max_features = rf_max_features\n",
    "        self.rf_min_samples_split = rf_min_samples_split\n",
    "        self.rf_min_samples_leaf = rf_min_samples_leaf\n",
    "        \n",
    "        # Par√¢metros XGBoost\n",
    "        self.xgb_n_estimators = xgb_n_estimators\n",
    "        self.xgb_max_depth = xgb_max_depth\n",
    "        self.xgb_learning_rate = xgb_learning_rate\n",
    "        self.xgb_subsample = xgb_subsample\n",
    "        self.xgb_colsample_bytree = xgb_colsample_bytree\n",
    "        self.xgb_min_child_weight = xgb_min_child_weight\n",
    "        self.xgb_gamma = xgb_gamma\n",
    "        self.xgb_reg_alpha = xgb_reg_alpha\n",
    "        self.xgb_reg_lambda = xgb_reg_lambda\n",
    "        \n",
    "        # Par√¢metros do meta-estimador\n",
    "        self.meta_C = meta_C\n",
    "        self.meta_max_iter = meta_max_iter\n",
    "        \n",
    "        # Configura√ß√µes gerais\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Definir estimadores base com par√¢metros otimiz√°veis\n",
    "        base_estimators = [\n",
    "            ('decision_tree', DecisionTreeClassifier(\n",
    "                max_depth=self.dt_max_depth,\n",
    "                min_samples_split=self.dt_min_samples_split,\n",
    "                min_samples_leaf=self.dt_min_samples_leaf,\n",
    "                criterion=self.dt_criterion,\n",
    "                max_features=self.dt_max_features,\n",
    "                random_state=self.random_state\n",
    "            )),\n",
    "            ('random_forest', RandomForestClassifier(\n",
    "                n_estimators=self.rf_n_estimators,\n",
    "                max_depth=self.rf_max_depth,\n",
    "                criterion=self.rf_criterion,\n",
    "                max_features=self.rf_max_features,\n",
    "                min_samples_split=self.rf_min_samples_split,\n",
    "                min_samples_leaf=self.rf_min_samples_leaf,\n",
    "                random_state=self.random_state\n",
    "            )),\n",
    "            ('xgboost', xgb.XGBClassifier(\n",
    "                n_estimators=self.xgb_n_estimators,\n",
    "                max_depth=self.xgb_max_depth,\n",
    "                learning_rate=self.xgb_learning_rate,\n",
    "                subsample=self.xgb_subsample,\n",
    "                colsample_bytree=self.xgb_colsample_bytree,\n",
    "                min_child_weight=self.xgb_min_child_weight,\n",
    "                gamma=self.xgb_gamma,\n",
    "                reg_alpha=self.xgb_reg_alpha,\n",
    "                reg_lambda=self.xgb_reg_lambda,\n",
    "                objective='binary:logistic',\n",
    "                eval_metric='logloss',\n",
    "                random_state=self.random_state,\n",
    "                verbosity=0\n",
    "            ))\n",
    "        ]\n",
    "        \n",
    "        # Meta-estimador (Logistic Regression)\n",
    "        meta_estimator = LogisticRegression(\n",
    "            C=self.meta_C,\n",
    "            max_iter=self.meta_max_iter,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        # Criar o StackingClassifier\n",
    "        self.stacking_classifier = StackingClassifier(\n",
    "            estimators=base_estimators,\n",
    "            final_estimator=meta_estimator,\n",
    "            cv=self.cv,\n",
    "            stack_method='predict_proba',  # Usar probabilidades\n",
    "            n_jobs=1  # Evitar conflitos de paraleliza√ß√£o\n",
    "        )\n",
    "        \n",
    "        # Treinar o ensemble\n",
    "        self.stacking_classifier.fit(X, y)\n",
    "        self.classes_ = self.stacking_classifier.classes_\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.stacking_classifier.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.stacking_classifier.predict_proba(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))\n",
    "\n",
    "print(\"Comit√™ Heterog√™neo (Stacking) com Decision Tree, Random Forest e XGBoost definido com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88b273",
   "metadata": {},
   "source": [
    "### 1.3 Carregar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1329a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de treino: (853006, 19)\n",
      "Dataset de teste: (215171, 19)\n",
      "\n",
      "Distribui√ß√£o das classes:\n",
      "Treino: {0.0: 831112, 1.0: 21894}\n",
      "Teste: {0.0: 209675, 1.0: 5496}\n",
      "\n",
      "Distribui√ß√£o das classes:\n",
      "Treino: {0.0: 831112, 1.0: 21894}\n",
      "Teste: {0.0: 209675, 1.0: 5496}\n"
     ]
    }
   ],
   "source": [
    "# Carregamento e prepara√ß√£o inicial dos dados\n",
    "print(\"Carregando datasets...\")\n",
    "\n",
    "# Carregar datasets pr√©-processados\n",
    "train_data = pd.read_csv('../dataset_sepsis_prepared.csv')\n",
    "test_data = pd.read_csv('../dataset_sepsis_test_prepared.csv')\n",
    "\n",
    "print(f\"Dataset de treino: {train_data.shape}\")\n",
    "print(f\"Dataset de teste: {test_data.shape}\")\n",
    "\n",
    "# Separar features e target\n",
    "X_train = train_data.drop('SepsisLabel', axis=1)\n",
    "y_train = train_data['SepsisLabel']\n",
    "X_test = test_data.drop('SepsisLabel', axis=1)\n",
    "y_test = test_data['SepsisLabel']\n",
    "\n",
    "# Normaliza√ß√£o dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nDistribui√ß√£o das classes:\")\n",
    "print(\"Treino:\", y_train.value_counts().to_dict())\n",
    "print(\"Teste:\", y_test.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e2b91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "O2Sat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SBP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DBP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Resp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BUN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelets",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unit1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unit2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HospAdmTime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ICULOS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Critical_Risk_Window",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Time_Category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SepsisLabel",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "35d75c7f-cfa3-4f39-8c69-412f6b51502f",
       "rows": [
        [
         "0",
         "8",
         "-1.1097944366836745",
         "-0.4601797972892955",
         "-0.936182396179708",
         "2.87336491135296",
         "3.044200612267326",
         "2.159974443333858",
         "-0.0736012350859598",
         "-0.2771860514420799",
         "-1.39357951670772",
         "0.4507157624350807",
         "1.0",
         "1.0",
         "0.0",
         "-12.06",
         "9.0",
         "0",
         "0",
         "0.0"
        ],
        [
         "1",
         "47",
         "0.5699710093354073",
         "-2.437770480712409",
         "0.1734770445575556",
         "0.3939602121785264",
         "0.6507831363841678",
         "0.4309426287535458",
         "-0.9973237405476244",
         "0.3091707774149635",
         "0.2456159065449318",
         "-0.2751078157149356",
         "1.0",
         "1.0",
         "0.0",
         "-0.05",
         "48.0",
         "0",
         "1",
         "0.0"
        ],
        [
         "2",
         "6",
         "0.1500296478306369",
         "0.978067972472969",
         "0.0161139406337461",
         "-0.9834868429183812",
         "-0.5538501262934915",
         "-0.1986829337362194",
         "-0.0736012350859598",
         "-0.310738624275361",
         "0.1213677719195975",
         "-0.1912664785221958",
         "1.0",
         "1.0",
         "0.0",
         "-0.02",
         "7.0",
         "0",
         "0",
         "0.0"
        ],
        [
         "3",
         "39",
         "-0.2699117136741334",
         "0.2589440875918367",
         "0.2893547834449668",
         "0.8531092305441623",
         "0.4050938398230071",
         "-0.1154602785560446",
         "0.7520149316733524",
         "0.2985914374982416",
         "-0.003964924479364",
         "-3.1529195642522194",
         "0.0",
         "0.0",
         "1.0",
         "-75.85",
         "43.0",
         "0",
         "1",
         "0.0"
        ],
        [
         "4",
         "127",
         "0.5699710093354073",
         "-0.4601797972892955",
         "0.0070124212356604",
         "0.7612794268710351",
         "1.8342546872935597",
         "1.0550498228769023",
         "-0.5209867333216573",
         "0.7021396354059021",
         "-0.1805445000968947",
         "0.0304330288288612",
         "0.0",
         "0.0",
         "1.0",
         "-0.03",
         "128.0",
         "1",
         "2",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>BUN</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>Critical_Risk_Window</th>\n",
       "      <th>Time_Category</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.109794</td>\n",
       "      <td>-0.460180</td>\n",
       "      <td>-0.936182</td>\n",
       "      <td>2.873365</td>\n",
       "      <td>3.044201</td>\n",
       "      <td>2.159974</td>\n",
       "      <td>-0.073601</td>\n",
       "      <td>-0.277186</td>\n",
       "      <td>-1.393580</td>\n",
       "      <td>0.450716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>0.569971</td>\n",
       "      <td>-2.437770</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.393960</td>\n",
       "      <td>0.650783</td>\n",
       "      <td>0.430943</td>\n",
       "      <td>-0.997324</td>\n",
       "      <td>0.309171</td>\n",
       "      <td>0.245616</td>\n",
       "      <td>-0.275108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.150030</td>\n",
       "      <td>0.978068</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>-0.983487</td>\n",
       "      <td>-0.553850</td>\n",
       "      <td>-0.198683</td>\n",
       "      <td>-0.073601</td>\n",
       "      <td>-0.310739</td>\n",
       "      <td>0.121368</td>\n",
       "      <td>-0.191266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.269912</td>\n",
       "      <td>0.258944</td>\n",
       "      <td>0.289355</td>\n",
       "      <td>0.853109</td>\n",
       "      <td>0.405094</td>\n",
       "      <td>-0.115460</td>\n",
       "      <td>0.752015</td>\n",
       "      <td>0.298591</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>-3.152920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-75.85</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>0.569971</td>\n",
       "      <td>-0.460180</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.761279</td>\n",
       "      <td>1.834255</td>\n",
       "      <td>1.055050</td>\n",
       "      <td>-0.520987</td>\n",
       "      <td>0.702140</td>\n",
       "      <td>-0.180545</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hour        HR     O2Sat      Temp       SBP       MAP       DBP      Resp  \\\n",
       "0     8 -1.109794 -0.460180 -0.936182  2.873365  3.044201  2.159974 -0.073601   \n",
       "1    47  0.569971 -2.437770  0.173477  0.393960  0.650783  0.430943 -0.997324   \n",
       "2     6  0.150030  0.978068  0.016114 -0.983487 -0.553850 -0.198683 -0.073601   \n",
       "3    39 -0.269912  0.258944  0.289355  0.853109  0.405094 -0.115460  0.752015   \n",
       "4   127  0.569971 -0.460180  0.007012  0.761279  1.834255  1.055050 -0.520987   \n",
       "\n",
       "        BUN       WBC  Platelets  Gender  Unit1  Unit2  HospAdmTime  ICULOS  \\\n",
       "0 -0.277186 -1.393580   0.450716     1.0    1.0    0.0       -12.06     9.0   \n",
       "1  0.309171  0.245616  -0.275108     1.0    1.0    0.0        -0.05    48.0   \n",
       "2 -0.310739  0.121368  -0.191266     1.0    1.0    0.0        -0.02     7.0   \n",
       "3  0.298591 -0.003965  -3.152920     0.0    0.0    1.0       -75.85    43.0   \n",
       "4  0.702140 -0.180545   0.030433     0.0    0.0    1.0        -0.03   128.0   \n",
       "\n",
       "   Critical_Risk_Window  Time_Category  SepsisLabel  \n",
       "0                     0              0          0.0  \n",
       "1                     0              1          0.0  \n",
       "2                     0              0          0.0  \n",
       "3                     0              1          0.0  \n",
       "4                     1              2          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef93427",
   "metadata": {},
   "source": [
    "## 2. Sampling para Busca de Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a10ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARA√á√ÉO DE AMOSTRA PARA BUSCA DE HIPERPAR√ÇMETROS ===\n",
      "Dataset original de treino: 853,006 amostras\n",
      "Amostra para busca de hiperpar√¢metros: 8,531 amostras\n",
      "Redu√ß√£o: 99.0%\n",
      "\n",
      "Distribui√ß√£o das classes na amostra:\n",
      "Amostra: {0.0: 8312, 1.0: 219}\n",
      "Original: {0.0: 831112, 1.0: 21894}\n",
      "Dataset original de treino: 853,006 amostras\n",
      "Amostra para busca de hiperpar√¢metros: 8,531 amostras\n",
      "Redu√ß√£o: 99.0%\n",
      "\n",
      "Distribui√ß√£o das classes na amostra:\n",
      "Amostra: {0.0: 8312, 1.0: 219}\n",
      "Original: {0.0: 831112, 1.0: 21894}\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# SAMPLING ESTRATIFICADO PARA BUSCA DE HIPERPAR√ÇMETROS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=== PREPARA√á√ÉO DE AMOSTRA PARA BUSCA DE HIPERPAR√ÇMETROS ===\")\n",
    "\n",
    "# Amostra estratificada do dataset de treino (muito pequena devido √† complexidade)\n",
    "_, X_sample, _, y_sample = train_test_split(\n",
    "    X_train_scaled, y_train, \n",
    "    test_size=0.01, \n",
    "    stratify=y_train,\n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "print(f\"Dataset original de treino: {X_train_scaled.shape[0]:,} amostras\")\n",
    "print(f\"Amostra para busca de hiperpar√¢metros: {X_sample.shape[0]:,} amostras\")\n",
    "print(f\"Redu√ß√£o: {(1 - X_sample.shape[0]/X_train_scaled.shape[0])*100:.1f}%\")\n",
    "\n",
    "print(\"\\nDistribui√ß√£o das classes na amostra:\")\n",
    "print(\"Amostra:\", pd.Series(y_sample).value_counts().to_dict())\n",
    "print(\"Original:\", y_train.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045f5bf",
   "metadata": {},
   "source": [
    "## 3.1 Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80a2e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√µes auxiliares definidas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "## Fun√ß√£o auxiliar para c√°lculo do G-Mean\n",
    "def gmean_score(y_true, y_pred):\n",
    "    \"\"\"Calcula o G-Mean (Geometric Mean) para problemas bin√°rios\"\"\"\n",
    "    # Sensitivity (recall da classe positiva - sepsis)\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "    # Specificity (recall da classe negativa - sem sepsis)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "    # G-Mean √© a m√©dia geom√©trica de sensitivity e specificity\n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "# Fun√ß√£o para avaliar modelos\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Avalia um modelo treinado e retorna m√©tricas completas\"\"\"\n",
    "    # Predi√ß√µes\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # M√©tricas de treino\n",
    "    train_metrics = {\n",
    "        'accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'precision': precision_score(y_train, y_train_pred, zero_division=0),\n",
    "        'recall': recall_score(y_train, y_train_pred, zero_division=0),\n",
    "        'f1': f1_score(y_train, y_train_pred, zero_division=0),\n",
    "        'gmean': gmean_score(y_train, y_train_pred)\n",
    "    }\n",
    "    \n",
    "    # M√©tricas de teste\n",
    "    test_metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_test_pred, zero_division=0),\n",
    "        'gmean': gmean_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    # AUC-ROC para problemas bin√°rios\n",
    "    try:\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]  # Probabilidade da classe positiva\n",
    "        test_metrics['auc_roc'] = roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        # AUC-ROC para treino tamb√©m\n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        train_metrics['auc_roc'] = roc_auc_score(y_train, y_train_proba)\n",
    "    except Exception as e:\n",
    "        test_metrics['auc_roc'] = None\n",
    "        train_metrics['auc_roc'] = None\n",
    "    \n",
    "    return train_metrics, test_metrics, y_test_pred\n",
    "\n",
    "# Fun√ß√£o para plotar hist√≥rico de busca\n",
    "def plot_search_history(all_search_results, search_results, model_name, metric='mean_test_score'):\n",
    "    \"\"\"Plota a evolu√ß√£o dos resultados durante a busca de hiperpar√¢metros\"\"\"\n",
    "        \n",
    "    plt.figure(figsize=(15, 6))\n",
    "        \n",
    "    results_df = pd.DataFrame(search_results.cv_results_)\n",
    "    # Extrair melhor score de cada busca e seu desvio-padr√£o\n",
    "    search_scores = []\n",
    "    search_stds = []\n",
    "    search_indices = []\n",
    "    \n",
    "    for i, search_result in enumerate(all_search_results):\n",
    "        search_scores.append(search_result['best_score'])\n",
    "        search_indices.append(i + 1)\n",
    "        \n",
    "        # Encontrar o desvio-padr√£o correspondente ao melhor score desta busca\n",
    "        cv_results = search_result['cv_results']\n",
    "        best_idx = np.argmax(cv_results['mean_test_score'])\n",
    "        search_stds.append(cv_results['std_test_score'][best_idx])\n",
    "    \n",
    "    # GR√ÅFICO 1: Melhor F1-Score por Busca com Desvio-Padr√£o\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(search_indices, search_scores, 'b-o', alpha=0.8, markersize=8)\n",
    "    \n",
    "    # Adicionar sombra do desvio-padr√£o\n",
    "    plt.fill_between(search_indices, \n",
    "                     np.array(search_scores) - np.array(search_stds),\n",
    "                     np.array(search_scores) + np.array(search_stds), \n",
    "                     color='blue', alpha=0.3)\n",
    "    \n",
    "    plt.title(f'{model_name} - Melhor F1-Score por Busca (com Desvio-Padr√£o)')\n",
    "    plt.xlabel('N√∫mero da Busca')\n",
    "    plt.ylabel('Melhor F1-Score')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Destacar a melhor busca\n",
    "    best_idx = search_scores.index(max(search_scores))\n",
    "    plt.plot(search_indices[best_idx], search_scores[best_idx], 'ro', markersize=12, \n",
    "            markeredgecolor='darkred', markeredgewidth=2,\n",
    "            label=f'Melhor: {search_scores[best_idx]:.4f} ¬± {search_stds[best_idx]:.4f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # GR√ÅFICO 2: Itera√ß√µes da melhor busca\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    # Verificar se existe coluna de treino\n",
    "    if 'mean_train_score' in results_df.columns:\n",
    "        plt.plot(results_df['mean_train_score'], 'g-o', alpha=0.7, label='Treino')\n",
    "    \n",
    "    # Plotar valida√ß√£o\n",
    "    plt.plot(results_df[metric], 'b-o', alpha=0.7, label='Valida√ß√£o')\n",
    "    \n",
    "    # DESTACAR A MELHOR ITERA√á√ÉO\n",
    "    best_iteration_idx = results_df[metric].idxmax()\n",
    "    best_iteration_score = results_df[metric].iloc[best_iteration_idx]\n",
    "    \n",
    "    plt.plot(best_iteration_idx, best_iteration_score, 'ro', markersize=15, \n",
    "            markeredgecolor='darkred', markeredgewidth=2,\n",
    "            label=f'Melhor itera√ß√£o: #{best_iteration_idx + 1} ({best_iteration_score:.4f})')\n",
    "    \n",
    "    plt.title(f'{model_name} - Treino vs Valida√ß√£o (Melhor Busca)')\n",
    "    plt.xlabel('Itera√ß√£o')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Fun√ß√£o para executar m√∫ltiplas buscas de hiperpar√¢metros\n",
    "def multiple_randomized_search(estimator, param_distributions, X, y, cv_strategy, \n",
    "                              n_searches=20, n_iter_per_search=80, scoring='f1', \n",
    "                              random_state=42, n_jobs=-1, verbose=0):\n",
    "    \"\"\"\n",
    "    Executa m√∫ltiplas buscas RandomizedSearchCV e retorna a melhor configura√ß√£o global\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_searches : int\n",
    "        N√∫mero de execu√ß√µes do RandomizedSearchCV (default: 20)\n",
    "    n_iter_per_search : int  \n",
    "        N√∫mero de itera√ß√µes por execu√ß√£o (default: 80)\n",
    "    \"\"\"\n",
    "    print(f\"Executando {n_searches} buscas com {n_iter_per_search} itera√ß√µes cada...\")\n",
    "    \n",
    "    best_overall_score = -np.inf\n",
    "    best_overall_params = None\n",
    "    best_search_result = None\n",
    "    all_results = []\n",
    "    \n",
    "    for search_idx in range(n_searches):\n",
    "        print(f\"\\nBusca {search_idx + 1}/{n_searches}...\")\n",
    "        \n",
    "        # RandomizedSearchCV para esta execu√ß√£o\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=estimator,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter=n_iter_per_search,\n",
    "            scoring=scoring,\n",
    "            cv=cv_strategy,\n",
    "            random_state=None,\n",
    "            n_jobs=n_jobs,\n",
    "            return_train_score=True,\n",
    "            verbose=0  # Menos verbose para m√∫ltiplas execu√ß√µes\n",
    "        )\n",
    "        \n",
    "        search.fit(X, y)\n",
    "        \n",
    "        # Armazenar resultados desta busca\n",
    "        search_results = {\n",
    "            'search_idx': search_idx,\n",
    "            'best_score': search.best_score_,\n",
    "            'best_params': search.best_params_,\n",
    "            'cv_results': search.cv_results_\n",
    "        }\n",
    "        all_results.append(search_results)\n",
    "        \n",
    "        # Verificar se esta √© a melhor busca at√© agora\n",
    "        if search.best_score_ > best_overall_score:\n",
    "            best_overall_score = search.best_score_\n",
    "            best_overall_params = search.best_params_\n",
    "            best_search_result = search\n",
    "            \n",
    "        print(f\"Melhor score desta busca: {search.best_score_:.4f}\")\n",
    "        print(f\"Melhor configura√ß√£o desta busca: {search.best_params_}\")\n",
    "        print(f\"Melhor score geral at√© agora: {best_overall_score:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Busca completa! Melhor score geral: {best_overall_score:.4f}\")\n",
    "    print(f\"Total de configura√ß√µes testadas: {n_searches * n_iter_per_search:,}\")\n",
    "    \n",
    "    return best_search_result, all_results, best_overall_params\n",
    "\n",
    "\n",
    "# Fun√ß√£o para plotar hist√≥rico de busca a partir de loaded_results\n",
    "def plot_search_history_from_loaded(loaded_results, model_name, metric='mean_test_score'):\n",
    "    \"\"\"Plota a evolu√ß√£o dos resultados a partir de loaded_results\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Extrair dados do loaded_results\n",
    "    detailed_df = loaded_results['detailed_df']\n",
    "    \n",
    "    # Agrupar por search_idx para obter o melhor de cada busca e seu desvio-padr√£o\n",
    "    best_per_search = detailed_df.loc[detailed_df.groupby('search_idx')['mean_test_score'].idxmax()]\n",
    "    best_per_search = best_per_search[['search_idx', 'mean_test_score', 'std_test_score']].reset_index(drop=True)\n",
    "    best_per_search['search_number'] = best_per_search['search_idx'] + 1  # 1-indexado\n",
    "    \n",
    "    # GR√ÅFICO 1: Melhor F1-Score por Busca com Desvio-Padr√£o\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(best_per_search['search_number'], best_per_search['mean_test_score'], \n",
    "             'b-o', alpha=0.8, markersize=8)\n",
    "    \n",
    "    # Adicionar sombra do desvio-padr√£o\n",
    "    plt.fill_between(best_per_search['search_number'], \n",
    "                     best_per_search['mean_test_score'] - best_per_search['std_test_score'],\n",
    "                     best_per_search['mean_test_score'] + best_per_search['std_test_score'], \n",
    "                     color='blue', alpha=0.3)\n",
    "    \n",
    "    plt.title(f'{model_name} - Melhor F1-Score por Busca (com Desvio-Padr√£o)')\n",
    "    plt.xlabel('N√∫mero da Busca')\n",
    "    plt.ylabel('Melhor F1-Score')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Destacar a melhor busca\n",
    "    best_search_idx = best_per_search['mean_test_score'].idxmax()\n",
    "    best_search_score = best_per_search['mean_test_score'].iloc[best_search_idx]\n",
    "    best_search_std = best_per_search['std_test_score'].iloc[best_search_idx]\n",
    "    best_search_number = best_per_search['search_number'].iloc[best_search_idx]\n",
    "    \n",
    "    plt.plot(best_search_number, best_search_score, 'ro', markersize=12, \n",
    "             markeredgecolor='darkred', markeredgewidth=2,\n",
    "             label=f'Melhor: {best_search_score:.4f} ¬± {best_search_std:.4f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # GR√ÅFICO 2: Itera√ß√µes da melhor busca\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    # Encontrar qual search_idx teve o melhor score geral\n",
    "    best_overall_idx = detailed_df['mean_test_score'].idxmax()\n",
    "    best_overall_search_idx = detailed_df.loc[best_overall_idx, 'search_idx']\n",
    "    \n",
    "    # Filtrar dados apenas da melhor busca\n",
    "    best_search_data = detailed_df[detailed_df['search_idx'] == best_overall_search_idx].copy()\n",
    "    best_search_data = best_search_data.sort_values('iteration').reset_index(drop=True)\n",
    "    \n",
    "    # Criar eixo X 1-indexado para itera√ß√µes\n",
    "    iterations_1indexed = range(1, len(best_search_data) + 1)\n",
    "    \n",
    "    # Verificar se existe coluna de treino\n",
    "    if 'mean_train_score' in best_search_data.columns and best_search_data['mean_train_score'].notna().any():\n",
    "        plt.plot(iterations_1indexed, best_search_data['mean_train_score'], \n",
    "                'g-o', alpha=0.7, label='Treino')\n",
    "    \n",
    "    # Plotar valida√ß√£o sem sombra\n",
    "    plt.plot(iterations_1indexed, best_search_data[metric], 'b-o', alpha=0.7, label='Valida√ß√£o')\n",
    "    \n",
    "    # DESTACAR A MELHOR ITERA√á√ÉO\n",
    "    best_iteration_idx = best_search_data[metric].idxmax()\n",
    "    best_iteration_score = best_search_data[metric].iloc[best_iteration_idx]\n",
    "    best_iteration_number = best_iteration_idx + 1  # 1-indexado\n",
    "    \n",
    "    plt.plot(best_iteration_number, best_iteration_score, 'ro', markersize=15, \n",
    "             markeredgecolor='darkred', markeredgewidth=2,\n",
    "             label=f'Melhor itera√ß√£o: #{best_iteration_number} ({best_iteration_score:.4f})')\n",
    "    \n",
    "    plt.title(f'{model_name} - Treino vs Valida√ß√£o (Melhor Busca #{best_overall_search_idx + 1})')\n",
    "    plt.xlabel('Itera√ß√£o')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Fun√ß√µes auxiliares definidas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f455437",
   "metadata": {},
   "source": [
    "### 3.1 Definir Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5214135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o da valida√ß√£o cruzada estratificada\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda55987",
   "metadata": {},
   "source": [
    "## 4. Stacking - Busca de Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0468b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nome do modelo para uso em salvamento e exibi√ß√£o\n",
    "MODEL_NAME = \"Stacking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "296f34c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BUSCA DE HIPERPAR√ÇMETROS - Stacking ===\n",
      "Iniciando busca de hiperpar√¢metros para Stacking...\n",
      "Executando 20 buscas com 2 itera√ß√µes cada...\n",
      "\n",
      "Busca 1/20...\n",
      "Melhor score desta busca: 0.0265\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 4, 'dt_min_samples_leaf': 18, 'dt_min_samples_split': 34, 'meta_C': np.float64(3.176949833122895), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 233, 'xgb_learning_rate': np.float64(1.7410978906984163), 'xgb_max_depth': 8, 'xgb_n_estimators': 269}\n",
      "Melhor score geral at√© agora: 0.0265\n",
      "\n",
      "Busca 2/20...\n",
      "Melhor score desta busca: 0.0265\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 4, 'dt_min_samples_leaf': 18, 'dt_min_samples_split': 34, 'meta_C': np.float64(3.176949833122895), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 233, 'xgb_learning_rate': np.float64(1.7410978906984163), 'xgb_max_depth': 8, 'xgb_n_estimators': 269}\n",
      "Melhor score geral at√© agora: 0.0265\n",
      "\n",
      "Busca 2/20...\n",
      "Melhor score desta busca: 0.0263\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 17, 'dt_min_samples_leaf': 17, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.280028077503617), 'meta_max_iter': 3000, 'rf_max_depth': 35, 'rf_n_estimators': 222, 'xgb_learning_rate': np.float64(0.6598564029633305), 'xgb_max_depth': 5, 'xgb_n_estimators': 289}\n",
      "Melhor score geral at√© agora: 0.0265\n",
      "\n",
      "Busca 3/20...\n",
      "Melhor score desta busca: 0.0263\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 17, 'dt_min_samples_leaf': 17, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.280028077503617), 'meta_max_iter': 3000, 'rf_max_depth': 35, 'rf_n_estimators': 222, 'xgb_learning_rate': np.float64(0.6598564029633305), 'xgb_max_depth': 5, 'xgb_n_estimators': 289}\n",
      "Melhor score geral at√© agora: 0.0265\n",
      "\n",
      "Busca 3/20...\n",
      "Melhor score desta busca: 0.0341\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 7, 'dt_min_samples_leaf': 7, 'dt_min_samples_split': 28, 'meta_C': np.float64(9.563356430296048), 'meta_max_iter': 100, 'rf_max_depth': 17, 'rf_n_estimators': 242, 'xgb_learning_rate': np.float64(0.9392907175242635), 'xgb_max_depth': 8, 'xgb_n_estimators': 312}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 4/20...\n",
      "Melhor score desta busca: 0.0341\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 7, 'dt_min_samples_leaf': 7, 'dt_min_samples_split': 28, 'meta_C': np.float64(9.563356430296048), 'meta_max_iter': 100, 'rf_max_depth': 17, 'rf_n_estimators': 242, 'xgb_learning_rate': np.float64(0.9392907175242635), 'xgb_max_depth': 8, 'xgb_n_estimators': 312}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 4/20...\n",
      "Melhor score desta busca: 0.0170\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 46, 'dt_min_samples_leaf': 38, 'dt_min_samples_split': 5, 'meta_C': np.float64(5.658385782961916), 'meta_max_iter': 3000, 'rf_max_depth': 18, 'rf_n_estimators': 108, 'xgb_learning_rate': np.float64(0.8386241593408649), 'xgb_max_depth': 3, 'xgb_n_estimators': 368}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 5/20...\n",
      "Melhor score desta busca: 0.0170\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 46, 'dt_min_samples_leaf': 38, 'dt_min_samples_split': 5, 'meta_C': np.float64(5.658385782961916), 'meta_max_iter': 3000, 'rf_max_depth': 18, 'rf_n_estimators': 108, 'xgb_learning_rate': np.float64(0.8386241593408649), 'xgb_max_depth': 3, 'xgb_n_estimators': 368}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 5/20...\n",
      "Melhor score desta busca: 0.0178\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 3, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.5234404719761026), 'meta_max_iter': 2000, 'rf_max_depth': 11, 'rf_n_estimators': 173, 'xgb_learning_rate': np.float64(0.9283889850897893), 'xgb_max_depth': 10, 'xgb_n_estimators': 306}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 6/20...\n",
      "Melhor score desta busca: 0.0178\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 3, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 30, 'meta_C': np.float64(5.5234404719761026), 'meta_max_iter': 2000, 'rf_max_depth': 11, 'rf_n_estimators': 173, 'xgb_learning_rate': np.float64(0.9283889850897893), 'xgb_max_depth': 10, 'xgb_n_estimators': 306}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 6/20...\n",
      "Melhor score desta busca: 0.0085\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 38, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 8, 'meta_C': np.float64(1.6653645914541049), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 172, 'xgb_learning_rate': np.float64(0.7916547652645569), 'xgb_max_depth': 6, 'xgb_n_estimators': 338}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 7/20...\n",
      "Melhor score desta busca: 0.0085\n",
      "Melhor configura√ß√£o desta busca: {'dt_max_depth': 38, 'dt_min_samples_leaf': 47, 'dt_min_samples_split': 8, 'meta_C': np.float64(1.6653645914541049), 'meta_max_iter': 1000, 'rf_max_depth': 4, 'rf_n_estimators': 172, 'xgb_learning_rate': np.float64(0.7916547652645569), 'xgb_max_depth': 6, 'xgb_n_estimators': 338}\n",
      "Melhor score geral at√© agora: 0.0341\n",
      "\n",
      "Busca 7/20...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# M√∫ltiplas execu√ß√µes do RandomizedSearchCV\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIniciando busca de hiperpar√¢metros para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m model_search, model_all_searches, best_params = \u001b[43mmultiple_randomized_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHeterogeneousStackingCommittee\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_searches\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter_per_search\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Processamento sequencial\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Sele√ß√£o da Melhor Configura√ß√£o\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- RESULTADOS \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 158\u001b[39m, in \u001b[36mmultiple_randomized_search\u001b[39m\u001b[34m(estimator, param_distributions, X, y, cv_strategy, n_searches, n_iter_per_search, scoring, random_state, n_jobs, verbose)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# RandomizedSearchCV para esta execu√ß√£o\u001b[39;00m\n\u001b[32m    146\u001b[39m search = RandomizedSearchCV(\n\u001b[32m    147\u001b[39m     estimator=estimator,\n\u001b[32m    148\u001b[39m     param_distributions=param_distributions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m     verbose=\u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Menos verbose para m√∫ltiplas execu√ß√µes\u001b[39;00m\n\u001b[32m    156\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Armazenar resultados desta busca\u001b[39;00m\n\u001b[32m    161\u001b[39m search_results = {\n\u001b[32m    162\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msearch_idx\u001b[39m\u001b[33m'\u001b[39m: search_idx,\n\u001b[32m    163\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_score\u001b[39m\u001b[33m'\u001b[39m: search.best_score_,\n\u001b[32m    164\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_params\u001b[39m\u001b[33m'\u001b[39m: search.best_params_,\n\u001b[32m    165\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcv_results\u001b[39m\u001b[33m'\u001b[39m: search.cv_results_\n\u001b[32m    166\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mHeterogeneousStackingCommittee.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.stacking_classifier = StackingClassifier(\n\u001b[32m    113\u001b[39m     estimators=base_estimators,\n\u001b[32m    114\u001b[39m     final_estimator=meta_estimator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m     n_jobs=\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Evitar conflitos de paraleliza√ß√£o\u001b[39;00m\n\u001b[32m    118\u001b[39m )\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Treinar o ensemble\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstacking_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m.stacking_classifier.classes_\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:706\u001b[39m, in \u001b[36mStackingClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m._label_encoder.classes_\n\u001b[32m    704\u001b[39m     y_encoded = \u001b[38;5;28mself\u001b[39m._label_encoder.transform(y)\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:253\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cv, \u001b[33m\"\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m cv.random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    251\u001b[39m         cv.random_state = np.random.RandomState()\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     predictions = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.stack_method_ = [\n\u001b[32m    271\u001b[39m     meth\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.stack_method_, all_estimators)\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    274\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1234\u001b[39m, in \u001b[36mcross_val_predict\u001b[39m\u001b[34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[39m\n\u001b[32m   1231\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m   1233\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m-> \u001b[39m\u001b[32m1234\u001b[39m predictions = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m inv_test_indices = np.empty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m   1248\u001b[39m inv_test_indices[test_indices] = np.arange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1319\u001b[39m, in \u001b[36m_fit_and_predict\u001b[39m\u001b[34m(estimator, X, y, train, test, fit_params, method)\u001b[39m\n\u001b[32m   1317\u001b[39m     estimator.fit(X_train, **fit_params)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[32m   1321\u001b[39m predictions = func(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    186\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     tree._fit(\n\u001b[32m    197\u001b[39m         X,\n\u001b[32m    198\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    202\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\25.2\\mda\\data-minning-proj-crisp-dm\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 4.1 BUSCA DE HIPERPARAMETROS \n",
    "# ======================================================================\n",
    "\n",
    "print(f\"=== BUSCA DE HIPERPAR√ÇMETROS - {MODEL_NAME} ===\")\n",
    "\n",
    "# Defini√ß√£o do Espa√ßo de Hiperpar√¢metros para Stacking\n",
    "param_distributions = {\n",
    "    # Par√¢metros Decision Tree (busca)\n",
    "    'dt_max_depth': randint(3, 50),\n",
    "    'dt_min_samples_split': randint(2, 40),\n",
    "    'dt_min_samples_leaf': randint(1, 50),\n",
    "    # Par√¢metros Decision Tree fixos: criterion='gini', max_features='sqrt'\n",
    "    \n",
    "    # Par√¢metros Random Forest (busca)\n",
    "    'rf_n_estimators': randint(5, 300),\n",
    "    'rf_max_depth': randint(3, 50),\n",
    "    # Par√¢metros Random Forest fixos: criterion='gini', max_features='sqrt', min_samples_split=16, min_samples_leaf=1\n",
    "    \n",
    "    # Par√¢metros XGBoost (busca apenas n_estimators, max_depth, learning_rate)\n",
    "    # Demais par√¢metros fixos nos melhores valores encontrados\n",
    "    'xgb_n_estimators': randint(140, 381),\n",
    "    'xgb_max_depth': randint(3, 11),\n",
    "    'xgb_learning_rate': uniform(0.5, 1.5),\n",
    "    \n",
    "    # Par√¢metros do Meta-estimador (Logistic Regression)\n",
    "    'meta_C': uniform(0.001, 10),  # Regulariza√ß√£o: valores menores = mais regulariza√ß√£o\n",
    "    'meta_max_iter': [100, 500, 1000, 2000, 3000],  # Itera√ß√µes m√°ximas para converg√™ncia\n",
    "}\n",
    "\n",
    "# M√∫ltiplas execu√ß√µes do RandomizedSearchCV\n",
    "print(f\"Iniciando busca de hiperpar√¢metros para {MODEL_NAME}...\")\n",
    "model_search, model_all_searches, best_params = multiple_randomized_search(\n",
    "    estimator=HeterogeneousStackingCommittee(random_state=42, cv=3),\n",
    "    param_distributions=param_distributions,\n",
    "    X=X_sample,                  \n",
    "    y=y_sample,\n",
    "    cv_strategy=cv_strategy,\n",
    "    n_searches=20,  \n",
    "    n_iter_per_search=2,       \n",
    "    scoring='f1',\n",
    "    n_jobs=1,  # Processamento sequencial\n",
    ")\n",
    "\n",
    "# Sele√ß√£o da Melhor Configura√ß√£o\n",
    "print(f\"\\n--- RESULTADOS {MODEL_NAME} ---\")\n",
    "print(\"Melhores hiperpar√¢metros:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nMelhor F1-Score (CV): {model_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e072ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registro de Desempenho - plotar evolu√ß√£o\n",
    "plot_search_history(model_all_searches, model_search, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c802f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 4.5 AN√ÅLISE DAS MELHORES CONFIGURA√á√ïES ENCONTRADAS\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"=== TOP CONFIGURA√á√ïES - {MODEL_NAME} ===\")\n",
    "\n",
    "# Extrair os melhores resultados de cada busca\n",
    "best_configs = []\n",
    "\n",
    "for i, search_result in enumerate(model_all_searches):\n",
    "    config = {\n",
    "        'Busca': i + 1,\n",
    "        'F1_Score': search_result['best_score'],\n",
    "        'RF_N_Est': search_result['best_params']['rf_n_estimators'],\n",
    "        'RF_Depth': search_result['best_params']['rf_max_depth'],\n",
    "        'SVM_C': search_result['best_params']['svm_C'],\n",
    "        'SVM_Gamma': search_result['best_params']['svm_gamma'],\n",
    "        'KNN_K': search_result['best_params']['knn_n_neighbors'],\n",
    "        'MLP_Layers': str(search_result['best_params']['mlp_hidden_layers']),\n",
    "        'Meta_C': search_result['best_params']['meta_C'],\n",
    "        'CV_Folds': search_result['best_params']['cv']\n",
    "    }\n",
    "    best_configs.append(config)\n",
    "\n",
    "# Converter para DataFrame e ordenar por F1-Score\n",
    "results_df = pd.DataFrame(best_configs)\n",
    "results_df = results_df.sort_values('F1_Score', ascending=False).reset_index(drop=True)\n",
    "results_df['Ranking'] = range(1, len(results_df) + 1)\n",
    "\n",
    "# Reordenar colunas\n",
    "results_df = results_df[['Ranking', 'Busca', 'F1_Score', 'RF_N_Est', 'RF_Depth', \n",
    "                        'SVM_C', 'SVM_Gamma', 'KNN_K', 'MLP_Layers', 'Meta_C', 'CV_Folds']]\n",
    "\n",
    "# Mostrar tabela formatada\n",
    "print(\"Configura√ß√µes encontradas (ordenadas por F1-Score Bin√°rio):\")\n",
    "print(\"-\" * 150)\n",
    "print(results_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Estat√≠sticas resumidas\n",
    "print(f\"\\n--- ESTAT√çSTICAS DAS CONFIGURA√á√ïES ---\")\n",
    "print(f\"Melhor F1-Score: {results_df['F1_Score'].max():.4f}\")\n",
    "print(f\"F1-Score m√©dio: {results_df['F1_Score'].mean():.4f}\")\n",
    "print(f\"Desvio padr√£o: {results_df['F1_Score'].std():.4f}\")\n",
    "print(f\"F1-Score m√≠nimo: {results_df['F1_Score'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc179c4e",
   "metadata": {},
   "source": [
    "## 5. Salvar Resultados de Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar Resultados da Busca de Hiperpar√¢metros\n",
    "\n",
    "print(f\"=== SALVANDO RESULTADOS DA BUSCA - {MODEL_NAME} ===\")\n",
    "\n",
    "# Criar pasta se n√£o existir\n",
    "os.makedirs('searches', exist_ok=True)\n",
    "\n",
    "# 1. Salvar resultados detalhados de todas as buscas\n",
    "search_detailed_results = []\n",
    "\n",
    "for i, search_result in enumerate(model_all_searches):\n",
    "    # Extrair informa√ß√µes de cada busca individual\n",
    "    cv_results = search_result['cv_results']\n",
    "    \n",
    "    for j in range(len(cv_results['mean_test_score'])):\n",
    "        search_detailed_results.append({\n",
    "            'search_idx': search_result['search_idx'],\n",
    "            'iteration': j,\n",
    "            'mean_test_score': cv_results['mean_test_score'][j],\n",
    "            'std_test_score': cv_results['std_test_score'][j],\n",
    "            'mean_train_score': cv_results['mean_train_score'][j] if 'mean_train_score' in cv_results else None,\n",
    "            'std_train_score': cv_results['std_train_score'][j] if 'std_train_score' in cv_results else None,\n",
    "            'params': str(cv_results['params'][j]),\n",
    "            **{k: (str(v) if isinstance(v, tuple) else v) for k, v in cv_results['params'][j].items()}\n",
    "        })\n",
    "\n",
    "# Converter para DataFrame e salvar\n",
    "search_df = pd.DataFrame(search_detailed_results)\n",
    "search_df.to_csv(f'searches/{MODEL_NAME.lower()}_all_searches.csv', index=False)\n",
    "\n",
    "print(f\"  Todos os Resultados salvos: searches/{MODEL_NAME.lower()}_all_searches.csv\")\n",
    "print(f\"  Total de configura√ß√µes testadas: {len(search_df):,}\")\n",
    "\n",
    "# 2. Salvar resumo da melhor busca\n",
    "best_search_summary = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'best_overall_score': model_search.best_score_,\n",
    "    'best_overall_params': {k: (str(v) if isinstance(v, tuple) else v) for k, v in model_search.best_params_.items()},\n",
    "    'search_config': {\n",
    "        'n_searches': 5,\n",
    "        'n_iter_per_search': 3,\n",
    "        'scoring': 'f1',\n",
    "        'cv_folds': 3,\n",
    "        'total_configurations': len(search_df)\n",
    "    },\n",
    "    'top_configs': search_df.nlargest(len(search_df), 'mean_test_score')[\n",
    "        ['mean_test_score', 'std_test_score', 'rf_n_estimators', 'svm_C', 'knn_n_neighbors', \n",
    "         'meta_C', 'cv']\n",
    "    ].to_dict('records')\n",
    "}\n",
    "\n",
    "# Salvar resumo em JSON\n",
    "with open(f'searches/{MODEL_NAME.lower()}_search_summary.json', 'w') as f:\n",
    "    json.dump(best_search_summary, f, indent=2)\n",
    "\n",
    "print(f\"  Resumo salvo: searches/{MODEL_NAME.lower()}_search_summary.json\")\n",
    "\n",
    "# Mostrar estat√≠sticas da busca\n",
    "print(f\"\\n--- ESTAT√çSTICAS DA BUSCA {MODEL_NAME} ---\")\n",
    "print(f\"Melhor F1-Score: {model_search.best_score_:.4f}\")\n",
    "print(f\"Desvio padr√£o do melhor: {search_df.loc[search_df['mean_test_score'].idxmax(), 'std_test_score']:.4f}\")\n",
    "print(f\"F1-Score m√©dio geral: {search_df['mean_test_score'].mean():.4f}\")\n",
    "print(f\"F1-Score m√≠nimo: {search_df['mean_test_score'].min():.4f}\")\n",
    "print(f\"F1-Score m√°ximo: {search_df['mean_test_score'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda1278",
   "metadata": {},
   "source": [
    "## 5.2 Carregar Resultado de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46013e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_search_results(model_name, searches_folder='searches'):\n",
    "    \"\"\"\n",
    "    Carrega resultados de busca salvos anteriormente\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Dicion√°rio com todos os resultados carregados\n",
    "    \"\"\"\n",
    "    print(f\"=== CARREGANDO RESULTADOS DE BUSCA - {model_name.upper()} ===\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Carregar DataFrame detalhado\n",
    "    csv_path = os.path.join(searches_folder, f'{model_name.lower()}_all_searches.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        results['detailed_df'] = pd.read_csv(csv_path)\n",
    "        print(f\"‚úÖ Resultados detalhados carregados: {len(results['detailed_df']):,} configura√ß√µes\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado: {csv_path}\")\n",
    "    \n",
    "    # 2. Carregar resumo JSON\n",
    "    json_path = os.path.join(searches_folder, f'{model_name.lower()}_search_summary.json')\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            results['summary'] = json.load(f)\n",
    "        print(f\"‚úÖ Resumo carregado: F1-Score = {results['summary']['best_overall_score']:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado: {json_path}\")\n",
    "    \n",
    "    # 3. Carregar backup pickle\n",
    "    pkl_path = os.path.join(searches_folder, f'{model_name.lower()}_full_search.pkl')\n",
    "    if os.path.exists(pkl_path):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            results['full_backup'] = pickle.load(f)\n",
    "        print(f\"‚úÖ Backup completo carregado\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado: {pkl_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_best_params_from_saved(model_name, searches_folder='searches'):\n",
    "    \"\"\"\n",
    "    Recupera os melhores par√¢metros de arquivos salvos\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Melhores par√¢metros encontrados\n",
    "    \"\"\"\n",
    "    # Tentar carregar do JSON primeiro\n",
    "    json_path = os.path.join(searches_folder, f'{model_name.lower()}_search_summary.json')\n",
    "    \n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        return summary['best_overall_params']\n",
    "    \n",
    "    # Fallback para pickle\n",
    "    pkl_path = os.path.join(searches_folder, f'{model_name.lower()}_full_search.pkl')\n",
    "    if os.path.exists(pkl_path):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            backup = pickle.load(f)\n",
    "        return backup['best_params']\n",
    "    \n",
    "    print(f\"‚ùå N√£o foi poss√≠vel carregar par√¢metros para {model_name}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4.2 Carregar Resultados Salvos (Fun√ß√£o Auxiliar)\n",
    "# Exemplo de uso da fun√ß√£o (n√£o executar se j√° temos os resultados)\n",
    "loaded_results = load_search_results(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f841878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a hist√≥ria da busca a partir dos resultados carregados\n",
    "plot_search_history_from_loaded(loaded_results, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### 4.3 Recuperar Melhores Par√¢metros para Uso Posterior\n",
    "# Exemplo de uso (descomente se precisar carregar par√¢metros salvos):\n",
    "if 'loaded_results' in locals():\n",
    "    best_params = get_best_params_from_saved(MODEL_NAME)\n",
    "    if best_params:\n",
    "        print(f\"‚úÖ Par√¢metros carregados: {best_params}\")\n",
    "    best_score = loaded_results['summary']['best_overall_score']\n",
    "    print(f\"‚úÖ Melhor F1-Score carregado: {best_score:.4f}\")\n",
    "else:\n",
    "    best_params = model_search.best_params_\n",
    "    best_score = model_search.best_score_\n",
    "    print(f\"‚úÖ Usando par√¢metros da busca atual: {best_params}\")\n",
    "    print(f\"‚úÖ Melhor F1-Score da busca atual: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821aef65",
   "metadata": {},
   "source": [
    "## 6. Treinar Modelo Final e Salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento Final com melhores hiperpar√¢metros\n",
    "best_model = HeterogeneousStackingCommittee(**best_params, random_state=42)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nModelo final {MODEL_NAME} treinado: {best_model}\")\n",
    "\n",
    "# Criar pasta se n√£o existir\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Salvar modelo treinado\n",
    "dump(best_model, f'models/{MODEL_NAME.lower()}_trained.joblib')\n",
    "print(f\"Modelo salvo: models/{MODEL_NAME.lower()}_trained.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b617a75",
   "metadata": {},
   "source": [
    "## 7. Avalia√ß√£o Final e Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo\n",
    "loaded_model = load(f'models/{MODEL_NAME.lower()}_trained.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17206097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"=== AVALIA√á√ÉO E SALVAMENTO DOS RESULTADOS - {MODEL_NAME} ===\")\n",
    "\n",
    "# Criar pastas se n√£o existirem\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Avalia√ß√£o completa do modelo\n",
    "print(\"\\nAvaliando performance do modelo...\")\n",
    "\n",
    "if 'loaded_model' in locals():\n",
    "    model = loaded_model\n",
    "else:\n",
    "    model = best_model\n",
    "\n",
    "X_train_eval = X_train_scaled\n",
    "y_train_eval = y_train\n",
    "X_test_eval = X_test_scaled\n",
    "y_test_eval = y_test\n",
    "\n",
    "# Avaliar modelo\n",
    "train_metrics, test_metrics, y_pred = evaluate_model(\n",
    "    model, X_train_eval, X_test_eval, y_train_eval, y_test_eval, MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86722da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar todos os resultados\n",
    "model_final_results = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'best_params': best_params,\n",
    "    'best_cv_score': best_score,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'predictions': y_pred.tolist(),\n",
    "    'test_labels': y_test_eval.tolist(),\n",
    "    'evaluation_info': {\n",
    "        'train_samples_used': len(X_train_eval),\n",
    "        'test_samples_used': len(X_test_eval),\n",
    "        'total_train_samples': len(X_train_scaled),\n",
    "        'total_test_samples': len(X_test_scaled)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar resultados em JSON\n",
    "with open(f'results/{MODEL_NAME.lower()}_results.json', 'w') as f:\n",
    "    json.dump(model_final_results, f, indent=2)\n",
    "\n",
    "print(f\"Resultados {MODEL_NAME} salvos em: results/{MODEL_NAME.lower()}_results.json\")\n",
    "\n",
    "# Mostrar resumo\n",
    "print(f\"\\n--- RESUMO {MODEL_NAME} ---\")\n",
    "print(f\"F1-Score CV: {model_final_results['best_cv_score']:.4f}\")\n",
    "print(f\"F1-Score Teste: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Acur√°cia Teste: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precis√£o Teste: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall Teste: {test_metrics['recall']:.4f}\")\n",
    "print(f\"G-Mean Teste: {test_metrics['gmean']:.4f}\")\n",
    "if test_metrics['auc_roc']:\n",
    "    print(f\"AUC-ROC Teste: {test_metrics['auc_roc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
