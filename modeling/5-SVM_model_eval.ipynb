{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6119d49",
   "metadata": {},
   "source": [
    "## 1. SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09f8c9",
   "metadata": {},
   "source": [
    "### 1.1 Importar Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "from joblib import load, dump\n",
    "from scipy.stats import randint, loguniform, uniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, roc_curve)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar funções dos módulos customizados\n",
    "from ml_utils import gmean_score, evaluate_model, load_and_prepare_datasets\n",
    "from search_utils import (multiple_randomized_search, plot_search_history, save_search_results, \n",
    "                          save_final_results, DEFAULT_CV_STRATEGY, plot_search_history_from_loaded,\n",
    "                          load_search_results, get_best_params_from_saved)\n",
    "\n",
    "# Configurações de plotagem\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34408213",
   "metadata": {},
   "source": [
    "### 1.2 Configuração do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a50fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do modelo e hiperparâmetros\n",
    "MODEL_NAME = \"SVM\"\n",
    "MODEL_CLASS = SVC\n",
    "RANDOM_STATE_MODEL = 10\n",
    "RANDOM_STATE_SAMPLE = 10\n",
    "\n",
    "# Configuração da busca de hiperparâmetros\n",
    "N_SEARCHES = 20\n",
    "N_ITER_PER_SEARCH = 5\n",
    "SAMPLE_SIZE = 0.05  # % of training data \n",
    "\n",
    "# Pastas para salvamento\n",
    "SEARCHES_FOLDER = 'searches'\n",
    "RESULTS_FOLDER = 'results'\n",
    "MODELS_FOLDER = 'models'\n",
    "\n",
    "print(f\"Modelo configurado: {MODEL_NAME}\")\n",
    "print(f\"Classe do modelo: {MODEL_CLASS}\")\n",
    "print(f\"Buscas: {N_SEARCHES} x {N_ITER_PER_SEARCH} iterações\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5ac77",
   "metadata": {},
   "source": [
    "## 2. CARREGAMENTO E PREPARAÇÃO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e preparação inicial dos dados\n",
    "print(\"=== CARREGAMENTO DOS DATASETS ===\")\n",
    "\n",
    "# Carregar e preparar datasets usando função do módulo\n",
    "X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, train_data, test_data, scaler = load_and_prepare_datasets()\n",
    "\n",
    "print(f\"Dataset de treino: {train_data.shape}\")\n",
    "print(f\"Dataset de teste: {test_data.shape}\")\n",
    "print(f\"Features: {X_train_scaled.shape[1]}\")\n",
    "\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "print(\"Treino:\", y_train.value_counts().to_dict())\n",
    "print(\"Teste:\", y_test.value_counts().to_dict())\n",
    "\n",
    "# Mostrar sample dos dados\n",
    "print(\"\\nPrimeiras linhas do dataset de treino:\")\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e75f7c",
   "metadata": {},
   "source": [
    "## 3. SAMPLING PARA BUSCA DE HIPERPARÂMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# SAMPLING ESTRATIFICADO PARA BUSCA DE HIPERPARÂMETROS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=== PREPARAÇÃO DE AMOSTRA PARA BUSCA DE HIPERPARÂMETROS ===\")\n",
    "\n",
    "# Amostra estratificada do dataset de treino\n",
    "_, X_sample, _, y_sample = train_test_split(\n",
    "    X_train_scaled, y_train,\n",
    "    test_size=SAMPLE_SIZE,\n",
    "    stratify=y_train,\n",
    "    random_state=RANDOM_STATE_SAMPLE\n",
    ")\n",
    "\n",
    "print(f\"Dataset original de treino: {X_train_scaled.shape[0]:,} amostras\")\n",
    "print(f\"Amostra para busca de hiperparâmetros: {X_sample.shape[0]:,} amostras\")\n",
    "print(f\"Redução: {(1 - X_sample.shape[0]/X_train_scaled.shape[0])*100:.1f}%\")\n",
    "\n",
    "print(\"\\nDistribuição das classes na amostra:\")\n",
    "print(\"Amostra:\", pd.Series(y_sample).value_counts().to_dict())\n",
    "print(\"Original:\", y_train.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d03f7a",
   "metadata": {},
   "source": [
    "## 4. DEFINIR ESTRATÉGIA DE VALIDAÇÃO CRUZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar estratégia de CV padrão dos módulos\n",
    "cv_strategy = DEFAULT_CV_STRATEGY\n",
    "print(f\"Estratégia de CV: {cv_strategy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d371b",
   "metadata": {},
   "source": [
    "## 5. SVM - BUSCA DE HIPERPARÂMETROS\n",
    "\n",
    "### 5.1 Definir Espaço de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177acb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# DEFINIÇÃO DO ESPAÇO DE HIPERPARÂMETROS\n",
    "# ======================================================================\n",
    "\n",
    "# Definir hiperparâmetros específicos para Decision Tree\n",
    "param_distributions = {\n",
    "    'C': loguniform(0.1, 1000),                                        # Distribuição log-uniforme para C\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],                 # Tipos de kernel\n",
    "    'gamma': ['scale', 'auto'] + list(loguniform(0.01, 100).rvs(20))   # Parâmetro gamma\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabc219",
   "metadata": {},
   "source": [
    "### 5.2 Executar Busca de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5fd47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# BUSCA DE HIPERPARAMETROS\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"=== BUSCA DE HIPERPARÂMETROS - {MODEL_NAME} ===\")\n",
    "print(f\"Iniciando busca de hiperparâmetros para {MODEL_NAME}...\")\n",
    "print(f\"Executando {N_SEARCHES} buscas com {N_ITER_PER_SEARCH} iterações cada...\")\n",
    "print(f\"Usando amostra de {X_sample.shape[0]:,} exemplos\\n\")\n",
    "\n",
    "# Múltiplas execuções do RandomizedSearchCV\n",
    "search, all_searches, best_params = multiple_randomized_search(\n",
    "    estimator=MODEL_CLASS(random_state=RANDOM_STATE_MODEL),\n",
    "    param_distributions=param_distributions,\n",
    "    X=X_sample,\n",
    "    y=y_sample,\n",
    "    cv_strategy=cv_strategy,\n",
    "    n_searches=N_SEARCHES,\n",
    "    n_iter_per_search=N_ITER_PER_SEARCH,\n",
    "    scoring='f1',\n",
    "    random_state=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Exibir os melhores resultados\n",
    "print(f\"\\n--- RESULTADOS {MODEL_NAME} ---\")\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "for param, value in search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nMelhor F1-Score (CV): {search.best_score_:.4f}\")\n",
    "print(f\"Desvio padrão: {search.cv_results_['std_test_score'][search.best_index_]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e846be",
   "metadata": {},
   "source": [
    "### 5.3 Visualizar Histórico da Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registro de Desempenho - plotar evolução da busca\n",
    "plot_search_history(all_searches, search, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb809975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# ANÁLISE DAS MELHORES CONFIGURAÇÕES ENCONTRADAS\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"=== MELHORES CONFIGURAÇÕES ENCONTRADAS POR BUSCA - {MODEL_NAME} ===\")\n",
    "\n",
    "# Extrair os melhores resultados de cada busca\n",
    "best_configs = []\n",
    "\n",
    "for i, search_result in enumerate(all_searches):\n",
    "    config = {\n",
    "        'Busca': i + 1,\n",
    "        'F1_Score': search_result.best_score_,\n",
    "        **search_result.best_params_\n",
    "    }\n",
    "    best_configs.append(config)\n",
    "\n",
    "# Criar DataFrame e exibir top configs\n",
    "results_df = pd.DataFrame(best_configs)\n",
    "results_df = results_df.sort_values('F1_Score', ascending=False).round(4)\n",
    "\n",
    "print(f\"\\nTop configurações (de {len(results_df)} buscas):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nEstatísticas dos F1-Scores encontrados:\")\n",
    "print(f\"  Média: {results_df['F1_Score'].mean():.4f}\")\n",
    "print(f\"  Mediana: {results_df['F1_Score'].median():.4f}\")\n",
    "print(f\"  Desvio padrão: {results_df['F1_Score'].std():.4f}\")\n",
    "print(f\"  Min: {results_df['F1_Score'].min():.4f}\")\n",
    "print(f\"  Max: {results_df['F1_Score'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976dd702",
   "metadata": {},
   "source": [
    "## 6. SALVAR RESULTADOS DE BUSCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_df = save_search_results(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_search=search,\n",
    "    model_all_searches=all_searches,\n",
    "    n_searches=N_SEARCHES,\n",
    "    n_iter_per_search=N_ITER_PER_SEARCH,\n",
    "    scoring='f1',\n",
    "    cv_folds=5,\n",
    "    top_params_columns=['max_depth', 'min_samples_split', 'min_samples_leaf', 'criterion', 'max_features'],\n",
    "    searches_folder=SEARCHES_FOLDER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7caed9",
   "metadata": {},
   "source": [
    "### 6.2 Carregar Resultado de Busca (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_results = load_search_results(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a história da busca a partir dos resultados carregados\n",
    "plot_search_history_from_loaded(loaded_results, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bced71d",
   "metadata": {},
   "source": [
    "### 6.3 Definir Melhores Params e CV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e54993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir Melhores Parâmetros para Uso Posterior\n",
    "if 'loaded_results' in locals():\n",
    "    best_params = get_best_params_from_saved(MODEL_NAME)\n",
    "    if best_params:\n",
    "        print(f\"✅ Parâmetros carregados: {best_params}\")\n",
    "    best_score = loaded_results['summary']['best_overall_score']\n",
    "    print(f\"✅ Melhor F1-Score carregado: {best_score:.4f}\")\n",
    "else:\n",
    "    best_params = search.best_params_\n",
    "    best_score = search.best_score_\n",
    "    print(f\"✅ Usando parâmetros da busca atual: {best_params}\")\n",
    "    print(f\"✅ Melhor F1-Score da busca atual: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5faacff",
   "metadata": {},
   "source": [
    "## 7. TREINAR MODELO FINAL E SALVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento Final com melhores hiperparâmetros\n",
    "\n",
    "best_model = MODEL_CLASS(random_state=RANDOM_STATE_MODEL, **best_params)\n",
    "best_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c38b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model immediately after training\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(MODELS_FOLDER, f'{MODEL_NAME.lower().replace(\" \", \"_\")}_model.joblib')\n",
    "dump(best_model, model_path)\n",
    "print(f\"✅ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdfc8c",
   "metadata": {},
   "source": [
    "## 8. AVALIAÇÃO FINAL E SALVAMENTO DOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo (Opcional)\n",
    "loaded_model = load(f'models/{MODEL_NAME.lower()}_trained.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"=== AVALIAÇÃO E SALVAMENTO DOS RESULTADOS - {MODEL_NAME} ===\")\n",
    "\n",
    "# Criar pastas se não existirem\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Avaliação completa do modelo\n",
    "print(\"\\nAvaliando performance do modelo...\")\n",
    "\n",
    "# Usar datasets completos para avaliação final\n",
    "X_train_eval = X_train_scaled\n",
    "y_train_eval = y_train\n",
    "X_test_eval = X_test_scaled\n",
    "y_test_eval = y_test\n",
    "\n",
    "# Avaliar modelo usando função do módulo\n",
    "train_metrics, test_metrics, y_test_pred = evaluate_model(\n",
    "    best_model, X_train_eval, X_test_eval, y_train_eval, y_test_eval, MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, y_test_pred, zero_division=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620681b",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title(f'{MODEL_NAME} - Confusion Matrix (Test Set)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5258028e",
   "metadata": {},
   "source": [
    "### 5.4 Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916527b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados finais usando função do módulo\n",
    "model_final_results = save_final_results(\n",
    "    model_name=MODEL_NAME,\n",
    "    best_params=best_params,\n",
    "    best_score=best_score,\n",
    "    train_metrics=train_metrics,\n",
    "    test_metrics=test_metrics,\n",
    "    y_pred=y_test_pred,\n",
    "    y_test=y_test_eval,\n",
    "    X_train_scaled=X_train_eval,\n",
    "    X_test_scaled=X_test_eval,\n",
    "    results_folder=RESULTS_FOLDER\n",
    ")\n",
    "\n",
    "# Mostrar resumo final\n",
    "print(f\"\\n--- RESUMO FINAL {MODEL_NAME} ---\")\n",
    "print(f\"F1-Score CV: {model_final_results['best_cv_score']:.4f}\")\n",
    "print(f\"F1-Score Teste: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Acurácia Teste: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precisão Teste: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall Teste: {test_metrics['recall']:.4f}\")\n",
    "print(f\"G-Mean Teste: {test_metrics['gmean']:.4f}\")\n",
    "if test_metrics.get('auc_roc'):\n",
    "    print(f\"AUC-ROC Teste: {test_metrics['auc_roc']:.4f}\")\n",
    "\n",
    "print(f\"\\nAvaliação do {MODEL_NAME} concluída com sucesso!\")\n",
    "print(f\"Resultados salvos em: {RESULTS_FOLDER}/\")\n",
    "print(f\"Modelo salvo em: {MODELS_FOLDER}/\")\n",
    "print(f\"Histórico de busca salvo em: {SEARCHES_FOLDER}/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
